[
  {
    "model_id": "meta-llama/Llama-3.1-8B-Instruct",
    "label": "Llama 3.1 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 14896283,
    "likes": 4470,
    "last_updated": "2024-09-25T17:00:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.020238214643931794,
      "math": 0.012142928786359076,
      "story": 0.004047642928786359,
      "roleplay": 0.004047642928786359
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-3.1-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-3.1-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "modularai/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.1-8B-Instruct-GGUF/resolve/main/Llama-3.1-8B-Instruct-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-8B-Instruct-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "Mungert/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.1-8B-Instruct-GGUF/resolve/main/Llama-3.1-8B-Instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-8B-Instruct-q8_0.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.1-8B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.1-8B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Llama-3.1-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.1-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lurker18/Llama_3.1_8B_Instruct_AWQ_4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lurker18/Llama_3.1_8B_Instruct_AWQ_4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "clowman/Llama-3.1-8B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/Llama-3.1-8B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Mungert/Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.1-8B-GGUF/resolve/main/Llama-3.1-8B-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-8B-q8_0.gguf"
      },
      {
        "model_id": "clowman/Llama-3.1-8B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/Llama-3.1-8B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.1-8B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-8B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16060556023,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556023
      },
      {
        "model_id": "mlx-community/Llama-3.1-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-8B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.1-8B-GGUF/resolve/main/Llama-3.1-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-8B-Q8_0.gguf"
      },
      {
        "model_id": "alekgomez/Llama-3.1-8B-4bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alekgomez/Llama-3.1-8B-4bit-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "nicole-amenta/Llama-3.1-8B-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nicole-amenta/Llama-3.1-8B-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4517489516,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4517489516
      },
      {
        "model_id": "matrixportalx/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "pbatra/Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pbatra/Llama-3.1-8B-Instruct-GGUF/resolve/main/llama-3.1-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "NeuralNovel/llama-3.1-8b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/NeuralNovel/llama-3.1-8b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-14B-Instruct",
    "label": "Qwen2.5 14B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 12287862,
    "likes": 263,
    "last_updated": "2024-09-25T12:33:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.02124122367101304,
      "math": 0.012744734202607823,
      "story": 0.004248244734202608,
      "roleplay": 0.004248244734202608
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-14B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-14B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 29540133920,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133920
      },
      {
        "model_id": "unsloth/Qwen2.5-14B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-14B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-14B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GGUF/resolve/main/qwen2.5-14b-instruct-q4_k_m-00001-of-00003.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-14b-instruct-q4_k_m-00001-of-00003.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-14B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-14B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-14B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "gaianet/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-14B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Mungert/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-q4_k_m.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-14B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-14B-GGUF/resolve/main/Qwen2.5-14B.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B.Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-14B-Instruct-GGUF/resolve/main/qwen2.5-14b-instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-14b-instruct.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 11.26,
    "ram_recommended_gb": 14.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 11.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-7B-Instruct",
    "label": "Qwen2.5 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10596057,
    "likes": 756,
    "last_updated": "2025-01-12T02:10:10+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.023711133400200604,
      "math": 0.014226680040120362,
      "story": 0.004742226680040121,
      "roleplay": 0.004742226680040121
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271888,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271888
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-7b-instruct-q2_k.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-7B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5570829760,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5570829760
      },
      {
        "model_id": "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-7B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853600,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-7B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-7B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Qwen2.5-7B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-7B-GGUF/resolve/main/Qwen2.5-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853600,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853600,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "Mungert/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853696,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-bf16.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-7B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-7B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853600,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-F16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-7B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-7B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Alcoft/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853120,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-7B-GGUF/resolve/main/qwen2.5-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-7b.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "bullerwins/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-7B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "matrixportalx/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-7b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "Rubavijayan/Qwen2.5-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Rubavijayan/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct.Q4_1.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-7b-instruct.Q4_1.gguf"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct"
  },
  {
    "model_id": "dphn/dolphin-2.9.1-yi-1.5-34b",
    "label": "Dolphin 2.9.1 Yi 1.5 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 4865965,
    "likes": 39,
    "last_updated": "2024-05-20T14:34:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-1-yi-1-5-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22964285714285715,
      "code": 0.023623370110330992,
      "math": 0.014174022066198595,
      "story": 0.004724674022066199,
      "roleplay": 0.004724674022066199
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/dolphin-2.9.1-yi-1.5-34b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/dolphin-2.9.1-yi-1.5-34b-GGUF/resolve/main/dolphin-2.9.1-yi-1.5-34b-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9.1-yi-1.5-34b-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 23.62,
    "ram_recommended_gb": 29.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 23.62,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b"
  },
  {
    "model_id": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
    "label": "Meta Llama Llama 3.2 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "fp16",
      "hf",
      "small"
    ],
    "dropped_tags": [
      "fp16"
    ],
    "downloads": 3573167,
    "likes": 2,
    "last_updated": "2025-02-22T04:09:45+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-llama-3-2-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.29936106256572237,
      "code": 0.020312443488931978,
      "math": 0.013506095275643252,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 6.8,
    "ram_recommended_gb": 8.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 6.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16"
  },
  {
    "model_id": "meta-llama/Llama-3.2-1B-Instruct",
    "label": "Llama 3.2 1B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 3534817,
    "likes": 1025,
    "last_updated": "2024-10-24T15:07:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-2-1b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.025491474423269808,
      "math": 0.015294884653961885,
      "story": 0.005098294884653962,
      "roleplay": 0.005098294884653962
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-3.2-1B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-f16.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595168,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-F16.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Llama-3.2-1B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Llama-3.2-1B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-1B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1114572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "SanctumAI/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Llama-3.2-1B-Instruct-GGUF/resolve/main/llama-3.2-1b-instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct.f16.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.2-1B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3.2-1B-GGUF/resolve/main/Llama-3.2-1B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B.Q2_K.gguf"
      },
      {
        "model_id": "AMead10/Llama-3.2-1B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/AMead10/Llama-3.2-1B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1556394472,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "base16/Llama-3.2-1B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/base16/Llama-3.2-1B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "saul95/Llama-3.2-1B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/saul95/Llama-3.2-1B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1032380416,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "Mungert/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.2-1B-GGUF/resolve/main/Llama-3.2-1B-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479591456,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-bf16.gguf"
      },
      {
        "model_id": "Mungert/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595520,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-bf16.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-F16.gguf"
      },
      {
        "model_id": "callgg/llama-3.2-1b-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/callgg/llama-3.2-1b-gguf/resolve/main/llama3.2-1b-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479591584,
        "notes": null,
        "revision": "main",
        "filename": "llama3.2-1b-f16.gguf"
      },
      {
        "model_id": "mukel/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mukel/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-Q4_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.2-1B-GGUF/resolve/main/Llama-3.2-1B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "prithivMLmods/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Llama-3.2-1B-GGUF/resolve/main/Llama-3.2-1B.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595904,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B.F16.gguf"
      },
      {
        "model_id": "gaianet/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-f16.gguf"
      },
      {
        "model_id": "clowman/Llama-3.2-1B-Instruct-AWQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/Llama-3.2-1B-Instruct-AWQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "matrixportalx/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Llama-3.2-1B-Instruct-GGUF/resolve/main/llama-3.2-1b-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct-f16.gguf"
      },
      {
        "model_id": "DevQuasar/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "clowman/Llama-3.2-1B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/Llama-3.2-1B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "saul95/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/saul95/Llama-3.2-1B-GGUF/resolve/main/llama-3.2-1b.bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479591424,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b.bf16.gguf"
      },
      {
        "model_id": "mav23/Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.2-1B-GGUF/resolve/main/llama-3.2-1b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Llama-3.2-1B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.2-1B-Instruct-GGUF/resolve/main/llama-3.2-1b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "taylorj94/Llama-3.2-1B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/taylorj94/Llama-3.2-1B/resolve/main/Llama-3.2-1B-Instruct-Q4_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-Q4_K_L.gguf"
      },
      {
        "model_id": "ipetrukha/Llama-3.2-1B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ipetrukha/Llama-3.2-1B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "teleprint-me/llama-3.2-1b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/teleprint-me/llama-3.2-1b-instruct/resolve/main/ggml-model-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2479595360,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-f16.gguf"
      },
      {
        "model_id": "featherless-ai-quants/4bit-Llama-3.2-1B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/featherless-ai-quants/4bit-Llama-3.2-1B-GGUF/resolve/main/4bit-Llama-3.2-1B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "4bit-Llama-3.2-1B-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 1.9,
    "ram_recommended_gb": 2.38,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
    "label": "Qwen2.5 1.5B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 3104717,
    "likes": 489,
    "last_updated": "2024-09-25T12:32:50+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.022313189568706118,
      "math": 0.01338791374122367,
      "story": 0.0044626379137412235,
      "roleplay": 0.0044626379137412235
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-1.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3087467144,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416288,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-1.5b-instruct-fp16.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-1.5B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-1.5B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-1.5B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-1.5B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1614553840,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-1.5B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-1.5B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "Mungert/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669536,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-bf16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-F16.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-1.5B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-1.5B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-1.5B-GGUF/resolve/main/Qwen2.5-1.5B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-1.5b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "ZeroWw/Qwen2.5-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ZeroWw/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-1.5B-Instruct.f16.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-3B-Instruct",
    "label": "Qwen2.5 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2867626,
    "likes": 289,
    "last_updated": "2024-09-25T12:33:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.02403084252758275,
      "math": 0.014418505516549648,
      "story": 0.00480616850551655,
      "roleplay": 0.00480616850551655
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 6171926992,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6171926992
      },
      {
        "model_id": "Qwen/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-3b-instruct-q2_k.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2686704624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2.5-3B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-3B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Qwen2.5-3B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317216,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-3B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-3B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Mungert/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317312,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-bf16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "gaianet/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317216,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317216,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-3B-GGUF/resolve/main/Qwen2.5-3B-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 12349708480,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-f32.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317216,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct-F16.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-3B-GGUF/resolve/main/Qwen2.5-3B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-3B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-3B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Qwen2.5-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-3B-GGUF/resolve/main/qwen2.5-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-3b.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-3B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-3B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-3B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-3B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-3B-Instruct-GGUF/resolve/main/Qwen2.5-3B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-3B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-3b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "matrixportalx/Qwen2.5-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-3b-instruct-q6_k.gguf"
      },
      {
        "model_id": "zhitels/Qwen2.5-3B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/zhitels/Qwen2.5-3B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "STiFLeR7/Qwen2.5-3B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/STiFLeR7/Qwen2.5-3B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2067756520,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 3.34,
    "ram_recommended_gb": 4.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.34,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct"
  },
  {
    "model_id": "meta-llama/Llama-3.2-3B-Instruct",
    "label": "Llama 3.2 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1731601,
    "likes": 1659,
    "last_updated": "2024-10-24T15:07:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-2-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.02290245737211635,
      "math": 0.01374147442326981,
      "story": 0.00458049147442327,
      "roleplay": 0.00458049147442327
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "meta-llama/Llama-3.2-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.2-3B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687616,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-F16.gguf"
      },
      {
        "model_id": "second-state/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.2-3B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-3B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Llama-3.2-3B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "SanctumAI/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b-instruct.f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.2-3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.2-3B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6425528717,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6425528717
      },
      {
        "model_id": "AMead10/Llama-3.2-3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/AMead10/Llama-3.2-3B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3040769296,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "gaianet/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3.2-3B-GGUF/resolve/main/Llama-3.2-3B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B.Q2_K.gguf"
      },
      {
        "model_id": "Mungert/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433688000,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-bf16.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-F16.gguf"
      },
      {
        "model_id": "matrixportalx/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b-instruct-f16.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "nicole-amenta/Llama-3.2-3B-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nicole-amenta/Llama-3.2-3B-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1807496847,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1807496847
      },
      {
        "model_id": "tensorblock/Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.2-3B-GGUF/resolve/main/Llama-3.2-3B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Q2_K.gguf"
      },
      {
        "model_id": "prithivMLmods/Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Llama-3.2-3B-GGUF/resolve/main/Llama-3.2-3B-GGUF.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433683744,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-GGUF.F16.gguf"
      },
      {
        "model_id": "gpustack/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gpustack/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-FP16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-FP16.gguf"
      },
      {
        "model_id": "mukel/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mukel/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1964572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-Q4_0.gguf"
      },
      {
        "model_id": "merterbak/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/merterbak/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687712,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "benniekiss/llama-3.2-3B-instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/benniekiss/llama-3.2-3B-instruct-gguf/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "mav23/Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.2-3B-GGUF/resolve/main/llama-3.2-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.2-3B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-3B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "colesmcintosh/Llama-3.2-3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/colesmcintosh/Llama-3.2-3B-Instruct-8bit/resolve/main/model.safetensors?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community-staging/Llama-3.2-3B-Instruct-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community-staging/Llama-3.2-3B-Instruct-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MCZK/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MCZK/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct.f16.gguf"
      },
      {
        "model_id": "prithivMLmods/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687648,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct.F16.gguf"
      },
      {
        "model_id": "mav23/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "hankleetw/llama_3.2_3b_instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hankleetw/llama_3.2_3b_instruct/resolve/main/llama-3.2-3B-instruct_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433687840,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3B-instruct_f16.gguf"
      },
      {
        "model_id": "Alex01837178373/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alex01837178373/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b-instruct.Q6_K.gguf"
      },
      {
        "model_id": "vanhocpham/Llama-3.2-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/vanhocpham/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433688384,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct.F16.gguf"
      }
    ],
    "ram_estimate_gb": 3.34,
    "ram_recommended_gb": 4.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.34,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "label": "Deepseek R1 Distill Qwen 7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1704095,
    "likes": 691,
    "last_updated": "2025-02-24T03:32:20+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-qwen-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0732221664994985,
      "code": 0.12357142857142857,
      "math": 0.02196664994984955,
      "story": 0.00432221664994985,
      "roleplay": 0.00432221664994985
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853152,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-7B-f16.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271864
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-7B-Q6_K.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-qwen-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-qwen-7b/resolve/main/deepseek-r1-distill-qwen-7b-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-7b-q2_k.gguf"
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Qwen-7B_AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Qwen-7B_AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5570829936,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5570829936
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Qwen-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Qwen-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 15231271443,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271443
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Qwen-7B_GPTQ-int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Qwen-7B_GPTQ-int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237852864,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-7B-f16.gguf"
      },
      {
        "model_id": "eaddario/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/eaddario/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237852896,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-7B-F16.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237852864,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-7B-f16.gguf"
      },
      {
        "model_id": "ALYTV/DeepSeek-R1-Distill-Qwen-7B-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ALYTV/DeepSeek-R1-Distill-Qwen-7B-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "pirahtays/DeepSeek-R1-Distill-Qwen-7B-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pirahtays/DeepSeek-R1-Distill-Qwen-7B-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "alekgomez/DeepSeek-R1-Distill-Qwen-7B-4bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alekgomez/DeepSeek-R1-Distill-Qwen-7B-4bit-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "pbatra/DeepSeek-R1-Distill-Qwen-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pbatra/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/deepseek-r1-distill-qwen-7b.Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-7b.Q4_0.gguf"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
  },
  {
    "model_id": "Qwen/Qwen2.5-7B-Instruct-1M",
    "label": "Qwen2.5 7B 1M",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1540462,
    "likes": 346,
    "last_updated": "2025-01-29T12:39:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-7b-1m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.020351053159478435,
      "math": 0.01221063189568706,
      "story": 0.004070210631895687,
      "roleplay": 0.004070210631895687
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7B-Instruct-1M-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853792,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-1M-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7B-Instruct-1M-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-1M-Q6_K.gguf"
      },
      {
        "model_id": "Mungert/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7B-Instruct-1M-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853632,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-1M-bf16.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-7B-Instruct-1M-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-1M-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-7B-Instruct-1M",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-7B-Instruct-1M/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271864
      },
      {
        "model_id": "QuantFactory/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7B-Instruct-1M.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-1M.Q2_K.gguf"
      },
      {
        "model_id": "BabaK07/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/BabaK07/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7b-Instruct-1M-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853536,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7b-Instruct-1M-F16.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-7B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-7B-Instruct-1M-GGUF/resolve/main/Qwen2.5-7B-Instruct-1M-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-7B-Instruct-1M-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-7B-Instruct-1M-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-1M-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-7B-Instruct-1M-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-1M-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-1M"
  },
  {
    "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "label": "Tinyllama 1.1B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1.0"
    ],
    "dropped_tags": [
      "v1.0"
    ],
    "downloads": 1356486,
    "likes": 1365,
    "last_updated": "2024-03-17T05:07:08+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "tinyllama-1-1b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22964285714285715,
      "code": 0.024269057171514542,
      "math": 0.014561434302908724,
      "story": 0.004853811434302909,
      "roleplay": 0.004853811434302909
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 768173232,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 768148704,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v0.4",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 765774992,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6/resolve/main/model.safetensors?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 1194572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "LnL-AI/TinyLlama-1.1B-Chat-v1.0-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LnL-AI/TinyLlama-1.1B-Chat-v1.0-GPTQ-4bit/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 974572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      },
      {
        "model_id": "atorsvn/TinyLlama-1.1B-Chat-v0.3-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/atorsvn/TinyLlama-1.1B-Chat-v0.3-gptq-4bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 974572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "andrijdavid/TinyLlama-1.1B-Chat-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/andrijdavid/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2201017248,
        "notes": null,
        "revision": "main",
        "filename": "TinyLlama-1.1B-Chat-v1.0-f16.gguf"
      },
      {
        "model_id": "TheBloke/TinyLlama-1.1B-Chat-v1.0-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 765750416,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/TinyLlama-1.1B-Chat-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 644572800,
        "notes": null,
        "revision": "main",
        "filename": "TinyLlama-1.1B-Chat-v1.0-Q2_K.gguf"
      },
      {
        "model_id": "Jiqing/TinyLlama-1.1B-Chat-v1.0-bnb-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Jiqing/TinyLlama-1.1B-Chat-v1.0-bnb-8bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1414572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "habanoz/TinyLlama-1.1B-Chat-v0.3-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/habanoz/TinyLlama-1.1B-Chat-v0.3-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 768173112,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "kirp/TinyLlama-1.1B-Chat-v0.2-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kirp/TinyLlama-1.1B-Chat-v0.2-gguf/resolve/main/ggml-model-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 644572800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-q2_k.gguf"
      },
      {
        "model_id": "pbatra/TinyLlama-1.1B-Chat-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pbatra/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2201017280,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-chat-v1.0.f16.gguf"
      },
      {
        "model_id": "afrideva/TinyLlama-1.1B-Chat-v0.6-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/TinyLlama-1.1B-Chat-v0.6-GGUF/resolve/main/tinyllama-1.1b-chat-v0.6.q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1194572800,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-chat-v0.6.q6_k.gguf"
      },
      {
        "model_id": "afrideva/TinyLlama-1.1B-Chat-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/TinyLlama-1.1B-Chat-v0.4-GGUF/resolve/main/tinyllama-1.1b-chat-v0.4.q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 919572800,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-chat-v0.4.q4_k_m.gguf"
      },
      {
        "model_id": "MaziyarPanahi/TinyLlama-1.1B-Chat-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 644572800,
        "notes": null,
        "revision": "main",
        "filename": "TinyLlama-1.1B-Chat-v1.0.Q2_K.gguf"
      },
      {
        "model_id": "solidrust/TinyLlama-1.1B-Chat-v1.0-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/TinyLlama-1.1B-Chat-v1.0-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 765750416,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "YashRawal225/TinyLlama-1.1B-Chat-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/YashRawal225/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/ggml-vocab-llama.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 723676,
        "notes": null,
        "revision": "main",
        "filename": "ggml-vocab-llama.gguf"
      },
      {
        "model_id": "Arcio/TinyLlama-1.1B-Chat-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Arcio/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/ggml-vocab-llama.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 723676,
        "notes": null,
        "revision": "main",
        "filename": "ggml-vocab-llama.gguf"
      }
    ],
    "ram_estimate_gb": 1.97,
    "ram_recommended_gb": 2.47,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.97,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.1,
    "tier": "high",
    "model_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  },
  {
    "model_id": "apple/OpenELM-1_1B-Instruct",
    "label": "Openelm 1 1B",
    "tags": [
      "chat",
      "hf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 1223078,
    "likes": 66,
    "last_updated": "2025-02-28T18:31:24+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "openelm-1-1b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.02574222668004012,
      "math": 0.015445336008024071,
      "story": 0.005148445336008025,
      "roleplay": 0.005148445336008025
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "apple/OpenELM-1_1B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/apple/OpenELM-1_1B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 4319591488,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 2.8,
    "ram_recommended_gb": 3.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 2.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.0,
    "tier": "high",
    "model_url": "https://huggingface.co/apple/OpenELM-1_1B-Instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "label": "Deepseek R1 Distill Qwen 32B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1148688,
    "likes": 1428,
    "last_updated": "2025-02-24T03:31:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-qwen-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.0720937813440321,
      "code": 0.12357142857142857,
      "math": 0.02162813440320963,
      "story": 0.00420937813440321,
      "roleplay": 0.00420937813440321
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Qwen-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-32B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-32B-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Valdemardi/DeepSeek-R1-Distill-Qwen-32B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Valdemardi/DeepSeek-R1-Distill-Qwen-32B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328994000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328994000
      },
      {
        "model_id": "empirischtech/DeepSeek-R1-Distill-Qwen-32B-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/empirischtech/DeepSeek-R1-Distill-Qwen-32B-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 65527841688,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 65527841688
      },
      {
        "model_id": "inarikami/DeepSeek-R1-Distill-Qwen-32B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/inarikami/DeepSeek-R1-Distill-Qwen-32B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328994120,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328994120
      },
      {
        "model_id": "dwetzel/DeepSeek-R1-Distill-Qwen-32B-GPTQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/dwetzel/DeepSeek-R1-Distill-Qwen-32B-GPTQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-qwen-32b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-qwen-32b/resolve/main/deepseek-r1-distill-qwen-32b-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-32b-q2_k.gguf"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Qwen-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Qwen-32B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-R1-Distill-Qwen-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-Distill-Qwen-32B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-32B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 24.22,
    "ram_recommended_gb": 30.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 24.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
  },
  {
    "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "label": "Meta Llama 3 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 1099381,
    "likes": 4136,
    "last_updated": "2025-06-18T23:49:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.022545135406218657,
      "math": 0.013527081243731193,
      "story": 0.004509027081243732,
      "roleplay": 0.004509027081243732
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Meta-Llama-3-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "bartowski/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3-8B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B.Q8_0.gguf"
      },
      {
        "model_id": "Mungert/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-q8_0.gguf"
      },
      {
        "model_id": "solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "PawanKrd/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/PawanKrd/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/llama-3-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-8B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-8B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-8B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-8B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-8B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF-v2/resolve/main/Meta-Llama-3-8B-Instruct-v2.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-v2.Q8_0.gguf"
      },
      {
        "model_id": "Mungert/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-q8_0.gguf"
      },
      {
        "model_id": "solidrust/Meta-Llama-3-8B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Meta-Llama-3-8B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "alokabhishek/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "alokabhishek/Meta-Llama-3-8B-Instruct-bnb-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alokabhishek/Meta-Llama-3-8B-Instruct-bnb-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "NousResearch/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "SanctumAI/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/meta-llama-3-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "AI-Engine/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/AI-Engine/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "NousResearch/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-8B-GGUF-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF-v2/resolve/main/Meta-Llama-3-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B.Q8_0.gguf"
      },
      {
        "model_id": "LiteLLMs/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Meta-Llama-3-8B-GGUF/resolve/main/Q8_0/Q8_0-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Q8_0/Q8_0-00001-of-00001.gguf"
      },
      {
        "model_id": "matrixportalx/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/meta-llama-3-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "MoMonir/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "ThomasBaruzier/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "LiteLLMs/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Q8_0/Q8_0-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Q8_0/Q8_0-00001-of-00005.gguf"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Q8_0.gguf"
      },
      {
        "model_id": "leliuga/Meta-Llama-3-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/leliuga/Meta-Llama-3-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3-8B-Instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3-8B-Instruct-hf-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-hf-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-hf-Q8_0.gguf"
      },
      {
        "model_id": "brittlewis12/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/meta-llama-3-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-8B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "LoneStriker/Meta-Llama-3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Q8_0.gguf"
      },
      {
        "model_id": "jburmeister/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jburmeister/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-8B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "rajkosto/Meta-Llama-3-8B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/rajkosto/Meta-Llama-3-8B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "solidrust/Meta-Llama-3-8B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Meta-Llama-3-8B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "SandLogicTechnologies/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "AviadDahan/Meta-Llama-3-8B-fp16-gguf",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "nitsuai/Meta-Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nitsuai/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-8B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16060556314,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556314
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-8B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3-8B-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3-8B-hf-GGUF/resolve/main/Meta-Llama-3-8B-hf-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-hf-Q8_0.gguf"
      },
      {
        "model_id": "alokabhishek/Meta-Llama-3-8B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alokabhishek/Meta-Llama-3-8B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "rainjay/Meta-Llama-3-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/rainjay/Meta-Llama-3-8B-Instruct-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"
  },
  {
    "model_id": "microsoft/Phi-3-mini-128k-instruct",
    "label": "Phi 3 Mini 128K",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 1083572,
    "likes": 1661,
    "last_updated": "2025-03-02T22:28:37+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-mini-128k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.12357142857142857,
      "math": 0.02169959879638917,
      "story": 0.00423319959879639,
      "roleplay": 0.00423319959879639
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Phi-3-mini-128k-instruct-GGUF/resolve/main/Phi-3-mini-128k-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203616,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-128k-instruct.Q2_K.gguf"
      },
      {
        "model_id": "second-state/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-3-mini-128k-instruct-GGUF/resolve/main/Phi-3-mini-128k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297248,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-128k-instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3-mini-128k-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-mini-128k-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2149696167,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2149696167
      },
      {
        "model_id": "gaianet/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-3-mini-128k-instruct-GGUF/resolve/main/Phi-3-mini-128k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297248,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-128k-instruct-f16.gguf"
      },
      {
        "model_id": "solidrust/Phi-3-mini-128k-instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Phi-3-mini-128k-instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2277171624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "jsincn/phi-3-mini-128k-instruct-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jsincn/phi-3-mini-128k-instruct-awq/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2277171624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MoMonir/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MoMonir/Phi-3-mini-128k-instruct-GGUF/resolve/main/phi-3-mini-128k-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 3135851744,
        "notes": null,
        "revision": "main",
        "filename": "phi-3-mini-128k-instruct.Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-3-mini-128k-instruct-GGUF/resolve/main/Phi-3-mini-128k-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204256,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-128k-instruct-Q2_K.gguf"
      },
      {
        "model_id": "AlessandroW/Phi-3-mini-128k-instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/AlessandroW/Phi-3-mini-128k-instruct-gguf/resolve/main/Phi-3-mini-128k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643296608,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-128k-instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3-mini-128k-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-mini-128k-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4060136345,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4060136345
      },
      {
        "model_id": "shuyuej/Phi-3-mini-128k-instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shuyuej/Phi-3-mini-128k-instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2279413824,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "LiteLLMs/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Phi-3-mini-128k-instruct-GGUF/resolve/main/Q2_K/Q2_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203680,
        "notes": null,
        "revision": "main",
        "filename": "Q2_K/Q2_K-00001-of-00001.gguf"
      },
      {
        "model_id": "BenevolenceMessiah/Phi-3-mini-128k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/BenevolenceMessiah/Phi-3-mini-128k-instruct-GGUF/resolve/main/phi-3-mini-128k-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204256,
        "notes": null,
        "revision": "main",
        "filename": "phi-3-mini-128k-instruct-q2_k.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3-mini-128k-instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "label": "Deepseek R1 Distill Llama 8B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 1068816,
    "likes": 784,
    "last_updated": "2025-02-24T03:32:07+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-llama-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0805566700100301,
      "code": 0.12357142857142857,
      "math": 0.024167001003009028,
      "story": 0.00505566700100301,
      "roleplay": 0.00505566700100301
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
      },
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 16060556376,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556376
      },
      {
        "model_id": "recursechat/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/recursechat/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Llama-8B_AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Llama-8B_AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Llama-8B_GPTQ-int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Llama-8B_GPTQ-int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-llama-8b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-llama-8b/resolve/main/deepseek-r1-distill-llama-8b-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-llama-8b-q8_0.gguf"
      },
      {
        "model_id": "eaddario/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/eaddario/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/DeepSeek-R1-Distill-Llama-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-8B.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Llama-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Llama-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16060556023,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556023
      },
      {
        "model_id": "Akashium/DeepSeek-R1-Distill-Llama-8B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Akashium/DeepSeek-R1-Distill-Llama-8B-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "alekgomez/DeepSeek-R1-Distill-Llama-8B-4bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alekgomez/DeepSeek-R1-Distill-Llama-8B-4bit-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
  },
  {
    "model_id": "meta-llama/Llama-2-7b-chat-hf",
    "label": "Llama 2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 997200,
    "likes": 4543,
    "last_updated": "2024-04-17T08:40:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22964285714285715,
      "code": 0.020106569709127383,
      "math": 0.01206394182547643,
      "story": 0.004021313941825476,
      "roleplay": 0.004021313941825476
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-2-7b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-7b-chat.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896726136,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896726136,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/llama-2-7b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-2-7b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-7b.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/llama-2-7b-chat-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-2-7b-chat-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889391512,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Llama-2-7b-chat-mlx",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "TheBloke/Llama-2-7B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-7B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889391512,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "HyperdustProtocol/llama-2-7b-bnb-4bit_0528",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Mungert/Llama-2-7b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-2-7b-chat-hf-GGUF/resolve/main/Llama-2-7b-chat-hf-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 13478106240,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-7b-chat-hf-bf16.gguf"
      },
      {
        "model_id": "second-state/Llama-2-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-2-7B-Chat-GGUF/resolve/main/Llama-2-7b-chat-hf-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 13478105696,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-7b-chat-hf-f16.gguf"
      },
      {
        "model_id": "mlx-community/Llama-2-7b-mlx",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/Llama-2-7B-Chat-fp16-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-2-7B-Chat-fp16-GGUF/resolve/main/Llama-2-7B-Chat-fp16-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-7B-Chat-fp16-Q6_K.gguf"
      },
      {
        "model_id": "4bit/Llama-2-7b-chat-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/4bit/Llama-2-7b-chat-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Llama-2-7b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-2-7b-hf-GGUF/resolve/main/Llama-2-7b-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-7b-hf-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-2-7b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-2-7b-chat-hf-GGUF/resolve/main/Llama-2-7b-chat-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-7b-chat-hf-Q2_K.gguf"
      },
      {
        "model_id": "substratusai/Llama-2-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/substratusai/Llama-2-7b-chat-GGUF/resolve/main/llama2-7b-chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 13478104736,
        "notes": null,
        "revision": "main",
        "filename": "llama2-7b-chat-f16.gguf"
      },
      {
        "model_id": "e-valente/Llama-2-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/e-valente/Llama-2-7B-Chat-GGUF/resolve/main/ggml-model-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-q4_0.gguf"
      },
      {
        "model_id": "mav23/Llama-2-7b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-2-7b-chat-hf-GGUF/resolve/main/llama-2-7b-chat-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-7b-chat-hf.Q2_K.gguf"
      },
      {
        "model_id": "shashikanth-a/llama-2-7b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shashikanth-a/llama-2-7b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "shashikanth-a/llama-2-7b-chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shashikanth-a/llama-2-7b-chat-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "localmodels/Llama-2-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/localmodels/Llama-2-7B-GPTQ/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      },
      {
        "model_id": "4bit/Llama-2-7b-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/4bit/Llama-2-7b-Chat-GPTQ/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      },
      {
        "model_id": "seonglae/llama-2-7b-chat-hf-gptq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/seonglae/llama-2-7b-chat-hf-gptq/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      },
      {
        "model_id": "unionai/Llama-2-7b-hf-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "anhtu12st/Llama-2-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/anhtu12st/Llama-2-7B-GPTQ/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896979412,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "alokabhishek/Llama-2-7b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alokabhishek/Llama-2-7b-chat-hf-GGUF/resolve/main/llama-2-7b-chat-hf.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-7b-chat-hf.Q4_K_M.gguf"
      },
      {
        "model_id": "localmodels/Llama-2-7B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/localmodels/Llama-2-7B-Chat-GPTQ/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      },
      {
        "model_id": "gsaivinay/Llama-2-7b-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gsaivinay/Llama-2-7b-Chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896726080,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "realzdlegend/Llama-2-7b-chat-hf-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/realzdlegend/Llama-2-7b-chat-hf-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"
  },
  {
    "model_id": "mistralai/Mistral-7B-Instruct-v0.2",
    "label": "Mistral 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.2"
    ],
    "dropped_tags": [
      "v0.2"
    ],
    "downloads": 905139,
    "likes": 2918,
    "last_updated": "2025-07-24T16:57:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "mistral-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.021335255767301907,
      "math": 0.012801153460381144,
      "story": 0.0042670511534603816,
      "roleplay": 0.0042670511534603816
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mistralai/Mistral-7B-v0.1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/mistral-7b-v0.3-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3.Q2_K.gguf"
      },
      {
        "model_id": "RedHatAI/Mistral-7B-Instruct-v0.3-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/RedHatAI/Mistral-7B-Instruct-v0.3-GPTQ-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-instruct-v0.3-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.2-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662280,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "SanctumAI/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14497337280,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.3.f16.gguf"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.2-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880232,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 28992851904,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3-f32.gguf"
      },
      {
        "model_id": "TheBloke/Mistral-7B-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/mistral-7b-instruct-v0.2-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-instruct-v0.2-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/mistral-7b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 28992851904,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3-f32.gguf"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.1-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662096,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Mistral-7B-Instruct-v0.1-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880304,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "solidrust/Mistral-7B-Instruct-v0.3-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Mistral-7B-Instruct-v0.3-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4163463144,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/mistral-7b-instruct-v0.1-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-instruct-v0.1-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-v0.3-GGUF/resolve/main/Mistral-7B-v0.3.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-v0.3.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Mistral-7B-v0.1-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-v0.1-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880304,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "thesven/Mistral-7B-Instruct-v0.3-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Mistral-7B-Instruct-v0.3-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4171245008,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Mistral-7B-v0.1-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Mistral-7B-v0.1-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662096,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "thesven/Mistral-7B-Instruct-v0.3-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Mistral-7B-Instruct-v0.3-GPTQ-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "casperhansen/mistral-7b-instruct-v0.1-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/casperhansen/mistral-7b-instruct-v0.1-awq/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4151034841,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "mlx-community/Mistral-7B-Instruct-v0.2",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "TheBlock/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBlock/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/mistral-7b-v0.2-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/mistral-7b-v0.2-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Mistral-7B-Instruct-v0.2-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mistral-7B-Instruct-v0.2-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/Mistral-7B-Instruct-v0.1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.1-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14497337344,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3-f16.gguf"
      },
      {
        "model_id": "enlogen/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/enlogen/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 28992851904,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3-f32.gguf"
      },
      {
        "model_id": "elimelec1/Mistral-7B-Instruct-v0.3-mlx-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/elimelec1/Mistral-7B-Instruct-v0.3-mlx-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "stan-hua/Mistral-7B-Instruct-v0.3-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stan-hua/Mistral-7B-Instruct-v0.3-AWQ-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/mistral-7B-v0.1",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "gaianet/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14497337344,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/Mistral-7B-Instruct-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "DevQuasar/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14497337216,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.3.f16.gguf"
      },
      {
        "model_id": "second-state/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/Mistral-7B-Instruct-v0.2-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.2-Q2_K.gguf"
      },
      {
        "model_id": "Mungert/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/Mistral-7B-Instruct-v0.1-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14484733600,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.1-bf16.gguf"
      },
      {
        "model_id": "fedora-copr/Mistral-7B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/fedora-copr/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/ggml-model-Q4_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-Q4_K.gguf"
      },
      {
        "model_id": "Mungert/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/Mistral-7B-Instruct-v0.2-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14484733376,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.2-bf16.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/Mistral-7B-Instruct-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-v0.1-GGUF/resolve/main/Mistral-7B-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-v0.2-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-v0.2-hf-GGUF/resolve/main/Mistral-7B-v0.2-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-v0.2-hf.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/Mistral-7B-Instruct-v0.1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.1-Q2_K.gguf"
      },
      {
        "model_id": "kaitchup/Mistral-7B-awq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kaitchup/Mistral-7B-awq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "LsTam/Mistral-7B-Instruct-v0.2-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LsTam/Mistral-7B-Instruct-v0.2-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Mistral-7B-v0.2-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-7B-v0.2-hf-GGUF/resolve/main/Mistral-7B-v0.2-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-v0.2-hf-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Mistral-7B-Instruct-v0.2-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.2-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662208,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ddh0/Mistral-7B-Instruct-v0.1-GGUF-fp16",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Mistral-7B-v0.1-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mistral-7B-v0.1-hf-4bit-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "QuantFactory/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/Mistral-7B-Instruct-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Mistral-7B-Instruct-v0.1-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mistral-7B-Instruct-v0.1-4bit-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "filipealmeida/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/filipealmeida/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v1.0-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14484731424,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v1.0-f16.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Mistral-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/Mistral-7B-Instruct-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-Instruct-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "jpodivin/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jpodivin/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/ggml-model-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14484732800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-f16.gguf"
      },
      {
        "model_id": "alokabhishek/Mistral-7B-Instruct-v0.2-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alokabhishek/Mistral-7B-Instruct-v0.2-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "kaitchup/Mistral-7B-v0.1-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kaitchup/Mistral-7B-v0.1-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "beratcmn/Mistral-7B-v0.1-int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/beratcmn/Mistral-7B-v0.1-int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Mistral-7B-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-v0.2-GGUF/resolve/main/Mistral-7B-v0.2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-7B-v0.2.Q2_K.gguf"
      },
      {
        "model_id": "wenqiglantz/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/wenqiglantz/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.2.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/mlx-mistral-7B-v0.1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/mlx-mistral-7B-v0.1/resolve/main/model.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4262357056,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "alokabhishek/Mistral-7B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alokabhishek/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-7b-instruct-v0.2.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "label": "Deepseek R1 Distill Qwen 1.5B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 804738,
    "likes": 1301,
    "last_updated": "2025-02-24T03:32:35+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-qwen-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07060180541624875,
      "code": 0.12357142857142857,
      "math": 0.021180541624874625,
      "story": 0.004060180541624875,
      "roleplay": 0.004060180541624875
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416576,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3554214621,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416352,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "DheyoAI/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DheyoAI/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-pct5.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 1660311840,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-pct5.gguf"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416096,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf"
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-qwen-1.5b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-qwen-1.5b/resolve/main/deepseek-r1-distill-qwen-1.5b-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-1.5b-q2_k.gguf"
      },
      {
        "model_id": "hdnh2006/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hdnh2006/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf"
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Qwen-1.5B_AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Qwen-1.5B_AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1614553904,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "jakiAJK/DeepSeek-R1-Distill-Qwen-1.5B_GPTQ-int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jakiAJK/DeepSeek-R1-Distill-Qwen-1.5B_GPTQ-int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "gaianet/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416096,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B-f16.gguf"
      },
      {
        "model_id": "Alcoft/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3560416160,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-1.5B_f16.gguf"
      },
      {
        "model_id": "pbatra/DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pbatra/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/deepseek-r1-distill-qwen-1.5b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-1.5b.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
  },
  {
    "model_id": "Qwen/Qwen1.5-0.5B-Chat",
    "label": "Qwen1.5 0.5B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 790307,
    "likes": 82,
    "last_updated": "2024-04-30T07:19:52+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen1-5-0-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22892857142857143,
      "code": 0.0210092778335005,
      "math": 0.012605566700100301,
      "story": 0.0042018555667001,
      "roleplay": 0.0042018555667001
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen1.5-0.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 1239173352,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen1.5-0.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-GGUF/resolve/main/qwen1_5-0_5b-chat-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1_5-0_5b-chat-q2_k.gguf"
      },
      {
        "model_id": "mlx-community/Qwen1.5-0.5B-Chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen1.5-0.5B-Chat-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen1.5-0.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen1.5-0.5B-Chat-GGUF/resolve/main/Qwen1.5-0.5B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-0.5B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen1.5-0.5B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 782808312,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/Qwen1.5-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen1.5-0.5B-GGUF/resolve/main/Qwen1.5-0.5B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-0.5B-Q2_K.gguf"
      },
      {
        "model_id": "Brianpu/Qwen1.5-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Brianpu/Qwen1.5-0.5B-GGUF/resolve/main/qwen1.5-0.5b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 589572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1.5-0.5b-q4_k_m.gguf"
      },
      {
        "model_id": "mlx-community/Qwen1.5-0.5B-Chat",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen1.5-0.5B-Chat/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1239172715,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1239172715
      },
      {
        "model_id": "madroid/Qwen1.5-0.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/madroid/Qwen1.5-0.5B/resolve/main/qwen1.5-0.5B-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 589572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1.5-0.5B-q4_0.gguf"
      }
    ],
    "ram_estimate_gb": 1.54,
    "ram_recommended_gb": 1.93,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "label": "Deepseek Coder Lite",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "v2"
    ],
    "dropped_tags": [
      "v2"
    ],
    "downloads": 776547,
    "likes": 461,
    "last_updated": "2024-07-03T05:16:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-coder-v2-le",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22892857142857143,
      "code": 0.11446428571428571,
      "math": 0.02307246740220662,
      "story": 0.004690822467402207,
      "roleplay": 0.004690822467402207
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 6430464768,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-Coder-V2-Lite-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 14066972416,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-Coder-V2-Lite-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "second-state/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 31424033248,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-Coder-V2-Lite-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 31424033248,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-Coder-V2-Lite-Instruct-f16.gguf"
      },
      {
        "model_id": "TechxGenus/DeepSeek-Coder-V2-Lite-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/DeepSeek-Coder-V2-Lite-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 9086606872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 9086606872
      },
      {
        "model_id": "mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8866303750,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 8866303750
      },
      {
        "model_id": "QuantFactory/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/DeepSeek-Coder-V2-Lite-Instruct-GGUF/resolve/main/DeepSeek-Coder-V2-Lite-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 6430464448,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-Coder-V2-Lite-Instruct.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1",
    "label": "Deepseek R1",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 776491,
    "likes": 12617,
    "last_updated": "2025-03-27T04:01:59+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07259528585757273,
      "code": 0.12357142857142857,
      "math": 0.021778585757271818,
      "story": 0.004259528585757272,
      "roleplay": 0.004259528585757272
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "deepseek-ai/DeepSeek-R1-0528",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 688586727753,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 688586727753
      },
      {
        "model_id": "unsloth/DeepSeek-R1-0528-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF/resolve/main/UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00001-of-00016.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 49336101056,
        "notes": null,
        "revision": "main",
        "filename": "UD-Q8_K_XL/DeepSeek-R1-0528-UD-Q8_K_XL-00001-of-00016.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-GGUF/resolve/main/DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 49369575104,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00005.gguf"
      },
      {
        "model_id": "QuixiAI/DeepSeek-R1-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuixiAI/DeepSeek-R1-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 364606492432,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 364606492432
      },
      {
        "model_id": "ubergarm/DeepSeek-R1-0528-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "bartowski/DeepSeek-R1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-GGUF/resolve/main/DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00007.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 39393003104,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00007.gguf"
      },
      {
        "model_id": "QuixiAI/DeepSeek-R1-0528-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuixiAI/DeepSeek-R1-0528-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 364606492432,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 364606492432
      },
      {
        "model_id": "cortexso/deepseek-r1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1/resolve/main/deepseek-r1-distill-qwen-7b-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3015939744,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-7b-q2_k.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-0528-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-0528-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 377607141186,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 377607141186
      },
      {
        "model_id": "calcuis/deepseek-r1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/calcuis/deepseek-r1/resolve/main/DeepSeek-R1-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 16068893408,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-0528-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-GGUF/resolve/main/DeepSeek-R1-0528-Q8_0-00001-of-00020.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 36521680256,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Q8_0-00001-of-00020.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-0528-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-0528-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 713066626803,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 713066626803
      },
      {
        "model_id": "adamo1139/DeepSeek-R1-0528-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/adamo1139/DeepSeek-R1-0528-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 364606492432,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 364606492432
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-GGUF/resolve/main/DeepSeek-R1-Q6_K-00001-of-00015.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 37648655232,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Q6_K-00001-of-00015.gguf"
      },
      {
        "model_id": "kaxap/mlx-DeepSeek-R1-0528-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kaxap/mlx-DeepSeek-R1-0528-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 377607142620,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 377607142620
      },
      {
        "model_id": "tachyphylaxis/DeepSeek-R1-0528-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "XelotX/DeepSeek-R1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/XelotX/DeepSeek-R1-GGUF/resolve/main/DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00007.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 39393003104,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Q2_K/DeepSeek-R1-Q2_K-00001-of-00007.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1"
  },
  {
    "model_id": "microsoft/phi-2",
    "label": "Phi 2",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 763517,
    "likes": 3383,
    "last_updated": "2024-04-29T16:25:56+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22964285714285715,
      "code": 0.11482142857142857,
      "math": 0.02463340020060181,
      "story": 0.0052111334002006016,
      "roleplay": 0.0052111334002006016
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "microsoft/phi-4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/microsoft/phi-4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 29319042992,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29319042992
      },
      {
        "model_id": "TheBloke/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1173610336,
        "notes": null,
        "revision": "main",
        "filename": "phi-2.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/phi-4-GGUF/resolve/main/phi-4.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114464,
        "notes": null,
        "revision": "main",
        "filename": "phi-4.Q4_K_M.gguf"
      },
      {
        "model_id": "unsloth/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8890306112,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114560,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "microsoft/phi-4-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/microsoft/phi-4-gguf/resolve/main/phi-4-Q4_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114560,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K.gguf"
      },
      {
        "model_id": "unsloth/phi-4-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/phi-4-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 9088666199,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 9088666199
      },
      {
        "model_id": "bartowski/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114816,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/phi-4-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/phi-4-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8246633911,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 8246633911
      },
      {
        "model_id": "stelterlab/phi-4-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/phi-4-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 9138087152,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 9138087152
      },
      {
        "model_id": "TheBloke/phi-2-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/phi-2-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1836014976,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/phi-4-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/phi-4-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 15576180399,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15576180399
      },
      {
        "model_id": "Mungert/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/phi-4-GGUF/resolve/main/phi-4-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114912,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-q4_k_m.gguf"
      },
      {
        "model_id": "mlx-community/phi-2-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/phi-2-hf-4bit-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1753456074,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "second-state/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114464,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "GPT4All-Community/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/GPT4All-Community/phi-4-GGUF/resolve/main/phi-4-Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8383418144,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_0.gguf"
      },
      {
        "model_id": "Mungert/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/phi-2-GGUF/resolve/main/phi-2-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5563096288,
        "notes": null,
        "revision": "main",
        "filename": "phi-2-bf16.gguf"
      },
      {
        "model_id": "mlx-community/phi-2",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "cortexso/phi-4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/phi-4/resolve/main/phi-4-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114560,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-q4_k_m.gguf"
      },
      {
        "model_id": "MaziyarPanahi/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/phi-2-GGUF/resolve/main/phi-2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1109719584,
        "notes": null,
        "revision": "main",
        "filename": "phi-2.Q2_K.gguf"
      },
      {
        "model_id": "cortexso/phi-3.5",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/phi-3.5/resolve/main/phi-3.5-mini-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204288,
        "notes": null,
        "revision": "main",
        "filename": "phi-3.5-mini-instruct-q2_k.gguf"
      },
      {
        "model_id": "kroonen/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kroonen/phi-2-GGUF/resolve/main/phi-2_Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2958032672,
        "notes": null,
        "revision": "main",
        "filename": "phi-2_Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/phi-4-GGUF/resolve/main/phi-4.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114464,
        "notes": null,
        "revision": "main",
        "filename": "phi-4.Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/phi-2-GGUF/resolve/main/phi-2-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1109719584,
        "notes": null,
        "revision": "main",
        "filename": "phi-2-Q2_K.gguf"
      },
      {
        "model_id": "afrideva/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/phi-2-GGUF/resolve/main/phi-2.fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5563088672,
        "notes": null,
        "revision": "main",
        "filename": "phi-2.fp16.gguf"
      },
      {
        "model_id": "fmchale/phi-4-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/fmchale/phi-4-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 29319042675,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29319042675
      },
      {
        "model_id": "mlx-community/phi-2-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114464,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "afrideva/phi-2-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/phi-2-chat-GGUF/resolve/main/phi-2-chat.fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5563088672,
        "notes": null,
        "revision": "main",
        "filename": "phi-2-chat.fp16.gguf"
      },
      {
        "model_id": "mav23/phi-1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/phi-1-GGUF/resolve/main/phi-1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 582316992,
        "notes": null,
        "revision": "main",
        "filename": "phi-1.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/phi-4-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/phi-4-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 11911407095,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 11911407095
      },
      {
        "model_id": "professorf/phi-1-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/professorf/phi-1-gguf/resolve/main/phi-1-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2839540096,
        "notes": null,
        "revision": "main",
        "filename": "phi-1-f16.gguf"
      },
      {
        "model_id": "andrijdavid/phi-2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/andrijdavid/phi-2-GGUF/resolve/main/ggml-model-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5563088672,
        "notes": null,
        "revision": "main",
        "filename": "ggml-model-f16.gguf"
      },
      {
        "model_id": "gaianet/phi-4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/phi-4-GGUF/resolve/main/phi-4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 9053114464,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-Q4_K_M.gguf"
      },
      {
        "model_id": "ddh0/phi-2-GGUF-fp16",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Jarrodbarnes/phi-4-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Jarrodbarnes/phi-4-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 29319042675,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29319042675
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/phi-2"
  },
  {
    "model_id": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24",
    "label": "Vikhr Nemo 12B R 21 09 24",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 725507,
    "likes": 126,
    "last_updated": "2024-10-25T11:20:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "vikhr-nemo-12b-r-21-09",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.026105817452357072,
      "math": 0.015663490471414243,
      "story": 0.005221163490471414,
      "roleplay": 0.005221163490471414
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Vikhr-Nemo-12B-Instruct-R-21-09-24-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Vikhr-Nemo-12B-Instruct-R-21-09-24-GGUF/resolve/main/Vikhr-Nemo-12B-Instruct-R-21-09-24-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "Vikhr-Nemo-12B-Instruct-R-21-09-24-Q4_K_M.gguf"
      },
      {
        "model_id": "qilowoq/Vikhr-Nemo-12B-Instruct-R-21-09-24-4Bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/qilowoq/Vikhr-Nemo-12B-Instruct-R-21-09-24-4Bit-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 9.82,
    "ram_recommended_gb": 12.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.82,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 12.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24"
  },
  {
    "model_id": "HuggingFaceH4/zephyr-7b-beta",
    "label": "Zephyr 7B Beta",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 706435,
    "likes": 1757,
    "last_updated": "2024-10-16T11:48:13+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "zephyr-7b-beta",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.024858324974924774,
      "math": 0.014914994984954863,
      "story": 0.004971664994984955,
      "roleplay": 0.004971664994984955
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/zephyr-7B-beta-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880232,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/zephyr-7B-beta-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662096,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/zephyr-7b-beta-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/zephyr-7b-beta-GGUF/resolve/main/zephyr-7b-beta.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-beta.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/zephyr-7b-beta-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/zephyr-7b-beta-GGUF/resolve/main/zephyr-7b-beta-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-beta-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/zephyr-7b-beta",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "second-state/Zephyr-7B-Beta-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Zephyr-7B-Beta-GGUF/resolve/main/zephyr-7b-beta-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-beta-Q2_K.gguf"
      },
      {
        "model_id": "mav23/zephyr-7b-beta-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/zephyr-7b-beta-GGUF/resolve/main/zephyr-7b-beta.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-beta.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/zephyr-7b-beta-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/zephyr-7b-beta-GGUF/resolve/main/zephyr-7b-beta.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-beta.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta"
  },
  {
    "model_id": "Qwen/Qwen2.5-32B-Instruct",
    "label": "Qwen2.5 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 691332,
    "likes": 290,
    "last_updated": "2024-09-25T12:33:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.022426028084252758,
      "math": 0.013455616850551655,
      "story": 0.0044852056168505515,
      "roleplay": 0.0044852056168505515
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-32B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 65527841752,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 65527841752
      },
      {
        "model_id": "Qwen/Qwen2.5-32B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328993904,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328993904
      },
      {
        "model_id": "unsloth/Qwen2.5-32B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-32B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-32B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-32B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-GGUF/resolve/main/qwen2.5-32b-instruct-fp16-00001-of-00017.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3922555904,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-32b-instruct-fp16-00001-of-00017.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-32B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-32B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Gensyn/Qwen2.5-32B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Gensyn/Qwen2.5-32B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-32B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-32B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-32B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-32B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-32B-Instruct-GGUF/resolve/main/qwen2.5-32b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-32b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-32B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-32B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-32B-Instruct-4bit-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-32B-Instruct-4bit-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "DevQuasar/Qwen2.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Qwen2.5-32B-Instruct-GGUF/resolve/main/Qwen2.5-32B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-32B-Instruct.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 24.22,
    "ram_recommended_gb": 30.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 24.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct"
  },
  {
    "model_id": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "label": "Smollm2 360M",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 608674,
    "likes": 138,
    "last_updated": "2025-05-15T11:12:18+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smollm2-360m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2464285714285714,
      "code": 0.022576479438314943,
      "math": 0.013545887662988965,
      "story": 0.004515295887662989,
      "roleplay": 0.004515295887662989
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "HuggingFaceTB/SmolLM2-360M",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 723674912,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/SmolLM2-360M-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/SmolLM2-360M-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 530572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 725553792,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct-f16.gguf"
      },
      {
        "model_id": "Mungert/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 725554272,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct-bf16.gguf"
      },
      {
        "model_id": "lmstudio-community/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 602572800,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 422572800,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "prithivMLmods/SmolLM2-360M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/SmolLM2-360M-GGUF/resolve/main/SmolLM2-360M .F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 725553216,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M .F16.gguf"
      },
      {
        "model_id": "prithivMLmods/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 725553664,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct.F16.gguf"
      },
      {
        "model_id": "Alcoft/SmolLM2-360M-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 725553664,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-360M-Instruct_f16.gguf"
      },
      {
        "model_id": "unsloth/SmolLM2-360M-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/SmolLM2-360M-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 530572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 1.44,
    "ram_recommended_gb": 1.8,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.44,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.36,
    "tier": "high",
    "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct"
  },
  {
    "model_id": "microsoft/Phi-3.5-vision-instruct",
    "label": "Phi 3.5 Vision",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 585835,
    "likes": 702,
    "last_updated": "2024-09-26T22:42:52+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-5-vision",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.11821428571428572,
      "math": 0.02385481444332999,
      "story": 0.0049516048144433306,
      "roleplay": 0.0049516048144433306
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Phi-3.5-vision-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-vision-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2334279041,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2334279041
      },
      {
        "model_id": "onnx-community/Phi-3.5-vision-instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Phi-3.5-vision-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-vision-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4407019904,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4407019904
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct"
  },
  {
    "model_id": "meta-llama/Llama-3.1-70B-Instruct",
    "label": "Llama 3.1 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 524754,
    "likes": 835,
    "last_updated": "2024-12-15T01:55:33+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.020181795386158476,
      "math": 0.012109077231695084,
      "story": 0.004036359077231696,
      "roleplay": 0.004036359077231696
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-3.1-70B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-3.1-70B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Mungert/Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama-3.1-70B-Instruct-GGUF/resolve/main/Llama-3.1-70B-Instruct-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 38814572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-70B-Instruct-q4_0.gguf"
      },
      {
        "model_id": "hierholzer/Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hierholzer/Llama-3.1-70B-Instruct-GGUF/resolve/main/Llama-3.1-70B-Instruct-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 29714572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-70B-Instruct-Q3_K_L.gguf"
      },
      {
        "model_id": "mav23/Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.1-70B-Instruct-GGUF/resolve/main/llama-3.1-70b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-70b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.1-70B-Instruct-GGUF/resolve/main/Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Llama-3.1-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.1-70B-GGUF/resolve/main/llama-3.1-70b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-70b.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2-1.5B-Instruct",
    "label": "Qwen2 1.5B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 514677,
    "likes": 148,
    "last_updated": "2024-06-06T14:36:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22892857142857143,
      "code": 0.020708375125376127,
      "math": 0.012425025075225676,
      "story": 0.004141675025075226,
      "roleplay": 0.004141675025075226
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2-1.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3087467144,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2-1.5B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1614553840,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF/resolve/main/qwen2-1_5b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093666432,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-1_5b-instruct-fp16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-1.5B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2-1.5B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-1.5B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2-1.5B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-1.5B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2-1.5B-Instruct-GGUF/resolve/main/Qwen2-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093666400,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-1.5B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2-1.5B-Instruct-GGUF/resolve/main/Qwen2-1.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2-1.5B-GGUF/resolve/main/Qwen2-1.5B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2-1.5B-Instruct-GGUF/resolve/main/Qwen2-1.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "afrideva/Qwen2-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/Qwen2-1.5B-GGUF/resolve/main/qwen2-1.5b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-1.5b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2-1.5B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-1.5B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2-1.5B-Instruct-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 868628547,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 868628547
      },
      {
        "model_id": "MCZK/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MCZK/Qwen2-1.5B-Instruct-GGUF/resolve/main/Qwen2-1.5B-Instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093666400,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B-Instruct.f16.gguf"
      },
      {
        "model_id": "thesven/Qwen2-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Qwen2-1.5B-Instruct-GGUF/resolve/main/Qwen2-1.5B-Instruct-GGUF-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093666400,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-1.5B-Instruct-GGUF-bf16.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct"
  },
  {
    "model_id": "microsoft/Phi-3-mini-4k-instruct",
    "label": "Phi 3 Mini 4K",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 504823,
    "likes": 1261,
    "last_updated": "2024-09-20T18:09:38+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-mini-4k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.11857142857142858,
      "math": 0.02396013039117352,
      "story": 0.0049867101303911745,
      "roleplay": 0.0049867101303911745
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "kaitchup/Phi-3-mini-4k-instruct-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kaitchup/Phi-3-mini-4k-instruct-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2281459480,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "microsoft/Phi-3-mini-4k-instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2393231072,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-q4.gguf"
      },
      {
        "model_id": "unsloth/Phi-3-mini-4k-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3-mini-4k-instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2264298471,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Phi-3-mini-4k-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3-mini-4k-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 7642192784,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7642192784
      },
      {
        "model_id": "QuantFactory/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1446879616,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct.Q2_K.gguf"
      },
      {
        "model_id": "second-state/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q4.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2318919040,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-Q4.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3-mini-4k-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-mini-4k-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2149696167,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2149696167
      },
      {
        "model_id": "SanctumAI/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Phi-3-mini-4k-instruct-GGUF/resolve/main/phi-3-mini-4k-instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643296704,
        "notes": null,
        "revision": "main",
        "filename": "phi-3-mini-4k-instruct.f16.gguf"
      },
      {
        "model_id": "bartowski/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203264,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Phi-3-mini-4k-instruct-GGUF-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Phi-3-mini-4k-instruct-GGUF-v2/resolve/main/Phi-3-mini-4k-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416202976,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct.Q2_K.gguf"
      },
      {
        "model_id": "Sreenington/Phi-3-mini-4k-instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Sreenington/Phi-3-mini-4k-instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2277203528,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Phi-3-mini-4k-instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Phi-3-mini-4k-instruct-v0.3-GGUF/resolve/main/Phi-3-mini-4k-instruct-v0.3-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15285055808,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-v0.3-f32.gguf"
      },
      {
        "model_id": "leliuga/Phi-3-mini-4k-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/leliuga/Phi-3-mini-4k-instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2264110136,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "brittlewis12/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/Phi-3-mini-4k-instruct-GGUF/resolve/main/phi-3-mini-4k-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203680,
        "notes": null,
        "revision": "main",
        "filename": "phi-3-mini-4k-instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Phi-3-mini-4k-instruct-v0-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3-mini-4k-instruct-v0-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2264298478,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "elysiantech/phi-3-mini-4k-instruct-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/elysiantech/phi-3-mini-4k-instruct-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2279413824,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203712,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-Q2_K.gguf"
      },
      {
        "model_id": "backyardai/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/backyardai/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643295904,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct.F16.gguf"
      },
      {
        "model_id": "mav23/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Phi-3-mini-4k-instruct-GGUF/resolve/main/phi-3-mini-4k-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203712,
        "notes": null,
        "revision": "main",
        "filename": "phi-3-mini-4k-instruct.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3-mini-4k-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-mini-4k-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4060136345,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4060136345
      },
      {
        "model_id": "LiteLLMs/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Phi-3-mini-4k-instruct-GGUF/resolve/main/Q2_K/Q2_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203136,
        "notes": null,
        "revision": "main",
        "filename": "Q2_K/Q2_K-00001-of-00001.gguf"
      },
      {
        "model_id": "gaianet/Phi-3-mini-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643296704,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-mini-4k-instruct-f16.gguf"
      },
      {
        "model_id": "solidrust/Phi-3-mini-4k-instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Phi-3-mini-4k-instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2277171624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "elysiantech/phi-3-mini-4k-instruct-awq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/elysiantech/phi-3-mini-4k-instruct-awq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2277171624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "federicoramos77/Phi-3-mini-4k-instruct-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/federicoramos77/Phi-3-mini-4k-instruct-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 3104916263,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 3104916263
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"
  },
  {
    "model_id": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
    "label": "Qwen3 Coder 30B A3B Mlx 4Bit",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 484721,
    "likes": 2,
    "last_updated": "2025-07-31T14:37:10+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "a3b",
    "quant_bits": 4,
    "canonical_base": "qwen3-coder-30b-a3b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22739010989010988,
      "code": 0.11369505494505494,
      "math": 0.023219157472417252,
      "story": 0.004739719157472418,
      "roleplay": 0.004739719157472418
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-6bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 2,
        "format": null,
        "size_bytes": 7814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "Mungert/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-q4_0.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-q4_0.gguf"
      },
      {
        "model_id": "cpatonn/Qwen3-Coder-30B-A3B-Instruct-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "ubergarm/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ubergarm/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-IQ4_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": 19202716288,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-IQ4_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 15314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "cpatonn/Qwen3-Coder-30B-A3B-Instruct-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "stelterlab/Qwen3-Coder-30B-A3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "bullerwins/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "QuantTrio/Qwen3-Coder-30B-A3B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "cpatonn/Qwen3-Coder-30B-A3B-Instruct-GPTQ-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Userb1az/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Userb1az/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-30B-A3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen3-Coder-30B-A3B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Gallardo994/Qwen3-Coder-30B-A3B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen3-Coder-30B-A3B-Instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Jojoistauchdabei/Qwen3-Coder-30B-A3B-Instruct-INT4",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "NexVeridian/Qwen3-Coder-30B-A3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "AIDXteam/Qwen3-Coder-30B-A3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "NexVeridian/Qwen3-Coder-30B-A3B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "jedisct1/Qwen3-Coder-30B-A3B-Instruct-mlx",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "prithivMLmods/Qwen3-Coder-30B-A3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen3-Coder-30B-A3B-Instruct-GGUF/resolve/main/qwen3-coder-30b-a3b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen3-coder-30b-a3b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "NexVeridian/Qwen3-Coder-30B-A3B-Instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 22814572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "btbtyler09/Qwen3-Coder-30B-A3B-Instruct-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 18314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "btbtyler09/Qwen3-Coder-30B-A3B-Instruct-gptq-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 30314572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 37.18,
    "ram_recommended_gb": 46.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 37.18,
    "quant_class": "a3b-q4",
    "format": "mlx",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit"
  },
  {
    "model_id": "moonshotai/Kimi-K2-Instruct",
    "label": "Kimi K2",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 482632,
    "likes": 2089,
    "last_updated": "2025-08-11T13:45:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "kimi-k2",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.020915245737211634,
      "math": 0.01254914744232698,
      "story": 0.004183049147442327,
      "roleplay": 0.004183049147442327
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Kimi-K2-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Kimi-K2-Instruct-GGUF/resolve/main/BF16/Kimi-K2-Instruct-BF16-00001-of-00045.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 48749343040,
        "notes": null,
        "revision": "main",
        "filename": "BF16/Kimi-K2-Instruct-BF16-00001-of-00045.gguf"
      },
      {
        "model_id": "mlx-community/Kimi-K2-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Kimi-K2-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 577593852668,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 577593852668
      },
      {
        "model_id": "ubergarm/Kimi-K2-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ubergarm/Kimi-K2-Instruct-GGUF/resolve/main/IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00001-of-00006.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 42683801152,
        "notes": null,
        "revision": "main",
        "filename": "IQ1_KT/Kimi-K2-Instruct-IQ1_KT-00001-of-00006.gguf"
      },
      {
        "model_id": "unsloth/Kimi-K2-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Kimi-K2-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 1029190981272,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1029190981272
      },
      {
        "model_id": "bobchenyx/Kimi-K2-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bobchenyx/Kimi-K2-Instruct-GGUF/resolve/main/Kimi-K2-Instruct-Q2_K/Kimi-K2-Instruct-Q2_K-00001-of-00008.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 48408820288,
        "notes": null,
        "revision": "main",
        "filename": "Kimi-K2-Instruct-Q2_K/Kimi-K2-Instruct-Q2_K-00001-of-00008.gguf"
      },
      {
        "model_id": "luisra/Kimi-K2-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/luisra/Kimi-K2-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 533366584080,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 533366584080
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/moonshotai/Kimi-K2-Instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-V3",
    "label": "Deepseek",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 477531,
    "likes": 3952,
    "last_updated": "2025-03-27T04:01:45+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0742753259779338,
      "code": 0.12357142857142857,
      "math": 0.02228259779338014,
      "story": 0.00442753259779338,
      "roleplay": 0.00442753259779338
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "deepseek-ai/DeepSeek-V2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/deepseek-ai/DeepSeek-V2/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 471486512925,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 471486512925
      },
      {
        "model_id": "bullerwins/DeepSeek-V3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3-Q3_K_M/DeepSeek-V3-Q3_K_M-00001-of-00008.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 44186351552,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V3-Q3_K_M/DeepSeek-V3-Q3_K_M-00001-of-00008.gguf"
      },
      {
        "model_id": "QuixiAI/DeepSeek-V3-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuixiAI/DeepSeek-V3-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 351911613368,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 351911613368
      },
      {
        "model_id": "bartowski/DeepSeek-V2.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-V2.5-GGUF/resolve/main/DeepSeek-V2.5-Q2_K/DeepSeek-V2.5-Q2_K-00001-of-00003.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 39806397440,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2.5-Q2_K/DeepSeek-V2.5-Q2_K-00001-of-00003.gguf"
      },
      {
        "model_id": "leafspark/DeepSeek-V2-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/leafspark/DeepSeek-V2-Chat-GGUF/resolve/main/DeepSeek-V2-Chat.bf16.gguf/DeepSeek-V2-Chat.bf16.part-01-of-22.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 21474836480,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2-Chat.bf16.gguf/DeepSeek-V2-Chat.bf16.part-01-of-22.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-V2.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-V2.5-GGUF/resolve/main/DeepSeek-V2.5-Q6_K-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 39241492640,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2.5-Q6_K-00001-of-00005.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-V3"
  },
  {
    "model_id": "deepseek-ai/deepseek-coder-6.7b-base",
    "label": "Deepseek Coder 6.7B Base",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 474531,
    "likes": 115,
    "last_updated": "2024-03-19T03:54:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-coder-6-7b-base",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.078462888665998,
      "code": 0.11446428571428571,
      "math": 0.0235388665997994,
      "story": 0.0048462888665997995,
      "roleplay": 0.0048462888665997995
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/deepseek-coder-6.7B-base-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-base-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5339572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/deepseek-coder-6.7B-base-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-base-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5339572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 7.21,
    "ram_recommended_gb": 9.01,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.21,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 6.7,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base"
  },
  {
    "model_id": "meta-llama/Llama-3.3-70B-Instruct",
    "label": "Llama 3.3 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 453784,
    "likes": 2474,
    "last_updated": "2024-12-21T18:28:01+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23714285714285716,
      "code": 0.023159478435305917,
      "math": 0.01389568706118355,
      "story": 0.004631895687061184,
      "roleplay": 0.004631895687061184
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "kosbu/Llama-3.3-70B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kosbu/Llama-3.3-70B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996256,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996256
      },
      {
        "model_id": "MaziyarPanahi/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Llama-3.3-70B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 29714572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q3_K_L.gguf"
      },
      {
        "model_id": "casperhansen/llama-3.3-70b-instruct-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/casperhansen/llama-3.3-70b-instruct-awq/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996256,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996256
      },
      {
        "model_id": "unsloth/Llama-3.3-70B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.3-70B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 141107497872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497872
      },
      {
        "model_id": "bartowski/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.3-70B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.3-70B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.3-70B-Instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 52814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "hierholzer/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hierholzer/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/llama-3.3-70b-instruct-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/llama-3.3-70b-instruct-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 141107497175,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497175
      },
      {
        "model_id": "XelotX/Llama-3.3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/XelotX/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "furiosa-ai/Llama-3.3-70B-Instruct-INT8",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 51.58,
    "ram_recommended_gb": 64.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 51.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
  },
  {
    "model_id": "microsoft/Phi-4-multimodal-instruct",
    "label": "Phi 4 Multimodal",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 444037,
    "likes": 1469,
    "last_updated": "2025-05-01T15:26:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-4-multimodal",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24714285714285714,
      "code": 0.12357142857142857,
      "math": 0.02229012036108325,
      "story": 0.004430040120361084,
      "roleplay": 0.004430040120361084
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Lexius/Phi-4-multimodal-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Lexius/Phi-4-multimodal-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 11149227208,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 11149227208
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-V3-0324",
    "label": "Deepseek 0324",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 427859,
    "likes": 3033,
    "last_updated": "2025-03-27T04:01:53+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-v3",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07116599799398195,
      "code": 0.12357142857142857,
      "math": 0.021349799398194584,
      "story": 0.004116599799398195,
      "roleplay": 0.004116599799398195
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/DeepSeek-V3-0324-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/DeepSeek-V3-0324-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF/resolve/main/Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00001-of-00009.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 48339780320,
        "notes": null,
        "revision": "main",
        "filename": "Q4_K_M/DeepSeek-V3-0324-Q4_K_M-00001-of-00009.gguf"
      },
      {
        "model_id": "QuixiAI/DeepSeek-V3-0324-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuixiAI/DeepSeek-V3-0324-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 351911613816,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 351911613816
      },
      {
        "model_id": "mlx-community/DeepSeek-V3-0324-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-V3-0324-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 377607111548,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 377607111548
      },
      {
        "model_id": "unsloth/DeepSeek-V3-0324",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-V3-0324/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 1368985513488,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1368985513488
      },
      {
        "model_id": "ubergarm/DeepSeek-V3-0324-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-V3-0324-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-V3-0324-GGUF/resolve/main/DeepSeek-V3-0324-Q4_K_M-00001-of-00011.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 38765709824,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V3-0324-Q4_K_M-00001-of-00011.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-v3-0324-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-v3-0324-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 754999062511,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 754999062511
      },
      {
        "model_id": "jasonyux/DeepSeek-V3-0324-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/jasonyux/DeepSeek-V3-0324-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 351911613816,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 351911613816
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    "label": "Deepseek R1 0528 Qwen3 8B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 368453,
    "likes": 923,
    "last_updated": "2025-05-29T13:13:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-0528-qwen3-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08049398194583751,
      "code": 0.1232142857142857,
      "math": 0.024148194583751253,
      "story": 0.005049398194583752,
      "roleplay": 0.005049398194583752
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "MaziyarPanahi/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-0528-Qwen3-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 16381516824,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16381516824
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-0528-Qwen3-8B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-0528-Qwen3-8B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-0528-Qwen3-8B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-0528-Qwen3-8B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "hxac/DeepSeek-R1-0528-Qwen3-8B-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hxac/DeepSeek-R1-0528-Qwen3-8B-AWQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Sci-fi-vy/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Sci-fi-vy/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "stelterlab/DeepSeek-R1-0528-Qwen3-8B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/DeepSeek-R1-0528-Qwen3-8B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "brittlewis12/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/deepseek-r1-0528-qwen3-8b.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-0528-qwen3-8b.Q8_0.gguf"
      },
      {
        "model_id": "second-state/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf"
      },
      {
        "model_id": "Epistates/deepseek-r1-0528-qwen3-8b-mlx-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Epistates/deepseek-r1-0528-qwen3-8b-mlx-awq/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-0528-Qwen3-8B-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-0528-Qwen3-8B-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 6314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ZeroWw/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ZeroWw/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B.q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B.q8_0.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-R1-0528-Qwen3-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-0528-Qwen3-8B-GGUF/resolve/main/DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-0528-Qwen3-8B-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
  },
  {
    "model_id": "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
    "label": "Meta Llama 3.1 8B Bnb 4Bit",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 412635,
    "likes": 81,
    "last_updated": "2025-02-15T10:31:16+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "meta-llama-3-1-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.0225388665997994,
      "math": 0.013523319959879638,
      "story": 0.00450777331995988,
      "roleplay": 0.00450777331995988
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "context-labs/Meta-Llama-3.1-8B-Instruct-FP16",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/Meta-Llama-3.1-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/meta-llama-3.1-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3.1-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "FriendliAI/Meta-Llama-3.1-8B-Instruct-int8",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ModelCloud/Meta-Llama-3.1-8B-Instruct-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ModelCloud/Meta-Llama-3.1-8B-Instruct-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-8B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bullerwins/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-GGUF/resolve/main/Meta-Llama-3.1-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B.Q8_0.gguf"
      },
      {
        "model_id": "gaianet/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "pek111/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pek111/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "fedric95/Meta-Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/fedric95/Meta-Llama-3.1-8B-GGUF/resolve/main/Meta-Llama-3.1-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Q8_0.gguf"
      },
      {
        "model_id": "aniljava/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/aniljava/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "brittlewis12/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/meta-llama-3.1-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3.1-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-8B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "backyardai/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/backyardai/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "DevQuasar/Meta-Llama-3.1-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "UCLA-EMC/Meta-Llama-3.1-8B-AWQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/UCLA-EMC/Meta-Llama-3.1-8B-AWQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "3Simplex/Meta-Llama-3.1-8B-Instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "fixie-ai/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/fixie-ai/Meta-Llama-3.1-8B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3.1-8B-GGUF/resolve/main/Meta-Llama-3.1-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B-Q8_0.gguf"
      },
      {
        "model_id": "thesven/Meta-Llama-3.1-8B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Meta-Llama-3.1-8B-Instruct-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "paulness/Meta-Llama-3.1-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "shashikanth-a/Meta-Llama-3.1-8B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-8B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-GGUF/resolve/main/Meta-Llama-3.1-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-8B.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit"
  },
  {
    "model_id": "Alibaba-NLP/gte-Qwen2-7B-instruct",
    "label": "Gte Qwen2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 409950,
    "likes": 463,
    "last_updated": "2025-03-24T09:43:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "gte-qwen2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2959560055253925,
      "code": 0.014802914491185435,
      "math": 0.007964419291138171,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct"
  },
  {
    "model_id": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-5bit",
    "label": "Qwen3 Coder 30B A3B Mlx 5Bit",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 361317,
    "likes": 0,
    "last_updated": "2025-08-01T14:33:43+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "canonical_base": "qwen3-coder-30b-a3b-5b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.20142857142857143,
      "code": 0.10071428571428571,
      "math": 0.02467853560682046,
      "story": 0.005226178535606821,
      "roleplay": 0.005226178535606821
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "NexVeridian/Qwen3-Coder-30B-A3B-Instruct-5bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "a3b",
        "quant_bits": 5,
        "format": null,
        "size_bytes": 19064572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-5bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen3-Coder-30B-A3B-Instruct-5bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 5,
        "format": "hf",
        "size_bytes": 19064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 23.68,
    "ram_recommended_gb": 29.6,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 23.68,
    "quant_method": "a3b",
    "quant_bits": 5,
    "quant_class": "a3b-q5",
    "format": "mlx",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-5bit"
  },
  {
    "model_id": "naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B",
    "label": "Hyperclovax Seed Vision 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 354517,
    "likes": 207,
    "last_updated": "2025-07-25T13:36:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hyperclovax-seed-vision-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.3255601735657617,
      "code": 0.011295059574989219,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 6.8,
    "ram_recommended_gb": 8.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 6.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B"
  },
  {
    "model_id": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "label": "Meta Llama 3.1 70B",
    "tags": [
      "awq",
      "chat",
      "cuda",
      "large"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "cuda",
      "int4",
      "large"
    ],
    "dropped_tags": [
      "int4"
    ],
    "downloads": 353940,
    "likes": 104,
    "last_updated": "2024-08-07T07:16:54+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "quant_bits": 4,
    "canonical_base": "meta-llama-3-1-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2328714285714286,
      "code": 0.02261409227683049,
      "math": 0.013568455366098294,
      "story": 0.004522818455366099,
      "roleplay": 0.004522818455366099
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "hugging-quants/Meta-Llama-3.1-70B-Instruct-GPTQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-70B-Instruct-GPTQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Meta-Llama-3.1-70B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "bartowski/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Meta-Llama-3.1-70B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-70B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-70B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-70B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "backyardai/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/backyardai/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct.IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 16751196320,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct.IQ1_M.gguf"
      },
      {
        "model_id": "bullerwins/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-70B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-70B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "DevQuasar/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "shuyuej/Meta-Llama-3.1-70B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shuyuej/Meta-Llama-3.1-70B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39792965496,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ThomasBaruzier/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-70B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-70B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "gaianet/Meta-Llama-3.1-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "fsaudm/Meta-Llama-3.1-70B-Instruct-INT8",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 85.18,
    "ram_recommended_gb": 106.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 85.18,
    "format": "awq",
    "quant_class": "awq-q4",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4"
  },
  {
    "model_id": "bigcode/starcoder2-3b",
    "label": "Starcoder2 3B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 342437,
    "likes": 202,
    "last_updated": "2024-03-04T13:33:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "starcoder2-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07020060180541625,
      "code": 0.11446428571428571,
      "math": 0.021060180541624875,
      "story": 0.004020060180541625,
      "roleplay": 0.004020060180541625
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/StarCoder2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/StarCoder2-3B-GGUF/resolve/main/starcoder2-3b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-Q2_K.gguf"
      },
      {
        "model_id": "TechxGenus/starcoder2-3b-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/starcoder2-3b-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2102272504,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/starcoder2-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/starcoder2-3b-GGUF/resolve/main/starcoder2-3b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/starcoder2-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/starcoder2-3b-GGUF/resolve/main/starcoder2-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/starcoder2-3b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/starcoder2-3b-instruct-GGUF/resolve/main/starcoder2-3b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "nold/starcoder2-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nold/starcoder2-3b-GGUF/resolve/main/starcoder2-3b_Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b_Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/starcoder2-3b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/starcoder2-3b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/starcoder2-3b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/starcoder2-3b-instruct-GGUF/resolve/main/starcoder2-3b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/starcoder2-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/starcoder2-3b-GGUF/resolve/main/starcoder2-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b.Q2_K.gguf"
      },
      {
        "model_id": "ysn-rfd/starcoder2-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ysn-rfd/starcoder2-3b-GGUF/resolve/main/starcoder2-3b-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1964572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-q4_0.gguf"
      },
      {
        "model_id": "TechxGenus/starcoder2-3b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/starcoder2-3b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 6060796768,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6060796768
      },
      {
        "model_id": "flyingfishinwater/starcoder2-3b-instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/flyingfishinwater/starcoder2-3b-instruct-gguf/resolve/main/starcoder2-3b-instruct-gguf_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6064559200,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-3b-instruct-gguf_f16.gguf"
      }
    ],
    "ram_estimate_gb": 2.98,
    "ram_recommended_gb": 3.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bigcode/starcoder2-3b"
  },
  {
    "model_id": "lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-6bit",
    "label": "Qwen3 Coder 480B A35B Mlx 6Bit",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 324069,
    "likes": 2,
    "last_updated": "2025-07-23T02:08:14+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "mlx",
    "quant_bits": 6,
    "canonical_base": "qwen3-coder-480b-a35b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22739010989010988,
      "code": 0.11369505494505494,
      "math": 0.0229746740220662,
      "story": 0.004658224674022066,
      "roleplay": 0.004658224674022066
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 240314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 480314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 149716201312,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-480B-A35B-Instruct-UD-IQ1_M.gguf"
      },
      {
        "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/Qwen3-Coder-480B-A35B-Instruct-Q6_K-00001-of-00011.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 384314572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-Coder-480B-A35B-Instruct-Q6_K-00001-of-00011.gguf"
      },
      {
        "model_id": "mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 240314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ubergarm/Qwen3-Coder-480B-A35B-Instruct-GGUF/resolve/main/IQ3_K/Qwen3-480B-A35B-Instruct-IQ3_K-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 46732971488,
        "notes": null,
        "revision": "main",
        "filename": "IQ3_K/Qwen3-480B-A35B-Instruct-IQ3_K-00001-of-00005.gguf"
      },
      {
        "model_id": "QuantTrio/Qwen3-Coder-480B-A35B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantTrio/Qwen3-Coder-480B-A35B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 252321934880,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 252321934880
      },
      {
        "model_id": "TechxGenus/Qwen3-Coder-480B-A35B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Qwen3-Coder-480B-A35B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 261573260408,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 261573260408
      },
      {
        "model_id": "phatvo/Qwen3-Coder-480B-A35B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/phatvo/Qwen3-Coder-480B-A35B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 250454381384,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 250454381384
      }
    ],
    "ram_estimate_gb": 289.18,
    "ram_recommended_gb": 361.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 289.18,
    "format": "mlx",
    "quant_class": "mlx-q6",
    "size_hint": "70B",
    "params_b": 480.0,
    "tier": "high",
    "model_url": "https://huggingface.co/lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-6bit"
  },
  {
    "model_id": "openchat/openchat-3.5-1210",
    "label": "Openchat 3.5 1210",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 314032,
    "likes": 279,
    "last_updated": "2024-05-18T18:10:44+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "open-3-5",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22892857142857143,
      "code": 0.02535356068204614,
      "math": 0.015212136409227682,
      "story": 0.005070712136409228,
      "roleplay": 0.005070712136409228
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "openchat/openchat-3.5-0106",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/openchat/openchat-3.5-0106/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14483530784,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14483530784
      },
      {
        "model_id": "TheBloke/openchat-3.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-1210-GGUF/resolve/main/openchat-3.5-1210.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3083107552,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-1210.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat-3.5-0106-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-0106-GGUF/resolve/main/openchat-3.5-0106.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5942078624,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-0106.Q6_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat-3.5-0106-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-0106-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 4158695048,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/OpenChat-3.5-0106-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/OpenChat-3.5-0106-GGUF/resolve/main/openchat-3.5-0106-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5943014912,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-0106-Q6_K.gguf"
      },
      {
        "model_id": "zeio/openchat-3.5-0106-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/zeio/openchat-3.5-0106-GGUF/resolve/main/openchat-3.5-0106.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5942078624,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-0106.Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/openchat-3.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/openchat-3.5-1210-GGUF/resolve/main/openchat-3.5-1210-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2719252768,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-1210-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/openchat-3.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/openchat-3.5-1210-GGUF/resolve/main/openchat-3.5-1210.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2719251648,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-1210.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat-3.5-1210-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-1210-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158695048,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/openchat-3.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/openchat-3.5-1210-GGUF/resolve/main/openchat-3.5-1210-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3083107520,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-1210-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/openchat-3.5-0106-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/openchat-3.5-0106-GGUF/resolve/main/openchat-3.5-0106-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5942079392,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.5-0106-Q6_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat-3.5-1210-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-1210-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150913000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ysn-rfd/openchat-3.5-0106-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "TheBloke/openchat-3.5-0106-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat-3.5-0106-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 4150913000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/openchat/openchat-3.5-1210"
  },
  {
    "model_id": "Qwen/Qwen2-7B-Instruct",
    "label": "Qwen2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 280723,
    "likes": 661,
    "last_updated": "2024-08-21T10:29:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.021799147442326982,
      "math": 0.013079488465396189,
      "story": 0.0043598294884653966,
      "roleplay": 0.0043598294884653966
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271872
      },
      {
        "model_id": "Qwen/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct-GGUF/resolve/main/qwen2-7b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237850688,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-7b-instruct-fp16.gguf"
      },
      {
        "model_id": "unsloth/Qwen2-7B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-7B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2-7B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-7B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2-7B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5570829760,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5570829760
      },
      {
        "model_id": "Qwen/Qwen2-7B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2-7B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2-7B-Instruct-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4284346187,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4284346187
      },
      {
        "model_id": "second-state/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237850656,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2-7B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-7B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2-7B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-7B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 30468417056,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct-f32.gguf"
      },
      {
        "model_id": "GPT4All-Community/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/GPT4All-Community/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7b-Instruct-Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7b-Instruct-Q4_0.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "fedric95/Qwen2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/fedric95/Qwen2-7B-GGUF/resolve/main/Qwen2-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2-7B-GGUF/resolve/main/Qwen2-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B.Q2_K.gguf"
      },
      {
        "model_id": "MoMonir/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MoMonir/Qwen2-7B-Instruct-GGUF/resolve/main/qwen2-7b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237850656,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-7b-instruct-fp16.gguf"
      },
      {
        "model_id": "DevQuasar/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2-7B-Instruct-GGUF/resolve/main/qwen2-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2-7B-GGUF/resolve/main/qwen2-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-7b.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2-7B-Instruct-GGUF/resolve/main/Qwen2-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237850656,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-7B-Instruct-f16.gguf"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "label": "Deepseek R1 Distill Llama 70B",
    "tags": [
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 275365,
    "likes": 714,
    "last_updated": "2025-02-24T03:31:15+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-llama-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07025075225677031,
      "code": 0.1232142857142857,
      "math": 0.021075225677031094,
      "story": 0.004025075225677031,
      "roleplay": 0.004025075225677031
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-70B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Llama-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Llama-70B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Llama-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Llama-70B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-70B-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 29714572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-70B-Q3_K_L.gguf"
      },
      {
        "model_id": "Valdemardi/DeepSeek-R1-Distill-Llama-70B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Valdemardi/DeepSeek-R1-Distill-Llama-70B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996432,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996432
      },
      {
        "model_id": "empirischtech/DeepSeek-R1-Distill-Llama-70B-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/empirischtech/DeepSeek-R1-Distill-Llama-70B-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Llama-70B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Llama-70B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Llama-70B-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Llama-70B-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 52814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Llama-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Llama-70B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf"
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-llama-70b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-llama-70b/resolve/main/deepseek-r1-distill-llama-70b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 38814572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-llama-70b-q4_k_m.gguf"
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Llama-70B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 141107497606,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497606
      },
      {
        "model_id": "gaianet/DeepSeek-R1-Distill-Llama-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-R1-Distill-Llama-70B-GGUF/resolve/main/DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Llama-70B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 51.58,
    "ram_recommended_gb": 64.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 51.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "label": "Qwen2.5 Coder 7B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 262807,
    "likes": 525,
    "last_updated": "2025-01-12T02:03:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-coder-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.11821428571428572,
      "math": 0.02188014042126379,
      "story": 0.0042933801404212634,
      "roleplay": 0.0042933801404212634
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5570829760,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5570829760
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/qwen2.5-coder-7b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853184,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b-instruct-fp16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271864
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853696,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-7B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-7B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-7B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853696,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853696,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-7B-GGUF/resolve/main/Qwen2.5-Coder-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B.Q2_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853696,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-F16.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-7B-GGUF/resolve/main/Qwen2.5-Coder-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Q2_K.gguf"
      },
      {
        "model_id": "ikw/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ikw/Qwen2.5-Coder-7B-GGUF/resolve/main/qwen2.5-coder-7b-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b-q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "lokeessshhhh/qwen2.5-coder-7b-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lokeessshhhh/qwen2.5-coder-7b-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "kolosal/qwen2.5-coder-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kolosal/qwen2.5-coder-7b/resolve/main/qwen2.5-coder-7b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853184,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b-instruct-fp16.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-7B-GGUF/resolve/main/qwen2.5-coder-7b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b.Q6_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/qwen2.5-coder-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853152,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct.F16.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-Coder-7B-GGUF/resolve/main/qwen2.5-coder-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-7B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-7B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "DevQuasar/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-7B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-7B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Alcoft/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853120,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct_f16.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-7B-GGUF/resolve/main/Qwen2.5-Coder-7B.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237850592,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B.F16.gguf"
      },
      {
        "model_id": "Orion-zhen/Qwen2.5-Coder-7B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Orion-zhen/Qwen2.5-Coder-7B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5698276920,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5698276920
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-Coder-7B-GGUF/resolve/main/Qwen2.5-Coder-7B.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B.Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-7B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-7B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ALYTV/Qwen2.5-Coder-7B-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ALYTV/Qwen2.5-Coder-7B-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-7B-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-7B-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/qwen2.5-coder-7b-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-7b-instruct.Q6_K.gguf"
      },
      {
        "model_id": "alexgusevski/Qwen2.5-Coder-7B-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alexgusevski/Qwen2.5-Coder-7B-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 15231271443,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271443
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct"
  },
  {
    "model_id": "GSAI-ML/LLaDA-8B-Instruct",
    "label": "Llada 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 258444,
    "likes": 309,
    "last_updated": "2025-02-27T02:50:10+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llada-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2464285714285714,
      "code": 0.023090521564694082,
      "math": 0.013854312938816449,
      "story": 0.004618104312938817,
      "roleplay": 0.004618104312938817
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mlx-community/LLaDA-8B-Instruct-mlx-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/LLaDA-8B-Instruct-mlx-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/LLaDA-8B-Instruct-mlx-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/LLaDA-8B-Instruct-mlx-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mrdmnd/llada-8b-instruct-4bit-gptq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mrdmnd/llada-8b-instruct-4bit-gptq/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/LLaDA-8B-Instruct-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/LLaDA-8B-Instruct-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16031193413,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16031193413
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct"
  },
  {
    "model_id": "codellama/CodeLlama-7b-Instruct-hf",
    "label": "Codellama 7B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 238474,
    "likes": 241,
    "last_updated": "2024-04-12T14:18:42+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22892857142857143,
      "code": 0.11446428571428571,
      "math": 0.022372868605817452,
      "story": 0.004457622868605818,
      "roleplay": 0.004457622868605818
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "codellama/CodeLlama-7b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 13477127208,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 13477127208
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-GGUF/resolve/main/codellama-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896976872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/codellama-7b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codellama-7b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889653656,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "DevShubham/Codellama-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevShubham/Codellama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K-008.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b-instruct.Q2_K-008.gguf"
      },
      {
        "model_id": "QuantFactory/CodeLlama-7b-Instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/CodeLlama-7b-Instruct-hf-GGUF/resolve/main/CodeLlama-7b-Instruct-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-7b-Instruct-hf.Q2_K.gguf"
      },
      {
        "model_id": "javiergtzr/CodeLlama-7b-Instruct-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/javiergtzr/CodeLlama-7b-Instruct-hf-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-mlx",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/CodeLlama-7b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-7b-hf-GGUF/resolve/main/CodeLlama-7b-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-7b-hf-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Instruct-hf-4bit-mlx-2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Instruct-hf-4bit-mlx-2/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896976872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Instruct-hf-4bit-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Instruct-hf-4bit-MLX/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "kirstus/CodeLlama-7b-Instruct-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kirstus/CodeLlama-7b-Instruct-hf/resolve/main/ggml/f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 13479340832,
        "notes": null,
        "revision": "main",
        "filename": "ggml/f16.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Instruct-hf-6bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Instruct-hf-6bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Instruct-hf-8bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Instruct-hf-8bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/CodeLlama-7b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/CodeLlama-7b-hf-GGUF/resolve/main/CodeLlama-7b-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-7b-hf.Q2_K.gguf"
      },
      {
        "model_id": "cmarkea/CodeLlama-7b-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cmarkea/CodeLlama-7b-hf-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mav23/CodeLlama-7b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/CodeLlama-7b-hf-GGUF/resolve/main/codellama-7b-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b-hf.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-hf-4bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "shashikanth-a/codellama-7b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shashikanth-a/codellama-7b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889653656,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ipetrukha/CodeLlama-7b-Instruct-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ipetrukha/CodeLlama-7b-Instruct-hf-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "label": "Deepseek R1 Distill Qwen 14B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 236458,
    "likes": 548,
    "last_updated": "2025-02-24T03:31:45+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-qwen-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07960381143430291,
      "code": 0.1232142857142857,
      "math": 0.023881143430290873,
      "story": 0.004960381143430292,
      "roleplay": 0.004960381143430292
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "stelterlab/DeepSeek-R1-Distill-Qwen-14B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/DeepSeek-R1-Distill-Qwen-14B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/DeepSeek-R1-Distill-Qwen-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "willcb/DeepSeek-R1-Distill-Qwen-14B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/willcb/DeepSeek-R1-Distill-Qwen-14B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 29540133960,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133960
      },
      {
        "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-14B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/DeepSeek-R1-Distill-Qwen-14B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Qwen-14B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 29540133297,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133297
      },
      {
        "model_id": "cortexso/deepseek-r1-distill-qwen-14b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/deepseek-r1-distill-qwen-14b/resolve/main/deepseek-r1-distill-qwen-14b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-r1-distill-qwen-14b-q4_k_m.gguf"
      },
      {
        "model_id": "second-state/DeepSeek-R1-Distill-Qwen-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "Fmuaddib/DeepSeek-R1-Distill-Qwen-14B-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Fmuaddib/DeepSeek-R1-Distill-Qwen-14B-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 29540133287,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133287
      },
      {
        "model_id": "Fmuaddib/DeepSeek-R1-Distill-Qwen-14B-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Fmuaddib/DeepSeek-R1-Distill-Qwen-14B-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 11.26,
    "ram_recommended_gb": 14.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 11.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
  },
  {
    "model_id": "microsoft/Phi-3.5-mini-instruct",
    "label": "Phi 3.5 Mini",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 229679,
    "likes": 902,
    "last_updated": "2025-03-02T22:27:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-5-mini",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2464285714285714,
      "code": 0.1232142857142857,
      "math": 0.024001504513540623,
      "story": 0.005000501504513541,
      "roleplay": 0.005000501504513541
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204512,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Phi-3.5-mini-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3.5-mini-instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2264298476,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Phi-3.5-mini-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3.5-mini-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 7642192784,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7642192784
      },
      {
        "model_id": "bartowski/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15285057024,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-f32.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3.5-mini-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-mini-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2149696133,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2149696133
      },
      {
        "model_id": "SanctumAI/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SanctumAI/Phi-3.5-mini-instruct-GGUF/resolve/main/phi-3.5-mini-instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297280,
        "notes": null,
        "revision": "main",
        "filename": "phi-3.5-mini-instruct.f16.gguf"
      },
      {
        "model_id": "thesven/Phi-3.5-mini-instruct-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Phi-3.5-mini-instruct-GPTQ-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2281459480,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297280,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204288,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct.Q2_K.gguf"
      },
      {
        "model_id": "codegood/Phi_3.5_mini_GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/codegood/Phi_3.5_mini_GGUF/resolve/main/Phi3_mini_instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297280,
        "notes": null,
        "revision": "main",
        "filename": "Phi3_mini_instruct-F16.gguf"
      },
      {
        "model_id": "tensorblock/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204288,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297280,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-f16.gguf"
      },
      {
        "model_id": "LoneStriker/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 3135853056,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3.5-mini-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-mini-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4060136333,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4060136333
      },
      {
        "model_id": "GPT4All-Community/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/GPT4All-Community/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 3135853056,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-mini-instruct-Q6_K.gguf"
      },
      {
        "model_id": "mav23/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Phi-3.5-mini-instruct-GGUF/resolve/main/phi-3.5-mini-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416204288,
        "notes": null,
        "revision": "main",
        "filename": "phi-3.5-mini-instruct.Q2_K.gguf"
      },
      {
        "model_id": "NexesQuants/Phi-3.5-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/NexesQuants/Phi-3.5-mini-instruct-GGUF/resolve/main/phi-3.5-mini-instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643297280,
        "notes": null,
        "revision": "main",
        "filename": "phi-3.5-mini-instruct-bf16.gguf"
      },
      {
        "model_id": "federicoramos77/Phi-3.5-mini-instruct-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/federicoramos77/Phi-3.5-mini-instruct-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 3104916263,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 3104916263
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-1.5B",
    "label": "Qwen2.5 Coder 1.5B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 218061,
    "likes": 60,
    "last_updated": "2024-11-18T12:53:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-coder-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0808074222668004,
      "code": 0.11821428571428572,
      "math": 0.02424222668004012,
      "story": 0.005080742226680041,
      "roleplay": 0.005080742226680041
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3087467144,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-1.5B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-1.5B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-1.5b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b-instruct-q2_k.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-1.5B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-1.5B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1614553840,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-1.5B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-1.5B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-1.5B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-1.5B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-1.5B-GGUF/resolve/main/Qwen2.5-Coder-1.5B.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093666368,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B.F16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-1.5B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-1.5B-GGUF/resolve/main/Qwen2.5-Coder-1.5B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-1.5B-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Q2_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669440,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-F16.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "ikw/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ikw/Qwen2.5-Coder-1.5B-GGUF/resolve/main/qwen2.5-coder-1.5b-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b-q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-Coder-1.5B-GGUF/resolve/main/Qwen2.5-Coder-1.5B.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B.Q6_K.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-1.5b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "mav23/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-Coder-1.5B-GGUF/resolve/main/qwen2.5-coder-1.5b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-1.5B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-1.5B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "kolosal/qwen2.5-coder-1.5b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kolosal/qwen2.5-coder-1.5b/resolve/main/Qwen2.5-Coder-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "Alcoft/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093668896,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093668896,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct.F16.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3093669376,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-1.5B-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-1.5B-GGUF/resolve/main/qwen2.5-coder-1.5b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b.Q6_K.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-1.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-1.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-1.5b-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-1.5b-instruct.Q6_K.gguf"
      },
      {
        "model_id": "DevQuasar/Qwen2.5-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Qwen2.5-Coder-1.5B-GGUF/resolve/main/Qwen2.5-Coder-1.5B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 764572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-1.5B.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-1.5B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-1.5B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B"
  },
  {
    "model_id": "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct",
    "label": "Exaone 3.5 7.8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 200927,
    "likes": 131,
    "last_updated": "2024-12-11T07:01:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "exaone-3-5-7-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23642857142857143,
      "code": 0.024864593781344032,
      "math": 0.014918756268806418,
      "story": 0.004972918756268807,
      "roleplay": 0.004972918756268807
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "bartowski/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "second-state/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "furiosa-ai/EXAONE-3.5-7.8B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "QuantFactory/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "gaianet/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "ThomasBaruzier/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/EXAONE-3.5-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/EXAONE-3.5-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.5-7.8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-7.8B-Instruct.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.54,
    "ram_recommended_gb": 13.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.8,
    "tier": "high",
    "model_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct"
  },
  {
    "model_id": "microsoft/Phi-4-mini-instruct",
    "label": "Phi 4 Mini",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 199709,
    "likes": 579,
    "last_updated": "2025-05-01T15:27:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-4-mini",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.1219642857142857,
      "math": 0.021060180541624875,
      "story": 0.004020060180541625,
      "roleplay": 0.004020060180541625
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874624,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "iqbalamo93/Phi-4-mini-instruct-GPTQ-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/iqbalamo93/Phi-4-mini-instruct-GPTQ-8bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4528609448,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874272,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "unsloth/Phi-4-mini-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-4-mini-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 7672066216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7672066216
      },
      {
        "model_id": "mlx-community/Phi-4-mini-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-4-mini-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2158100796,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2158100796
      },
      {
        "model_id": "unsloth/Phi-4-mini-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-4-mini-instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2891584764,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Phi-4-mini-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-4-mini-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4076012072,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4076012072
      },
      {
        "model_id": "Mungert/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874912,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "lmstudio-community/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874400,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "pytorch/Phi-4-mini-instruct-INT8-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pytorch/Phi-4-mini-instruct-INT8-INT4/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 4812014346,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "gaianet/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874624,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874624,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "pytorch/Phi-4-mini-instruct-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pytorch/Phi-4-mini-instruct-INT4/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "int",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 2941004562,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "tensorblock/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-4-mini-instruct-GGUF/resolve/main/Phi-4-mini-instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2491874624,
        "notes": null,
        "revision": "main",
        "filename": "Phi-4-mini-instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "sdanzo/Phi-4-mini-instruct-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/sdanzo/Phi-4-mini-instruct-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2158100796,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2158100796
      },
      {
        "model_id": "mlx-community/Phi-4-mini-instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-4-mini-instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 3117056452,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 3117056452
      },
      {
        "model_id": "ysn-rfd/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ysn-rfd/Phi-4-mini-instruct-GGUF/resolve/main/phi-4-mini-instruct-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2325151040,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-mini-instruct-q4_0.gguf"
      },
      {
        "model_id": "Melvin56/Phi-4-mini-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Melvin56/Phi-4-mini-instruct-GGUF/resolve/main/phi-4-mini-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 3155623520,
        "notes": null,
        "revision": "main",
        "filename": "phi-4-mini-instruct-Q6_K.gguf"
      },
      {
        "model_id": "pcuenq/Phi-4-mini-instruct-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pcuenq/Phi-4-mini-instruct-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2158101119,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2158101119
      },
      {
        "model_id": "pcuenq/Phi-4-mini-instruct-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/pcuenq/Phi-4-mini-instruct-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4076012395,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4076012395
      },
      {
        "model_id": "alexgusevski/Phi-4-mini-instruct-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alexgusevski/Phi-4-mini-instruct-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7672065971,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7672065971
      },
      {
        "model_id": "iqbalamo93/Phi-4-mini-instruct-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/iqbalamo93/Phi-4-mini-instruct-GPTQ-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2905413520,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-4-mini-instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-3B-Instruct",
    "label": "Qwen2.5 Coder 3B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 192605,
    "likes": 70,
    "last_updated": "2025-01-12T02:04:23+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-coder-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.11696428571428572,
      "math": 0.024528084252758278,
      "story": 0.0051760280842527585,
      "roleplay": 0.0051760280842527585
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-Coder-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 6171927000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6171927000
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-3B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 2686704624,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/qwen2.5-coder-3b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6800646592,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b-instruct-fp16.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-3B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-3B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-3B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-3B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-3B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317280,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317280,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317280,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-3B-GGUF/resolve/main/Qwen2.5-Coder-3B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317120,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-3B-GGUF/resolve/main/Qwen2.5-Coder-3B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-3B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-3B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-3B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-3B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178317280,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-F16.gguf"
      },
      {
        "model_id": "ikw/Qwen2.5-Coder-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ikw/Qwen2.5-Coder-3B-GGUF/resolve/main/qwen2.5-coder-3b-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b-q8_0.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-3B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "kolosal/qwen2.5-coder-3b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kolosal/qwen2.5-coder-3b/resolve/main/qwen2.5-coder-3b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6800646592,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b-instruct-fp16.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/qwen2.5-coder-3b-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b-instruct.Q6_K.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-3B-GGUF/resolve/main/Qwen2.5-Coder-3B.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178316608,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B.F16.gguf"
      },
      {
        "model_id": "prithivMLmods/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6178316736,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct.F16.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-3B-GGUF/resolve/main/qwen2.5-coder-3b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b.Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-3B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-3B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "matrixportalx/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/matrixportalx/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/qwen2.5-coder-3b-instruct-q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-3b-instruct-q6_k.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-3B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-3B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-3B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-3B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "alexgusevski/Qwen2.5-Coder-3B-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alexgusevski/Qwen2.5-Coder-3B-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6171926430,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6171926430
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-Coder-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2.5-Coder-3B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-3B-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-3B-Instruct.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.34,
    "ram_recommended_gb": 4.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.34,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct"
  },
  {
    "model_id": "microsoft/Phi-3.5-MoE-instruct",
    "label": "Phi 3.5",
    "tags": [
      "chat",
      "code",
      "hf",
      "moe"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "moe"
    ],
    "dropped_tags": [],
    "downloads": 185949,
    "likes": 560,
    "last_updated": "2025-03-07T23:26:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-5-moe",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.1219642857142857,
      "math": 0.02370812437311936,
      "story": 0.00490270812437312,
      "roleplay": 0.00490270812437312
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/Phi-3.5-MoE-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-3.5-MoE-instruct-GGUF/resolve/main/Phi-3.5-MoE-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15265136192,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-MoE-instruct-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Phi-3.5-MoE-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Phi-3.5-MoE-instruct-GGUF/resolve/main/Phi-3.5-MoE-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15265136480,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-MoE-instruct-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Phi-3.5-MoE-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Phi-3.5-MoE-instruct-GGUF/resolve/main/Phi-3.5-MoE-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 34359334464,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-MoE-instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3.5-MoE-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-MoE-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 23555055791,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 23555055791
      },
      {
        "model_id": "tensorblock/Phi-3.5-MoE-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-3.5-MoE-instruct-GGUF/resolve/main/Phi-3.5-MoE-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15265136192,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-MoE-instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Phi-3.5-MoE-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3.5-MoE-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 44491186655,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 44491186655
      },
      {
        "model_id": "gaianet/Phi-3.5-MoE-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-3.5-MoE-instruct-GGUF/resolve/main/Phi-3.5-MoE-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15265136192,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3.5-MoE-instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct"
  },
  {
    "model_id": "Qwen/Qwen-7B-Chat",
    "label": "Qwen 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 185571,
    "likes": 782,
    "last_updated": "2024-03-19T10:09:52+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22642857142857142,
      "code": 0.02374247743229689,
      "math": 0.014245486459378134,
      "story": 0.004748495486459378,
      "roleplay": 0.004748495486459378
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15442677288,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15442677288
      },
      {
        "model_id": "Qwen/Qwen-7B-Chat-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen-7B-Chat-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "int",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen-7B-Chat-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen-7B-Chat-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/Qwen-7B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Qwen-7B-Chat-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5860657816,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5860657816
      },
      {
        "model_id": "TheBloke/Qwen-7B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Qwen-7B-Chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5855188096,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Xorbits/Qwen-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Xorbits/Qwen-7B-Chat-GGUF/resolve/main/Qwen-7B-Chat.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen-7B-Chat.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 5.8,
    "ram_recommended_gb": 7.25,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen-7B-Chat"
  },
  {
    "model_id": "meta-llama/Llama-2-13b-chat-hf",
    "label": "Llama 2 13B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 182093,
    "likes": 1093,
    "last_updated": "2024-04-17T08:40:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-2-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.02470787362086259,
      "math": 0.014824724172517553,
      "story": 0.004941574724172518,
      "roleplay": 0.004941574724172518
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-2-13b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-2-13b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-13b-chat.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7247987312,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259449480,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-GGUF/resolve/main/llama-2-13b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-13b.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259449480,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/llama-2-13b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-2-13b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-13B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-13B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7247987312,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "4bit/Llama-2-13b-chat-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/4bit/Llama-2-13b-chat-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-2-13B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-2-13B-Chat-GGUF/resolve/main/Llama-2-13b-chat-hf-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 26033304352,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-13b-chat-hf-f16.gguf"
      },
      {
        "model_id": "tensorblock/Llama-2-13b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-2-13b-chat-hf-GGUF/resolve/main/Llama-2-13b-chat-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-13b-chat-hf-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-2-13b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-2-13b-hf-GGUF/resolve/main/Llama-2-13b-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-13b-hf-Q2_K.gguf"
      },
      {
        "model_id": "compressed-llm/llama-2-13b-chat-gptq",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "compressed-llm/llama-2-13b-gptq",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "QuantFactory/Llama-2-13b-chat-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-2-13b-chat-hf-GGUF/resolve/main/Llama-2-13b-chat-hf.Q4_1.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 7464572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-2-13b-chat-hf.Q4_1.gguf"
      },
      {
        "model_id": "compressed-llm/llama-2-13b-chat-awq",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Peeepy/llama-2-13b-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Peeepy/llama-2-13b-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "zohaib99k/Llama-2-13B-chat-8bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/zohaib99k/Llama-2-13B-chat-8bit-GPTQ/resolve/main/gptq_model-8bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-8bit-128g.safetensors"
      },
      {
        "model_id": "localmodels/Llama-2-13B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/localmodels/Llama-2-13B-GPTQ/resolve/main/gptq_model-4bit-128g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-128g.safetensors"
      }
    ],
    "ram_estimate_gb": 10.54,
    "ram_recommended_gb": 13.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf"
  },
  {
    "model_id": "Qwen/QwQ-32B",
    "label": "Qwq 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 170919,
    "likes": 2823,
    "last_updated": "2025-03-11T12:15:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwq-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.245,
      "code": 0.02504012036108325,
      "math": 0.01502407221664995,
      "story": 0.00500802407221665,
      "roleplay": 0.00500802407221665
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/QwQ-32B-GGUF/resolve/main/QwQ-32B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/QwQ-32B-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/QwQ-32B-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/QwQ-32B-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/QwQ-32B-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/QwQ-32B-GGUF/resolve/main/qwq-32b-q5_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 5,
        "format": "gguf",
        "size_bytes": 22714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwq-32b-q5_0.gguf"
      },
      {
        "model_id": "Qwen/QwQ-32B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/QwQ-32B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328993904,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328993904
      },
      {
        "model_id": "lmstudio-community/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/QwQ-32B-GGUF/resolve/main/QwQ-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Q6_K.gguf"
      },
      {
        "model_id": "unsloth/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/QwQ-32B-GGUF/resolve/main/QwQ-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Q2_K.gguf"
      },
      {
        "model_id": "Mungert/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/QwQ-32B-GGUF/resolve/main/QwQ-32B-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 17914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-q4_0.gguf"
      },
      {
        "model_id": "unsloth/QwQ-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/QwQ-32B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 65527841688,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 65527841688
      },
      {
        "model_id": "clowman/QwQ-32B-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/QwQ-32B-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/QwQ-32B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/QwQ-32B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "kaitchup/QwQ-32B-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kaitchup/QwQ-32B-AWQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/QwQ-32B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/QwQ-32B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/QwQ-32B-GGUF/resolve/main/QwQ-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Q2_K.gguf"
      },
      {
        "model_id": "clowman/QwQ-32B-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/QwQ-32B-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "brittlewis12/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/QwQ-32B-GGUF/resolve/main/qwq-32b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwq-32b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/QwQ-32B-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 24314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/QwQ-32B-GGUF/resolve/main/QwQ-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/QwQ-32B-GGUF/resolve/main/QwQ-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 20.38,
    "ram_recommended_gb": 25.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 20.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/QwQ-32B"
  },
  {
    "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-64k-GGUF",
    "label": "Llama 3 8B 64K",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 152952,
    "likes": 13,
    "last_updated": "2024-04-25T19:58:11+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "llama-3-8b-64k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.30450549166686874,
      "code": 0.02236161825065792,
      "math": 0.018858515094167454,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 8.8,
    "ram_recommended_gb": 11.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-64k-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Mistral-Small-24B-Instruct-2501-GGUF",
    "label": "Mistral Small 24B 2501",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 150822,
    "likes": 6,
    "last_updated": "2025-06-23T09:27:53+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "mistral-small-24b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23697032967032966,
      "code": 0.0235481444332999,
      "math": 0.014128886659979939,
      "story": 0.00470962888665998,
      "roleplay": 0.00470962888665998
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "stelterlab/Mistral-Small-24B-Instruct-2501-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/Mistral-Small-24B-Instruct-2501-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 14714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Mistral-Small-24B-Instruct-2501",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/Mistral-Small-24B-Instruct-2501-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf"
      },
      {
        "model_id": "bartowski/Mistral-Small-24B-Instruct-2501-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf"
      },
      {
        "model_id": "cortexso/mistral-small-24b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/mistral-small-24b/resolve/main/mistral-small-24b-base-2501-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-small-24b-base-2501-q4_k_m.gguf"
      },
      {
        "model_id": "unsloth/Mistral-Small-24B-Instruct-2501-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 14714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Mistral-Small-24B-Instruct-2501-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/Mistral-Small-24B-Instruct-2501-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf"
      },
      {
        "model_id": "dwetzel/Mistral-Small-24B-Instruct-2501-GPTQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/dwetzel/Mistral-Small-24B-Instruct-2501-GPTQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 14714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "gaianet/Mistral-Small-24B-Instruct-2501-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 17.02,
    "ram_recommended_gb": 21.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 17.02,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Mistral-Small-24B-Instruct-2501-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Yi-Coder-1.5B-Chat-GGUF",
    "label": "Yi Coder 1.5B",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 150116,
    "likes": 13,
    "last_updated": "2024-09-04T14:38:02+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "yi-coder-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2390857142857143,
      "code": 0.11954285714285715,
      "math": 0.02128961885656971,
      "story": 0.00409653961885657,
      "roleplay": 0.00409653961885657
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Yi-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-Coder-1.5B-GGUF/resolve/main/Yi-Coder-1.5B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-Q6_K.gguf"
      },
      {
        "model_id": "01-ai/Yi-Coder-1.5B-Chat",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "bartowski/Yi-Coder-1.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-Coder-1.5B-Chat-GGUF/resolve/main/Yi-Coder-1.5B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2954682304,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-Chat-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Yi-Coder-1.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-Coder-1.5B-Chat-GGUF/resolve/main/Yi-Coder-1.5B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "second-state/Yi-Coder-1.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-Coder-1.5B-Chat-GGUF/resolve/main/Yi-Coder-1.5B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2954682304,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-Chat-f16.gguf"
      },
      {
        "model_id": "gaianet/Yi-Coder-1.5B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-Coder-1.5B-Chat-GGUF/resolve/main/Yi-Coder-1.5B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2954682304,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-Chat-f16.gguf"
      },
      {
        "model_id": "bartowski/Yi-Coder-1.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-Coder-1.5B-GGUF/resolve/main/Yi-Coder-1.5B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2954681728,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-1.5B-f16.gguf"
      }
    ],
    "ram_estimate_gb": 2.62,
    "ram_recommended_gb": 3.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.62,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Yi-Coder-1.5B-Chat-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF",
    "label": "Llama 3 8B 32K",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "v0.1"
    ],
    "dropped_tags": [
      "v0.1"
    ],
    "downloads": 148754,
    "likes": 58,
    "last_updated": "2024-06-28T10:42:58+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "llama-3-8b-32k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.30305706504515223,
      "code": 0.011419857445545419,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 8.8,
    "ram_recommended_gb": 11.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-32k-v0.1-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/WizardLM-2-7B-GGUF",
    "label": "Wizardlm 2 7B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 148374,
    "likes": 82,
    "last_updated": "2024-04-15T18:39:24+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "wizardlm-2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23158571428571428,
      "code": 0.023510531594784355,
      "math": 0.014106318956870612,
      "story": 0.0047021063189568715,
      "roleplay": 0.0047021063189568715
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/WizardLM-2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/WizardLM-2-7B-GGUF/resolve/main/WizardLM-2-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "WizardLM-2-7B-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/WizardLM-2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/WizardLM-2-7B-GGUF/resolve/main/WizardLM-2-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "WizardLM-2-7B-Q2_K.gguf"
      },
      {
        "model_id": "dreamgen/WizardLM-2-7B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/WizardLM-2-7B-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Yi-1.5-6B-Chat-GGUF",
    "label": "Yi 1.5 6B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 147724,
    "likes": 9,
    "last_updated": "2024-05-12T20:34:51+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 6,
    "canonical_base": "yi-1-5-6b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22466263736263736,
      "code": 0.020821213640922768,
      "math": 0.01249272818455366,
      "story": 0.004164242728184554,
      "roleplay": 0.004164242728184554
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-1.5-6B-Chat",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "bartowski/Yi-1.5-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-1.5-6B-Chat-GGUF/resolve/main/Yi-1.5-6B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-6B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "gaianet/Yi-1.5-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-1.5-6B-Chat-GGUF/resolve/main/Yi-1.5-6B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-6B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "second-state/Yi-1.5-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-1.5-6B-Chat-GGUF/resolve/main/Yi-1.5-6B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-6B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "unsloth/Yi-1.5-6B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Yi-1.5-6B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/Yi-1.5-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-1.5-6B-Chat-GGUF/resolve/main/Yi-1.5-6B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-6B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "QuantFactory/Yi-1.5-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Yi-1.5-6B-Chat-GGUF/resolve/main/Yi-1.5-6B-Chat.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-6B-Chat.Q6_K.gguf"
      },
      {
        "model_id": "afrideva/Yi-1.5-6B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/Yi-1.5-6B-GGUF/resolve/main/yi-1.5-6b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "yi-1.5-6b.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 6.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Yi-1.5-6B-Chat-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/solar-pro-preview-instruct-GGUF",
    "label": "Solar Pro Preview",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 147638,
    "likes": 26,
    "last_updated": "2024-09-13T15:58:01+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "solar-pro-preview",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2390857142857143,
      "code": 0.021868104312938817,
      "math": 0.01312086258776329,
      "story": 0.004373620862587763,
      "roleplay": 0.004373620862587763
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "upstage/solar-pro-preview-instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/solar-pro-preview-instruct-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Yi-Coder-9B-Chat-GGUF",
    "label": "Yi Coder 9B",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 147569,
    "likes": 5,
    "last_updated": "2024-09-04T16:22:07+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "yi-coder-9b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22523956043956045,
      "code": 0.11261978021978022,
      "math": 0.022583500501504514,
      "story": 0.004527833500501505,
      "roleplay": 0.004527833500501505
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-Coder-9B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "second-state/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-Coder-9B-Chat-GGUF/resolve/main/Yi-Coder-9B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17661112864,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Chat-f16.gguf"
      },
      {
        "model_id": "gaianet/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-Coder-9B-Chat-GGUF/resolve/main/Yi-Coder-9B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17661112864,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Chat-f16.gguf"
      },
      {
        "model_id": "bartowski/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-Coder-9B-Chat-GGUF/resolve/main/Yi-Coder-9B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17661112864,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Chat-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-Coder-9B-Chat-GGUF/resolve/main/Yi-Coder-9B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 7514572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "mav23/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Yi-Coder-9B-Chat-GGUF/resolve/main/yi-coder-9b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "yi-coder-9b-chat.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Yi-Coder-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Yi-Coder-9B-Chat-GGUF/resolve/main/Yi-Coder-9B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Yi-Coder-9B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Yi-Coder-9B-GGUF/resolve/main/Yi-Coder-9B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-Coder-9B-Q2_K.gguf"
      },
      {
        "model_id": "k2rks/Yi-Coder-9B-Chat-mlx-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/k2rks/Yi-Coder-9B-Chat-mlx-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 9314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Yi-Coder-9B-Chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Yi-Coder-9B-Chat-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "k2rks/Yi-Coder-9B-Chat-mlx-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/k2rks/Yi-Coder-9B-Chat-mlx-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 4.42,
    "ram_recommended_gb": 5.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 4.42,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "9B",
    "params_b": 9.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Yi-Coder-9B-Chat-GGUF"
  },
  {
    "model_id": "tiiuae/falcon-7b-instruct",
    "label": "Falcon 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 146857,
    "likes": 1001,
    "last_updated": "2024-10-12T13:20:03+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.235,
      "code": 0.024845787362086258,
      "math": 0.014907472417251754,
      "story": 0.004969157472417252,
      "roleplay": 0.004969157472417252
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tiiuae/falcon-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/falcon-7b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14434402976,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14434402976
      },
      {
        "model_id": "TheBloke/Falcon-7B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Falcon-7B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5942953520,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/falcon-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/falcon-7b-instruct-GGUF/resolve/main/falcon-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "falcon-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "vivekraina/falcon-7b-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/vivekraina/falcon-7b-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "vivekraina/falcon-7b-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/vivekraina/falcon-7b-Instruct-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "legendhasit/falcon-7b-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/legendhasit/falcon-7b-instruct-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "4bit/falcon-7b-instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/4bit/falcon-7b-instruct-GPTQ/resolve/main/gptq_model-4bit-64g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit-64g.safetensors"
      },
      {
        "model_id": "inarikami/falcon-7b-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/inarikami/falcon-7b-instruct-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      },
      {
        "model_id": "cambioml/falcon-7b-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cambioml/falcon-7b-8bit/resolve/main/pytorch_model.bin?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/falcon-7b-instruct"
  },
  {
    "model_id": "MaziyarPanahi/Mistral-Large-Instruct-2411-GGUF",
    "label": "Mistral Large 2411",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 146648,
    "likes": 2,
    "last_updated": "2024-11-20T13:39:30+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "mistral-large",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22004725274725273,
      "code": 0.02534729187562688,
      "math": 0.015208375125376128,
      "story": 0.005069458375125377,
      "roleplay": 0.005069458375125377
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Mistral-Large-Instruct-2411-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-Large-Instruct-2411-GGUF/resolve/main/Mistral-Large-Instruct-2411-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 45196298528,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2411-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Mistral-Large-Instruct-2407-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-Large-Instruct-2407-GGUF/resolve/main/Mistral-Large-Instruct-2407-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 45196301984,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2407-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Mistral-Large-Instruct-2407-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Mistral-Large-Instruct-2407-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 64450401470,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 64450401470
      },
      {
        "model_id": "MaziyarPanahi/Mistral-Large-Instruct-2407-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-Large-Instruct-2407-GGUF/resolve/main/Mistral-Large-Instruct-2407.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 45196297984,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2407.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Mistral-Large-Instruct-2411-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-Large-Instruct-2411-GGUF/resolve/main/Mistral-Large-Instruct-2411-Q6_K-00001-of-00003.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 39826167872,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2411-Q6_K-00001-of-00003.gguf"
      },
      {
        "model_id": "second-state/Mistral-Large-Instruct-2407-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Mistral-Large-Instruct-2407-GGUF/resolve/main/Mistral-Large-Instruct-2407-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 45196298816,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2407-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Mistral-Large-Instruct-2407-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-Large-Instruct-2407-GGUF/resolve/main/Mistral-Large-Instruct-2407-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 45196297984,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Large-Instruct-2407-Q2_K.gguf"
      },
      {
        "model_id": "sjug/Mistral-Large-Instruct-2411-8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "casperhansen/mistral-large-instruct-2407-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/casperhansen/mistral-large-instruct-2407-awq/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 64895446576,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 64895446576
      },
      {
        "model_id": "SillyTilly/Mistral-Large-Instruct-2407",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Mistral-Large-Instruct-2411-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Mistral-Small-Instruct-2409-GGUF",
    "label": "Mistral Small 2409",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 146511,
    "likes": 2,
    "last_updated": "2025-01-01T23:41:50+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "mistral-small",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22004725274725273,
      "code": 0.021673771313941825,
      "math": 0.013004262788365094,
      "story": 0.004334754262788365,
      "roleplay": 0.004334754262788365
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Mistral-Small-Instruct-2409-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-Small-Instruct-2409-GGUF/resolve/main/Mistral-Small-Instruct-2409-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 44496728768,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-Instruct-2409-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Mistral-Small-Instruct-2409-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-Small-Instruct-2409-GGUF/resolve/main/Mistral-Small-Instruct-2409-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 18252703616,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-Instruct-2409-Q6_K.gguf"
      },
      {
        "model_id": "DevQuasar/Mistral-Small-Instruct-2409-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Mistral-Small-Instruct-2409-GGUF/resolve/main/Mistral-Small-Instruct-2409.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 8272097984,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-Instruct-2409.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Mistral-Small-Instruct-2409-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/mistral-small-3.1-24b-instruct-2503-hf-GGUF",
    "label": "Mistral Small 3.1 24B 2503",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 146442,
    "likes": 2,
    "last_updated": "2025-03-18T10:45:24+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "mistral-small-3-1-24b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23004725274725274,
      "code": 0.021103309929789368,
      "math": 0.01266198595787362,
      "story": 0.004220661985957874,
      "roleplay": 0.004220661985957874
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Mistral-Small-3.1-24B-Instruct-2503-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Mistral-Small-3.1-24B-Instruct-2503-GGUF/resolve/main/Mistral-Small-3.1-24B-Instruct-2503-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-3.1-24B-Instruct-2503-Q4_K_M.gguf"
      },
      {
        "model_id": "muranAI/Mistral-Small-3.1-24B-Instruct-2503-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/muranAI/Mistral-Small-3.1-24B-Instruct-2503-GGUF/resolve/main/mistral-small-3.1-24b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-small-3.1-24b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "barretts/mistral-small-3.1-24b-instruct-2503-hf-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/barretts/mistral-small-3.1-24b-instruct-2503-hf-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 12314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/mistral-small-3.1-24b-instruct-2503-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/mistral-small-3.1-24b-instruct-2503-hf-GGUF/resolve/main/mistral-small-3.1-24b-instruct-2503-hf-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 13514572800,
        "notes": null,
        "revision": "main",
        "filename": "mistral-small-3.1-24b-instruct-2503-hf-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 17.02,
    "ram_recommended_gb": 21.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 17.02,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/mistral-small-3.1-24b-instruct-2503-hf-GGUF"
  },
  {
    "model_id": "MaziyarPanahi/Meta-Llama-3.1-405B-Instruct-GGUF",
    "label": "Meta Llama 3.1 405B",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 145880,
    "likes": 14,
    "last_updated": "2024-07-29T14:08:03+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "meta-llama-3-1-405b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23158571428571428,
      "code": 0.023867853560682047,
      "math": 0.014320712136409227,
      "story": 0.00477357071213641,
      "roleplay": 0.00477357071213641
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Meta-Llama-3.1-405B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-405B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 243314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "hugging-quants/Meta-Llama-3.1-405B-Instruct-AWQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-405B-Instruct-AWQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 243314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-405B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-405B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 202814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "hugging-quants/Meta-Llama-3.1-405B-Instruct-GPTQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/hugging-quants/Meta-Llama-3.1-405B-Instruct-GPTQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 243314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Meta-Llama-3.1-405B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-405B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 243314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "leafspark/Meta-Llama-3.1-405B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/leafspark/Meta-Llama-3.1-405B-Instruct-GGUF/resolve/main/Llama-3.1-405B-Instruct.Q2_K.gguf/Llama-3.1-405B-Instruct-Q2_K-00001-of-00008.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 121814572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-405B-Instruct.Q2_K.gguf/Llama-3.1-405B-Instruct-Q2_K-00001-of-00008.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Meta-Llama-3.1-405B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Meta-Llama-3.1-405B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-405B-Instruct-F16/Meta-Llama-3.1-405B-Instruct-F16-00001-of-00018.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 47093935968,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-405B-Instruct-F16/Meta-Llama-3.1-405B-Instruct-F16-00001-of-00018.gguf"
      },
      {
        "model_id": "bullerwins/Meta-Llama-3.1-405B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bullerwins/Meta-Llama-3.1-405B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-405B-Instruct-Q2_K-00001-of-00004.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 121814572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3.1-405B-Instruct-Q2_K-00001-of-00004.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3.1-405B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3.1-405B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 405314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 146.98,
    "ram_recommended_gb": 183.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 146.98,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "70B",
    "params_b": 405.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-405B-Instruct-GGUF"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ",
    "label": "Qwen2.5 Coder 32B",
    "tags": [
      "awq",
      "chat",
      "code",
      "cuda",
      "small"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "code",
      "cuda",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 143432,
    "likes": 29,
    "last_updated": "2024-11-18T12:55:21+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "canonical_base": "qwen2-5-coder-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23779642857142858,
      "code": 0.11889821428571429,
      "math": 0.02408049147442327,
      "story": 0.005026830491474423,
      "roleplay": 0.005026830491474423
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/qwen2.5-coder-32b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-32b-instruct-q2_k.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-GGUF/resolve/main/Qwen2.5-Coder-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Q6_K.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-32B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-32B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-32B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-32B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-32B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-32B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-32B-GGUF/resolve/main/Qwen2.5-Coder-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Q2_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-32B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-32B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "XelotX/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/XelotX/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-32B-GGUF/resolve/main/Qwen2.5-Coder-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-32B-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-32B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-32B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-32B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-32B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-32B-Instruct-GGUF/resolve/main/qwen2.5-coder-32b-instruct-q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-32b-instruct-q6_k.gguf"
      },
      {
        "model_id": "Eric1227/Qwen2.5-Coder-32B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Eric1227/Qwen2.5-Coder-32B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-32B-Instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-32B-Instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 24314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 31.9,
    "ram_recommended_gb": 39.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 31.9,
    "format": "awq",
    "quant_class": "awq",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct-AWQ"
  },
  {
    "model_id": "microsoft/phi-1_5",
    "label": "Phi 1 5",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 129048,
    "likes": 1342,
    "last_updated": "2024-04-29T16:16:33+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-1",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.11375,
      "math": 0.02424598796389168,
      "story": 0.005081995987963892,
      "roleplay": 0.005081995987963892
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TKDKid1000/phi-1_5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TKDKid1000/phi-1_5-GGUF/resolve/main/phi-1_5-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2839534976,
        "notes": null,
        "revision": "main",
        "filename": "phi-1_5-f16.gguf"
      },
      {
        "model_id": "tensorblock/phi-1_5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/phi-1_5-GGUF/resolve/main/phi-1_5-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 582316992,
        "notes": null,
        "revision": "main",
        "filename": "phi-1_5-Q2_K.gguf"
      },
      {
        "model_id": "mav23/phi-1_5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/phi-1_5-GGUF/resolve/main/phi-1_5.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 582316992,
        "notes": null,
        "revision": "main",
        "filename": "phi-1_5.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/phi-1_5"
  },
  {
    "model_id": "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct",
    "label": "Exaone 3.5 2.4B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 125064,
    "likes": 168,
    "last_updated": "2024-12-11T06:51:40+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "exaone-3-5-2-4b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.0241123370110331,
      "math": 0.014467402206619859,
      "story": 0.00482246740220662,
      "roleplay": 0.00482246740220662
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1754572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "ThomasBaruzier/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/EXAONE-3.5-2.4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/EXAONE-3.5-2.4B-Instruct-GGUF/resolve/main/EXAONE-3.5-2.4B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1634572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-2.4B-Instruct.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 2.91,
    "ram_recommended_gb": 3.64,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.91,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 2.4,
    "tier": "high",
    "model_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct"
  },
  {
    "model_id": "Alibaba-NLP/gte-Qwen2-1.5B-instruct",
    "label": "Gte Qwen2 1.5B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 120746,
    "likes": 223,
    "last_updated": "2025-05-28T13:11:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "gte-qwen2-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.025842527582748246,
      "math": 0.015505516549648947,
      "story": 0.00516850551654965,
      "roleplay": 0.00516850551654965
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/gte-Qwen2-1.5B-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/gte-Qwen2-1.5B-instruct-GGUF/resolve/main/gte-Qwen2-1.5B-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3558625344,
        "notes": null,
        "revision": "main",
        "filename": "gte-Qwen2-1.5B-instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/gte-Qwen2-1.5B-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/gte-Qwen2-1.5B-instruct-GGUF/resolve/main/gte-Qwen2-1.5B-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3558625344,
        "notes": null,
        "revision": "main",
        "filename": "gte-Qwen2-1.5B-instruct-f16.gguf"
      }
    ],
    "ram_estimate_gb": 3.8,
    "ram_recommended_gb": 4.75,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct"
  },
  {
    "model_id": "ibm-granite/granite-3.3-2b-instruct",
    "label": "Granite 3.3 2B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 117273,
    "likes": 57,
    "last_updated": "2025-05-08T15:01:59+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-3-2b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.023711133400200604,
      "math": 0.014226680040120362,
      "story": 0.004742226680040121,
      "roleplay": 0.004742226680040121
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "ibm-granite/granite-3.3-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-instruct-GGUF/resolve/main/granite-3.3-2b-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5069158176,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-2b-instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/granite-3.3-2b-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-2b-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/granite-3.3-2b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/granite-3.3-2b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 5067121552,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5067121552
      },
      {
        "model_id": "lmstudio-community/granite-3.3-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.3-2b-instruct-GGUF/resolve/main/granite-3.3-2b-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1914572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-2b-instruct-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/granite-3.3-2b-instruct-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-2b-instruct-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5067121128,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5067121128
      },
      {
        "model_id": "mlx-community/granite-3.3-2b-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-2b-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 2314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 2.38,
    "ram_recommended_gb": 2.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 2.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-instruct"
  },
  {
    "model_id": "ibm-granite/granite-3.3-8b-instruct",
    "label": "Granite 3.3 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 115948,
    "likes": 116,
    "last_updated": "2025-05-12T06:39:42+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-3-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.02065195586760281,
      "math": 0.012391173520561684,
      "story": 0.004130391173520562,
      "roleplay": 0.004130391173520562
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "ibm-granite/granite-3.3-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct-GGUF/resolve/main/granite-3.3-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/granite-3.3-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/granite-3.3-8b-instruct-GGUF/resolve/main/granite-3.3-8b-instruct-UD-Q8_K_XL.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-8b-instruct-UD-Q8_K_XL.gguf"
      },
      {
        "model_id": "Mungert/granite-3.3-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.3-8b-instruct-GGUF/resolve/main/granite-3.3-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "mlx-community/granite-3.3-8b-instruct-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-8b-instruct-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16341771015,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16341771015
      },
      {
        "model_id": "lmstudio-community/granite-3.3-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.3-8b-instruct-GGUF/resolve/main/granite-3.3-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.3-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/granite-3.3-8b-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-8b-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/granite-3.3-8b-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-8b-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/granite-3.3-8b-instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/granite-3.3-8b-instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 6314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Fmuaddib/granite-3.3-8b-instruct-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Fmuaddib/granite-3.3-8b-instruct-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16341771003,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16341771003
      },
      {
        "model_id": "Fmuaddib/granite-3.3-8b-instruct-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Fmuaddib/granite-3.3-8b-instruct-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.98,
    "ram_recommended_gb": 7.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-V2-Lite-Chat",
    "label": "Deepseek Lite",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "v2"
    ],
    "dropped_tags": [
      "v2"
    ],
    "downloads": 115871,
    "likes": 126,
    "last_updated": "2024-06-25T08:36:27+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-v2-le",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22642857142857142,
      "code": 0.11321428571428571,
      "math": 0.022060682046138418,
      "story": 0.0043535606820461386,
      "roleplay": 0.0043535606820461386
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "deepseek-ai/DeepSeek-V2-Lite",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 31413626576,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 31413626576
      },
      {
        "model_id": "second-state/DeepSeek-V2-Lite-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/DeepSeek-V2-Lite-Chat-GGUF/resolve/main/DeepSeek-V2-Lite-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 31424033088,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2-Lite-Chat-f16.gguf"
      },
      {
        "model_id": "gaianet/DeepSeek-V2-Lite-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/DeepSeek-V2-Lite-Chat-GGUF/resolve/main/DeepSeek-V2-Lite-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 31424033088,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2-Lite-Chat-f16.gguf"
      },
      {
        "model_id": "TechxGenus/DeepSeek-V2-Lite-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/DeepSeek-V2-Lite-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 9086606872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 9086606872
      },
      {
        "model_id": "ModelCloud/DeepSeek-V2-Lite-gptq-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ModelCloud/DeepSeek-V2-Lite-gptq-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8826847688,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "slowfastai/DeepSeek-V2-Lite-Chat-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/slowfastai/DeepSeek-V2-Lite-Chat-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8740747410,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 8740747410
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite-Chat"
  },
  {
    "model_id": "tencent/Hunyuan-A13B-Instruct-GPTQ-Int4",
    "label": "Hunyuan A13B",
    "tags": [
      "chat",
      "cuda",
      "gptq",
      "small"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "gptq",
      "int4",
      "small"
    ],
    "dropped_tags": [
      "int4"
    ],
    "downloads": 115778,
    "likes": 47,
    "last_updated": "2025-07-11T03:53:30+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gptq",
    "quant_bits": 4,
    "canonical_base": "hunyuan-a13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.24779642857142856,
      "code": 0.022081243731193582,
      "math": 0.013248746238716148,
      "story": 0.004416248746238717,
      "roleplay": 0.004416248746238717
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tencent/Hunyuan-A13B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/Hunyuan-A13B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 5774572800,
        "notes": null,
        "revision": "main",
        "filename": "Hunyuan-A13B-Instruct-Q3_K_L.gguf"
      },
      {
        "model_id": "ubergarm/Hunyuan-A13B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF/resolve/main/Hunyuan-A13B-Instruct-IQ3_KS.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 36606100704,
        "notes": null,
        "revision": "main",
        "filename": "Hunyuan-A13B-Instruct-IQ3_KS.gguf"
      },
      {
        "model_id": "mlx-community/Hunyuan-A13B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-A13B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 6814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Hunyuan-A13B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-A13B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 8.98,
    "ram_recommended_gb": 11.23,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 8.98,
    "format": "gptq",
    "quant_class": "gptq-q4",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GPTQ-Int4"
  },
  {
    "model_id": "Qwen/Qwen2.5-72B-Instruct",
    "label": "Qwen2.5 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 114537,
    "likes": 854,
    "last_updated": "2025-01-12T02:07:38+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.0208462888665998,
      "math": 0.01250777331995988,
      "story": 0.00416925777331996,
      "roleplay": 0.00416925777331996
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-72B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 41595756104,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 41595756104
      },
      {
        "model_id": "Qwen/Qwen2.5-72B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-72B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 145412518888,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 145412518888
      },
      {
        "model_id": "Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-72B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-72B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct-GGUF/resolve/main/qwen2.5-72b-instruct-fp16-00001-of-00042.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3772493568,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-72b-instruct-fp16-00001-of-00042.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-72B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-72B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2.5-72B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-72B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Gensyn/Qwen2.5-72B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Gensyn/Qwen2.5-72B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 30554572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q3_K_L.gguf"
      },
      {
        "model_id": "DevQuasar/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-72B-Instruct-GGUF/resolve/main/Qwen2.5-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-72B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-72B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-72B-Instruct-4bit-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-72B-Instruct-4bit-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/Qwen2.5-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Qwen2.5-72B-Instruct-GGUF/resolve/main/qwen2.5-72b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-72b-instruct.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 53.02,
    "ram_recommended_gb": 66.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 53.02,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-14B-Instruct-AWQ",
    "label": "Qwen2.5 Coder 14B",
    "tags": [
      "awq",
      "chat",
      "code",
      "cuda"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "code",
      "cuda"
    ],
    "dropped_tags": [],
    "downloads": 113274,
    "likes": 12,
    "last_updated": "2025-01-12T02:15:55+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "quant_bits": 4,
    "canonical_base": "qwen2-5-coder-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23606565934065932,
      "code": 0.11803282967032966,
      "math": 0.023745737211634907,
      "story": 0.004915245737211635,
      "roleplay": 0.004915245737211635
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-14B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/qwen2.5-coder-14b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-14b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-14B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-14B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-14B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-14B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-14B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-14B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-14B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-14B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-14B-GGUF/resolve/main/Qwen2.5-Coder-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-GGUF/resolve/main/Qwen2.5-Coder-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "ikw/Qwen2.5-Coder-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-14B-GGUF/resolve/main/Qwen2.5-Coder-14B.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-14B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-14B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "kolosal/qwen2.5-coder-14b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kolosal/qwen2.5-coder-14b/resolve/main/qwen2.5-coder-14b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-14b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-14B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-14B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "k2rks/Qwen2.5-Coder-14B-Instruct-mlx-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/k2rks/Qwen2.5-Coder-14B-Instruct-mlx-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ALYTV/Qwen2.5-Coder-14B-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ALYTV/Qwen2.5-Coder-14B-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Alcoft/Qwen2.5-Coder-14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/Qwen2.5-Coder-14B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-14B-Instruct_Q4_K_S.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-14B-Instruct_Q4_K_S.gguf"
      }
    ],
    "ram_estimate_gb": 10.42,
    "ram_recommended_gb": 13.03,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.42,
    "format": "awq",
    "quant_class": "awq",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-14B-Instruct-AWQ"
  },
  {
    "model_id": "unsloth/Llama-3.2-3B-Instruct-unsloth-bnb-4bit",
    "label": "Llama 3.2 3B Unsloth Bnb 4Bit",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 112744,
    "likes": 10,
    "last_updated": "2025-06-02T21:41:30+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "llama-3-2-3b-unsloth",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23873626373626372,
      "code": 0.021949598796389167,
      "math": 0.0131697592778335,
      "story": 0.004389919759277833,
      "roleplay": 0.004389919759277833
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Llama-3.2-3B-unsloth-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.2-3B-unsloth-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 3.34,
    "ram_recommended_gb": 4.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.34,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-unsloth-bnb-4bit"
  },
  {
    "model_id": "unsloth/phi-4-unsloth-bnb-4bit",
    "label": "Phi 4 Unsloth Bnb 4Bit",
    "tags": [
      "chat",
      "code",
      "hf",
      "math"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "math"
    ],
    "dropped_tags": [],
    "downloads": 109649,
    "likes": 61,
    "last_updated": "2025-01-13T18:54:31+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "phi-4-unsloth",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.30628209815577656,
      "code": 0.24804364975220494,
      "math": 0.35,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/phi-4-unsloth-bnb-4bit"
  },
  {
    "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "label": "Qwen3 Coder 480B A35B Fp8",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 107139,
    "likes": 99,
    "last_updated": "2025-08-07T07:07:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen3-coder-480b-a35b-fp8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.1219642857142857,
      "math": 0.02365546639919759,
      "story": 0.004885155466399198,
      "roleplay": 0.004885155466399198
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-FP8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 482149572808,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 482149572808
      }
    ],
    "ram_estimate_gb": 960.8,
    "ram_recommended_gb": 1201.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 960.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 480.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"
  },
  {
    "model_id": "DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF",
    "label": "Llama 3.2 8X3B Dark Champion Uncensored Abliterated 18.4B",
    "tags": [
      "chat",
      "gguf",
      "moe",
      "mps",
      "roleplay",
      "small",
      "story"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "moe",
      "mps",
      "roleplay",
      "small",
      "story"
    ],
    "dropped_tags": [],
    "downloads": 106847,
    "likes": 313,
    "last_updated": "2025-07-28T00:18:34+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "llama-3-2-8x3b-moe-dark-champion-uncensored-ablerated-18-4b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24908571428571427,
      "code": 0.02228811434302909,
      "math": 0.013372868605817453,
      "story": 0.02490857142857143,
      "roleplay": 0.02490857142857143
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 3.8,
    "ram_recommended_gb": 4.75,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF"
  },
  {
    "model_id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "label": "Llama 3.1 Nemotron 70B",
    "tags": [
      "chat",
      "cuda",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 100942,
    "likes": 2052,
    "last_updated": "2025-04-13T04:12:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-nemotron-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.245,
      "code": 0.025510280842527582,
      "math": 0.015306168505516549,
      "story": 0.005102056168505517,
      "roleplay": 0.005102056168505517
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf"
      },
      {
        "model_id": "joshmiller656/Llama-3.1-Nemotron-70B-Instruct-AWQ-INT4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/joshmiller656/Llama-3.1-Nemotron-70B-Instruct-AWQ-INT4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf"
      },
      {
        "model_id": "RedHatAI/Llama-3.1-Nemotron-70B-Instruct-HF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/RedHatAI/Llama-3.1-Nemotron-70B-Instruct-HF/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 141107497872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497872
      },
      {
        "model_id": "MaziyarPanahi/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Mistral-Small-Instruct-2409.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-Small-Instruct-2409.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-HF-Q3_K_L.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 29714572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-HF-Q3_K_L.gguf"
      },
      {
        "model_id": "XelotX/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/XelotX/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/llama-3.1-nemotron-70b-instruct-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.1-nemotron-70b-instruct-hf.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3.1-Nemotron-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.1-Nemotron-70B-Instruct-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct-HF-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3.1-Nemotron-70B-Instruct-HF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-Nemotron-70B-Instruct-HF/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 141107497175,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497175
      },
      {
        "model_id": "unsloth/Llama-3.1-Nemotron-70B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Llama-3.1-Nemotron-70B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.1-Nemotron-70B-Instruct-HF-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-Nemotron-70B-Instruct-HF-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "backyardai/Llama-3.1-Nemotron-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/backyardai/Llama-3.1-Nemotron-70B-Instruct-GGUF/resolve/main/Llama-3.1-Nemotron-70B-Instruct.IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 16751201344,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-Nemotron-70B-Instruct.IQ1_M.gguf"
      }
    ],
    "ram_estimate_gb": 51.58,
    "ram_recommended_gb": 64.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 51.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"
  },
  {
    "model_id": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct",
    "label": "Exaone 3.5 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 89572,
    "likes": 124,
    "last_updated": "2024-12-11T07:17:06+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "exaone-3-5-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.024482196589769308,
      "math": 0.014689317953861584,
      "story": 0.004896439317953862,
      "roleplay": 0.004896439317953862
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 18180194648,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 18180194648
      },
      {
        "model_id": "second-state/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "furiosa-ai/EXAONE-3.5-32B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/EXAONE-3.5-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/EXAONE-3.5-32B-Instruct-GGUF/resolve/main/EXAONE-3.5-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.5-32B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 12.7,
    "ram_recommended_gb": 15.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 12.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct"
  },
  {
    "model_id": "MaziyarPanahi/WizardLM-2-8x22B-AWQ",
    "label": "Wizardlm 2 8X22B",
    "tags": [
      "awq",
      "chat",
      "cuda",
      "small"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "cuda",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 87180,
    "likes": 13,
    "last_updated": "2025-02-25T04:27:46+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "canonical_base": "wizardlm-2-8x22b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.24779642857142856,
      "code": 0.023986960882647942,
      "math": 0.014392176529588765,
      "story": 0.004797392176529589,
      "roleplay": 0.004797392176529589
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "alpindale/WizardLM-2-8x22B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "MaziyarPanahi/WizardLM-2-8x22B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/WizardLM-2-8x22B-GGUF/resolve/main/WizardLM-2-8x22B.IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 32732397696,
        "notes": null,
        "revision": "main",
        "filename": "WizardLM-2-8x22B.IQ1_M.gguf"
      },
      {
        "model_id": "bartowski/WizardLM-2-8x22B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/WizardLM-2-8x22B-GGUF/resolve/main/WizardLM-2-8x22B-Q2_K.gguf/WizardLM-2-8x22B-Q2_K-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "WizardLM-2-8x22B-Q2_K.gguf/WizardLM-2-8x22B-Q2_K-00001-of-00005.gguf"
      },
      {
        "model_id": "XelotX/WizardLM-2-8x22B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/XelotX/WizardLM-2-8x22B-GGUF/resolve/main/WizardLM-2-8x22B.IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 32732397696,
        "notes": null,
        "revision": "main",
        "filename": "WizardLM-2-8x22B.IQ1_M.gguf"
      }
    ],
    "ram_estimate_gb": 9.1,
    "ram_recommended_gb": 11.38,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.1,
    "format": "awq",
    "quant_class": "awq",
    "size_hint": "22B",
    "params_b": 22.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MaziyarPanahi/WizardLM-2-8x22B-AWQ"
  },
  {
    "model_id": "mosaicml/mpt-7b-chat",
    "label": "Mpt 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 82690,
    "likes": 517,
    "last_updated": "2024-03-05T20:25:13+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "mpt-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22642857142857142,
      "code": 0.02214393179538616,
      "math": 0.013286359077231694,
      "story": 0.004428786359077232,
      "roleplay": 0.004428786359077232
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mosaicml/mpt-7b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "oleksandrfluxon/mpt-7b-chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/mosaicml/mpt-7b-chat"
  },
  {
    "model_id": "unsloth/Qwen2.5-7B-Instruct-unsloth-bnb-4bit",
    "label": "Qwen2.5 7B Unsloth Bnb 4Bit",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 79289,
    "likes": 2,
    "last_updated": "2025-04-28T04:16:29+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "qwen2-5-7b-unsloth",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22489010989010988,
      "code": 0.0207271815446339,
      "math": 0.01243630892678034,
      "story": 0.004145436308926781,
      "roleplay": 0.004145436308926781
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen2.5-7B-unsloth-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-7B-unsloth-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Qwen2.5-7B-Instruct-unsloth-bnb-4bit"
  },
  {
    "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "label": "Qwen3 235B A22B 2507 Fp8",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 77711,
    "likes": 115,
    "last_updated": "2025-07-30T15:51:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen3-235b-a22b-2507-fp8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.02177407221664995,
      "math": 0.01306444332998997,
      "story": 0.00435481444332999,
      "roleplay": 0.00435481444332999
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen3-235B-A22B-Instruct-2507-FP8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-FP8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 236426193880,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 236426193880
      }
    ],
    "ram_estimate_gb": 470.8,
    "ram_recommended_gb": 588.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 470.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 235.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8"
  },
  {
    "model_id": "Qwen/QwQ-32B-Preview",
    "label": "Qwq 32B Preview",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 77553,
    "likes": 1738,
    "last_updated": "2025-01-12T01:58:42+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwq-32b-preview",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.235,
      "code": 0.022482447342026077,
      "math": 0.013489468405215645,
      "story": 0.004496489468405216,
      "roleplay": 0.004496489468405216
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/QwQ-32B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/QwQ-32B-Preview-GGUF/resolve/main/QwQ-32B-Preview-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Preview-Q2_K.gguf"
      },
      {
        "model_id": "KirillR/QwQ-32B-Preview-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/KirillR/QwQ-32B-Preview-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328993904,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328993904
      },
      {
        "model_id": "unsloth/QwQ-32B-Preview-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/QwQ-32B-Preview-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/QwQ-32B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/QwQ-32B-Preview-GGUF/resolve/main/QwQ-32B-Preview-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Preview-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/QwQ-32B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/QwQ-32B-Preview-GGUF/resolve/main/QwQ-32B-Preview-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Preview-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/QwQ-32B-Preview-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-Preview-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/QwQ-32B-Preview-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-Preview-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/QwQ-32B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/QwQ-32B-Preview-GGUF/resolve/main/QwQ-32B-Preview-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "QwQ-32B-Preview-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/QwQ-32B-Preview-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/QwQ-32B-Preview-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 24314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 24.22,
    "ram_recommended_gb": 30.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 24.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/QwQ-32B-Preview"
  },
  {
    "model_id": "NousResearch/Hermes-3-Llama-3.1-8B",
    "label": "Hermes 3 Llama 3.1 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 77192,
    "likes": 344,
    "last_updated": "2024-09-08T07:39:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hermes-3-llama-3-1-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.024206369107321966,
      "math": 0.01452382146439318,
      "story": 0.004841273821464393,
      "roleplay": 0.004841273821464393
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Hermes-3-Llama-3.1-8B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Hermes-3-Llama-3.1-8B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Hermes-3-Llama-3.1-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Hermes-3-Llama-3.1-8B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 16060556376,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556376
      },
      {
        "model_id": "solidrust/Hermes-3-Llama-3.1-8B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/solidrust/Hermes-3-Llama-3.1-8B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Hermes-3-Llama-3.1-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Hermes-3-Llama-3.1-8B-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Hermes-3-Llama-3.1-8B-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hermes-3-Llama-3.1-8B-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16060556023,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16060556023
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-8B"
  },
  {
    "model_id": "dnotitia/Smoothie-Qwen3-1.7B",
    "label": "Smoothie Qwen3 1.7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 75663,
    "likes": 1,
    "last_updated": "2025-05-04T15:03:36+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smoothie-qwen3-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2907335473274932,
      "code": 0.020478384492607863,
      "math": 0.014804521514250166,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 4.2,
    "ram_recommended_gb": 5.25,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 4.2,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.7,
    "tier": "high",
    "model_url": "https://huggingface.co/dnotitia/Smoothie-Qwen3-1.7B"
  },
  {
    "model_id": "RedHatAI/DeepSeek-R1-Distill-Llama-70B-FP8-dynamic",
    "label": "Deepseek R1 Distill Llama 70B Fp8 Dynamic",
    "tags": [
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 73946,
    "likes": 9,
    "last_updated": "2025-02-27T07:46:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-distill-llama-70b-fp8-dynamic",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.0774974924774323,
      "code": 0.11850274725274725,
      "math": 0.02324924774322969,
      "story": 0.00474974924774323,
      "roleplay": 0.00474974924774323
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "JamAndTeaStudios/DeepSeek-R1-Distill-Llama-70B-FP8-Dynamic",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/JamAndTeaStudios/DeepSeek-R1-Distill-Llama-70B-FP8-Dynamic/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 72669954704,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 72669954704
      }
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/DeepSeek-R1-Distill-Llama-70B-FP8-dynamic"
  },
  {
    "model_id": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "label": "Qwen3 30B A3B 2507 Fp8",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 73848,
    "likes": 58,
    "last_updated": "2025-07-29T13:33:20+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "canonical_base": "qwen3-30b-a3b-2507-fp8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.025974172517552657,
      "math": 0.015584503510531594,
      "story": 0.005194834503510532,
      "roleplay": 0.005194834503510532
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen3-30B-A3B-Instruct-2507-FP8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen3-30B-A3B-Instruct-2507-FP8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": 31175618584,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 31175618584
      },
      {
        "model_id": "willcb/Qwen3-30B-A3B-Instruct-2507-FP8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/willcb/Qwen3-30B-A3B-Instruct-2507-FP8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "a3b",
        "quant_bits": null,
        "format": null,
        "size_bytes": 31175592952,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 31175592952
      }
    ],
    "ram_estimate_gb": 60.8,
    "ram_recommended_gb": 76.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 60.8,
    "quant_method": "a3b",
    "quant_class": "a3b",
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507-FP8"
  },
  {
    "model_id": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "label": "Solar 10.7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1.0"
    ],
    "dropped_tags": [
      "v1.0"
    ],
    "downloads": 71584,
    "likes": 630,
    "last_updated": "2024-09-10T21:44:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "solar-10-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.02441950852557673,
      "math": 0.014651705115346038,
      "story": 0.004883901705115347,
      "roleplay": 0.004883901705115347
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "upstage/SOLAR-10.7B-v1.0",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/upstage/SOLAR-10.7B-v1.0/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 21463098376,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 21463098376
      },
      {
        "model_id": "second-state/SOLAR-10.7B-Instruct-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/SOLAR-10.7B-Instruct-v1.0-GGUF/resolve/main/SOLAR-10.7B-Instruct-v1.0-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3524572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-Instruct-v1.0-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/SOLAR-10.7B-Instruct-v1.0-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/SOLAR-10.7B-Instruct-v1.0-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5964172344,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/SOLAR-10.7B-v1.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SOLAR-10.7B-v1.2-GGUF/resolve/main/SOLAR-10.7B-v1.2-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3524572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-v1.2-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/SOLAR-10.7B-v1.0-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/SOLAR-10.7B-v1.0-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5975845400,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/SOLAR-10.7B-v1.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SOLAR-10.7B-v1.4-GGUF/resolve/main/SOLAR-10.7B-v1.4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 6199572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-v1.4-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/SOLAR-10.7B-v1.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SOLAR-10.7B-v1.3-GGUF/resolve/main/SOLAR-10.7B-v1.3-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3524572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-v1.3-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/SOLAR-10.7B-v1.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SOLAR-10.7B-v1.1-GGUF/resolve/main/SOLAR-10.7B-v1.1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3524572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-v1.1-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5975845400,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/SOLAR-10.7B-v1.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SOLAR-10.7B-v1.5-GGUF/resolve/main/SOLAR-10.7B-v1.5-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3524572800,
        "notes": null,
        "revision": "main",
        "filename": "SOLAR-10.7B-v1.5-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 5.03,
    "ram_recommended_gb": 6.29,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.03,
    "quant_class": null,
    "format": "hf",
    "size_hint": "10.7B",
    "params_b": 10.7,
    "tier": "high",
    "model_url": "https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0"
  },
  {
    "model_id": "AI-MO/Kimina-Prover-Distill-1.7B",
    "label": "Kimina Prover Distill 1.7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 68593,
    "likes": 8,
    "last_updated": "2025-07-10T11:33:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "kimina-prover-distill-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.30823511250678043,
      "code": 0.014439884718518087,
      "math": 0.0067810752487644285,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 4.2,
    "ram_recommended_gb": 5.25,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 4.2,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.7,
    "tier": "high",
    "model_url": "https://huggingface.co/AI-MO/Kimina-Prover-Distill-1.7B"
  },
  {
    "model_id": "unsloth/Qwen2.5-3B-Instruct-unsloth-bnb-4bit",
    "label": "Qwen2.5 3B Unsloth Bnb 4Bit",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 68320,
    "likes": 7,
    "last_updated": "2025-02-06T03:39:37+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "qwen2-5-3b-unsloth",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22354395604395605,
      "code": 0.022407221664994984,
      "math": 0.01344433299899699,
      "story": 0.004481444332998997,
      "roleplay": 0.004481444332998997
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen2.5-3B-unsloth-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-3B-unsloth-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 3.34,
    "ram_recommended_gb": 4.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.34,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Qwen2.5-3B-Instruct-unsloth-bnb-4bit"
  },
  {
    "model_id": "unsloth/llama-3-8b-Instruct-bnb-4bit",
    "label": "Llama 3 8B Bnb 4Bit",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 61140,
    "likes": 134,
    "last_updated": "2024-11-22T07:09:31+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "llama-3-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23392857142857143,
      "code": 0.02458876629889669,
      "math": 0.014753259779338014,
      "story": 0.004917753259779338,
      "roleplay": 0.004917753259779338
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/llama-3-8b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-3-8b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "casperhansen/llama-3-8b-instruct-awq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/casperhansen/llama-3-8b-instruct-awq/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/llama-3-8b-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "thesven/Llama-3-8B-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/Llama-3-8B-GPTQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-3-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.9-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.9-GGUF/resolve/main/Llama-3-8B-Instruct-v0.9.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.9.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-8B-Instruct-v0.10-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-8B-Instruct-v0.10-GGUF/resolve/main/Llama-3-8B-Instruct-v0.10-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.10-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/llama-3-8b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/llama-3-8b-GGUF/resolve/main/Llama-3-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.10-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.10-GGUF/resolve/main/Llama-3-8B-Instruct-v0.10.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.10.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/llama-3-8b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/llama-3-8b-chat-GGUF/resolve/main/llama-3-8b-chat-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-8b-chat-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-8B-Instruct-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-8B-Instruct-v0.4-GGUF/resolve/main/Llama-3-8B-Instruct-v0.4-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.4-Q8_0.gguf"
      },
      {
        "model_id": "ilayaraja3/llama-3-8b-instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ilayaraja3/llama-3-8b-instruct-gguf/resolve/main/llama-8b-q8.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-8b-q8.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.8-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.8-GGUF/resolve/main/Llama-3-8B-Instruct-v0.8.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.8.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.1-GGUF/resolve/main/Llama-3-8B-Instruct-v0.1.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.1.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.3-GGUF/resolve/main/Llama-3-8B-Instruct-v0.3.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.3.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.2-GGUF/resolve/main/Llama-3-8B-Instruct-v0.2.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.2.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.5-GGUF/resolve/main/Llama-3-8B-Instruct-v0.5.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.5.Q8_0.gguf"
      },
      {
        "model_id": "ai-anytime/Llama-3-8B-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ai-anytime/Llama-3-8B-AWQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-8B-Instruct-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.4-GGUF/resolve/main/Llama-3-8B-Instruct-v0.4.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.4.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-8B-Instruct-v0.9-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-8B-Instruct-v0.9-GGUF/resolve/main/Llama-3-8B-Instruct-v0.9-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-v0.9-Q8_0.gguf"
      },
      {
        "model_id": "shashikanth-a/llama-3-8b-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/llama-3-8b-Instruct-bnb-4bit"
  },
  {
    "model_id": "agentica-org/DeepCoder-14B-Preview",
    "label": "Deepcoder 14B Preview",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 59779,
    "likes": 670,
    "last_updated": "2025-05-11T22:54:03+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepcoder-14b-preview",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07196840521564694,
      "code": 0.1219642857142857,
      "math": 0.02159052156469408,
      "story": 0.0041968405215646945,
      "roleplay": 0.0041968405215646945
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/DeepCoder-14B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/DeepCoder-14B-Preview-GGUF/resolve/main/DeepCoder-14B-Preview-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepCoder-14B-Preview-q4_k_m.gguf"
      },
      {
        "model_id": "mlx-community/DeepCoder-14B-Preview-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepCoder-14B-Preview-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/DeepCoder-14B-Preview-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepCoder-14B-Preview-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/DeepCoder-14B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepCoder-14B-Preview-GGUF/resolve/main/DeepCoder-14B-Preview-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepCoder-14B-Preview-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/DeepCoder-14B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/DeepCoder-14B-Preview-GGUF/resolve/main/DeepCoder-14B-Preview.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepCoder-14B-Preview.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/DeepCoder-14B-Preview-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepCoder-14B-Preview-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 10814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "justinmeans/DeepCoder-14B-Preview-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/justinmeans/DeepCoder-14B-Preview-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 17.98,
    "ram_recommended_gb": 22.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 17.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/agentica-org/DeepCoder-14B-Preview"
  },
  {
    "model_id": "Qwen/Qwen1.5-1.8B-Chat",
    "label": "Qwen1.5 1.8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 57268,
    "likes": 59,
    "last_updated": "2024-04-30T07:20:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen1-5-1-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22642857142857142,
      "code": 0.02003761283851555,
      "math": 0.012022567703109329,
      "story": 0.00400752256770311,
      "roleplay": 0.00400752256770311
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen1.5-1.8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3673690696,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen1.5-1.8B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1_5-1_8b-chat-q8_0.gguf"
      },
      {
        "model_id": "second-state/Qwen1.5-1.8B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-1.8B-Chat-Q8_0.gguf"
      },
      {
        "model_id": "Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1394572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/Qwen1.5-1.8B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-1.8B-Chat-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Qwen1.5-1.8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen1.5-1.8B-GGUF/resolve/main/Qwen1.5-1.8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-1.8B-Q8_0.gguf"
      },
      {
        "model_id": "Qwen/Qwen1.5-1.8B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 2114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen1.5-1.8B-Chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen1.5-1.8B-Chat-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 2.47,
    "ram_recommended_gb": 3.1,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.47,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.8,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat"
  },
  {
    "model_id": "internlm/internlm2-chat-7b",
    "label": "Internlm2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 55928,
    "likes": 83,
    "last_updated": "2025-03-13T07:04:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "internlm2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.022764543630892677,
      "math": 0.013658726178535606,
      "story": 0.004552908726178535,
      "roleplay": 0.004552908726178535
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "internlm/internlm2-7b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/internlm/internlm2-chat-7b"
  },
  {
    "model_id": "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    "label": "Exaone 3.0 7.8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 55494,
    "likes": 411,
    "last_updated": "2024-08-08T04:16:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "exaone-3-0-7-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22642857142857142,
      "code": 0.02473294884653962,
      "math": 0.014839769307923772,
      "story": 0.004946589769307924,
      "roleplay": 0.004946589769307924
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Bingsu/exaone-3.0-7.8b-it",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Bingsu/exaone-3.0-7.8b-it/resolve/main/exaone-3.0-7.8B-it-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "exaone-3.0-7.8B-it-Q8_0.gguf"
      },
      {
        "model_id": "bartowski/EXAONE-3.0-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/EXAONE-3.0-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.0-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.0-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "second-state/EXAONE-3.0-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/EXAONE-3.0-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.0-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.0-7.8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "gaianet/EXAONE-3.0-7.8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/EXAONE-3.0-7.8B-Instruct-GGUF/resolve/main/EXAONE-3.0-7.8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "EXAONE-3.0-7.8B-Instruct-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.54,
    "ram_recommended_gb": 13.18,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.8,
    "tier": "high",
    "model_url": "https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"
  },
  {
    "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
    "label": "Meta Llama 3 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 54585,
    "likes": 1491,
    "last_updated": "2025-06-18T23:49:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.245,
      "code": 0.023648445336008024,
      "math": 0.014189067201604814,
      "story": 0.004729689067201605,
      "roleplay": 0.004729689067201605
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Meta-Llama-3-70B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Meta-Llama-3-70B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39792965496,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "NousResearch/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/NousResearch/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q3_K_S.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 3,
        "format": "gguf",
        "size_bytes": 29714572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q3_K_S.gguf"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-70B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-70B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39806462280,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-70B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-70B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-70B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-70B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996256,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996256
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-IQ1_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 16751195552,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-IQ1_M.gguf"
      },
      {
        "model_id": "NousResearch/Meta-Llama-3-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/NousResearch/Meta-Llama-3-70B-GGUF/resolve/main/Meta-Llama-3-70B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 38814572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-70B-Instruct-GGUF-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-70B-Instruct-GGUF-v2/resolve/main/Meta-Llama-3-70B-Instruct-v2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-v2.Q2_K.gguf"
      },
      {
        "model_id": "TechxGenus/Meta-Llama-3-70B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/Meta-Llama-3-70B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996256,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996256
      },
      {
        "model_id": "LoneStriker/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "ThomasBaruzier/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "PawanKrd/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/PawanKrd/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/llama-3-70b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-70b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-70B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-70B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "LiteLLMs/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Q2_K/Q2_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Q2_K/Q2_K-00001-of-00001.gguf"
      },
      {
        "model_id": "nitsuai/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nitsuai/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Meta-Llama-3-70B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Meta-Llama-3-70B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/Meta-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Meta-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Meta-Llama-3-70B-Instruct-GGUF/resolve/main/meta-llama-3-70b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "meta-llama-3-70b-instruct.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 43.18,
    "ram_recommended_gb": 53.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 43.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct"
  },
  {
    "model_id": "meta-llama/Llama-2-70b-chat-hf",
    "label": "Llama 2 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 53990,
    "likes": 2193,
    "last_updated": "2024-04-17T08:41:06+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-2-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.023159478435305917,
      "math": 0.01389568706118355,
      "story": 0.004631895687061184,
      "roleplay": 0.004631895687061184
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-2-70b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-2-70b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/Llama-2-70B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 35332232320,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-70B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 36613879656,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 36613879656
      },
      {
        "model_id": "TheBloke/Llama-2-70B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 35332232320,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/Llama-2-70B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGUF/resolve/main/llama-2-70b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-70b-chat.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Llama-2-70B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 36613879656,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 36613879656
      },
      {
        "model_id": "TheBloke/Llama-2-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Llama-2-70B-GGUF/resolve/main/llama-2-70b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-2-70b.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Llama-2-70B-fp16-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 56314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "localmodels/Llama-2-70B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/localmodels/Llama-2-70B-GPTQ/resolve/main/gptq_model-4bit--1g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit--1g.safetensors"
      },
      {
        "model_id": "4bit/Llama-2-70b-chat-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "localmodels/Llama-2-70B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/localmodels/Llama-2-70B-Chat-GPTQ/resolve/main/gptq_model-4bit--1g.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "gptq_model-4bit--1g.safetensors"
      }
    ],
    "ram_estimate_gb": 51.58,
    "ram_recommended_gb": 64.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 51.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
  },
  {
    "model_id": "HuggingFaceTB/SmolLM2-1.7B-Instruct",
    "label": "Smollm2 1.7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 53908,
    "likes": 662,
    "last_updated": "2025-04-21T20:51:14+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smollm2-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2439285714285714,
      "code": 0.022990220661985958,
      "math": 0.013794132397191574,
      "story": 0.004598044132397192,
      "roleplay": 0.004598044132397192
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "HuggingFaceTB/SmolLM2-1.7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3422777952,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424735936,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1674572800,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF/resolve/main/smollm2-1.7b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1249572800,
        "notes": null,
        "revision": "main",
        "filename": "smollm2-1.7b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "unsloth/SmolLM2-1.7B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/SmolLM2-1.7B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1334572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Mungert/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424736480,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-bf16.gguf"
      },
      {
        "model_id": "second-state/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424736096,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424736096,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-f16.gguf"
      },
      {
        "model_id": "tensorblock/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 824572800,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 824572800,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "unsloth/SmolLM2-1.7B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/SmolLM2-1.7B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1334572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/SmolLM2-1.7B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/SmolLM2-1.7B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3422777902,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 3422777902
      },
      {
        "model_id": "prithivMLmods/SmolLM2-1.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/SmolLM2-1.7B-GGUF/resolve/main/SmolLM2-1.7B.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424735392,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B.F16.gguf"
      },
      {
        "model_id": "prithivMLmods/SmolLM2-1.7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/prithivMLmods/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct.F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3424735808,
        "notes": null,
        "revision": "main",
        "filename": "SmolLM2-1.7B-Instruct.F16.gguf"
      }
    ],
    "ram_estimate_gb": 2.4,
    "ram_recommended_gb": 3.01,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.4,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.7,
    "tier": "high",
    "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct"
  },
  {
    "model_id": "hugging-quants/Llama-3.2-1B-Instruct-Q4_K_M-GGUF",
    "label": "Llama 3.2 1B K M",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "q4_k_m"
    ],
    "dropped_tags": [
      "q4_k_m"
    ],
    "downloads": 52744,
    "likes": 16,
    "last_updated": "2024-09-25T16:15:26+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "llama-3-2-1b-q4-k-m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2390857142857143,
      "code": 0.0212913741223671,
      "math": 0.01277482447342026,
      "story": 0.00425827482447342,
      "roleplay": 0.00425827482447342
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "aashish1904/Llama-3.2-1B-Instruct-Q4_K_M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/aashish1904/Llama-3.2-1B-Instruct-Q4_K_M-GGUF/resolve/main/llama-3.2-1b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "Solshine/Llama-3.2-1B-Q4_K_M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Solshine/Llama-3.2-1B-Q4_K_M-GGUF/resolve/main/llama-3.2-1b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-q4_k_m.gguf"
      },
      {
        "model_id": "itlwas/Llama-3.2-1B-Q4_K_M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/itlwas/Llama-3.2-1B-Q4_K_M-GGUF/resolve/main/llama-3.2-1b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-q4_k_m.gguf"
      },
      {
        "model_id": "itlwas/Llama-3.2-1B-Instruct-Q4_K_M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/itlwas/Llama-3.2-1B-Instruct-Q4_K_M-GGUF/resolve/main/llama-3.2-1b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct-q4_k_m.gguf"
      }
    ],
    "ram_estimate_gb": 1.84,
    "ram_recommended_gb": 2.3,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.84,
    "quant_bits": 4,
    "format": "gguf",
    "quant_class": "gguf-q4",
    "size_hint": "<2B",
    "params_b": 1.0,
    "tier": "high",
    "model_url": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q4_K_M-GGUF"
  },
  {
    "model_id": "unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
    "label": "Qwen3 Coder 30B A3B 1M",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 49711,
    "likes": 87,
    "last_updated": "2025-08-05T11:09:59+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "a3b",
    "canonical_base": "qwen3-coder-30b-a3b-1m",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.32727269926855423,
      "code": 0.2629797277731865,
      "math": 0.054671423923374075,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 60.8,
    "ram_recommended_gb": 76.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 60.8,
    "quant_class": "a3b",
    "format": "gguf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF"
  },
  {
    "model_id": "deepseek-ai/deepseek-coder-1.3b-instruct",
    "label": "Deepseek Coder 1.3B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 48207,
    "likes": 137,
    "last_updated": "2024-03-07T13:23:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-coder-1-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.11232142857142857,
      "math": 0.02375702106318957,
      "story": 0.00491900702106319,
      "roleplay": 0.00491900702106319
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/deepseek-coder-1.3b-instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 898108792,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/deepseek-coder-1.3b-instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 895344952,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Xenova/deepseek-coder-1.3b-instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 3.4,
    "ram_recommended_gb": 4.25,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.4,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.3,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct"
  },
  {
    "model_id": "01-ai/Yi-34B-Chat",
    "label": "Yi 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 47661,
    "likes": 356,
    "last_updated": "2024-11-11T03:36:35+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "yi-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.025522818455366098,
      "math": 0.015313691073219659,
      "story": 0.00510456369107322,
      "roleplay": 0.00510456369107322
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-34B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/01-ai/Yi-34B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 68777897896,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 68777897896
      },
      {
        "model_id": "TheBloke/Yi-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Yi-34B-Chat-GGUF/resolve/main/yi-34b-chat.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "yi-34b-chat.Q4_K_M.gguf"
      },
      {
        "model_id": "TheBloke/Yi-34B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Yi-34B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/Yi-34B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Yi-34B-Chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Yi-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-34B-Chat-GGUF/resolve/main/Yi-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Yi-34B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Yi-34B-GGUF/resolve/main/Yi-34B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-34B-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Yi-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Yi-34B-Chat-GGUF/resolve/main/Yi-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "TheBloke/Yi-34B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Yi-34B-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 25.66,
    "ram_recommended_gb": 32.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 25.66,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-34B-Chat"
  },
  {
    "model_id": "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
    "label": "Tinyllama 1.1B Intermediate Step 1431K 3T",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 45448,
    "likes": 178,
    "last_updated": "2024-09-27T22:46:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "tinyllama-1-1b-intermediate-step-1431k-3t",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02586133400200602,
      "math": 0.015516800401203611,
      "story": 0.0051722668004012045,
      "roleplay": 0.0051722668004012045
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "andrijdavid/TinyLlama-1.1B-intermediate-step-1431k-3T-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/andrijdavid/TinyLlama-1.1B-intermediate-step-1431k-3T-GGUF/resolve/main/TinyLlama-1.1B-intermediate-step-1431k-3T-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2201016800,
        "notes": null,
        "revision": "main",
        "filename": "TinyLlama-1.1B-intermediate-step-1431k-3T-f16.gguf"
      },
      {
        "model_id": "afrideva/TinyLlama-1.1B-intermediate-step-1431k-3T-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/TinyLlama-1.1B-intermediate-step-1431k-3T-GGUF/resolve/main/tinyllama-1.1b-intermediate-step-1431k-3t.fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 2201990016,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-intermediate-step-1431k-3t.fp16.gguf"
      },
      {
        "model_id": "chgk13/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 3.0,
    "ram_recommended_gb": 3.75,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.1,
    "tier": "high",
    "model_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T"
  },
  {
    "model_id": "Qwen/Qwen2-72B-Instruct",
    "label": "Qwen2 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 44479,
    "likes": 716,
    "last_updated": "2024-10-08T05:16:14+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.022990220661985958,
      "math": 0.013794132397191574,
      "story": 0.004598044132397192,
      "roleplay": 0.004598044132397192
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2-72B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-72B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 145412518888,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 145412518888
      },
      {
        "model_id": "Qwen/Qwen2-72B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2-72B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 41595756104,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 41595756104
      },
      {
        "model_id": "unsloth/Qwen2-72B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-72B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/Qwen2-72B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2-72B-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen2-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct-GGUF/resolve/main/qwen2-72b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-72b-instruct-q2_k.gguf"
      },
      {
        "model_id": "bartowski/Qwen2-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2-72B-Instruct-GGUF/resolve/main/Qwen2-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-72B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Qwen2-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2-72B-Instruct-GGUF/resolve/main/Qwen2-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2-72B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-72B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 53.02,
    "ram_recommended_gb": 66.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 53.02,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct"
  },
  {
    "model_id": "bigcode/starcoder2-7b",
    "label": "Starcoder2 7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 43480,
    "likes": 186,
    "last_updated": "2024-06-11T08:15:50+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "starcoder2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07159227683049148,
      "code": 0.11232142857142857,
      "math": 0.021477683049147444,
      "story": 0.004159227683049148,
      "roleplay": 0.004159227683049148
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/StarCoder2-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/StarCoder2-7B-GGUF/resolve/main/starcoder2-7b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b-Q2_K.gguf"
      },
      {
        "model_id": "TechxGenus/starcoder2-7b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/starcoder2-7b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14347905512,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14347905512
      },
      {
        "model_id": "QuantFactory/starcoder2-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/starcoder2-7b-instruct-GGUF/resolve/main/starcoder2-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "nold/starcoder2-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nold/starcoder2-7b-GGUF/resolve/main/starcoder2-7b_Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b_Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/starcoder2-7b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/starcoder2-7b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/starcoder2-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/starcoder2-7b-GGUF/resolve/main/starcoder2-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/starcoder2-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/starcoder2-7b-GGUF/resolve/main/starcoder2-7b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/starcoder2-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/starcoder2-7b-instruct-GGUF/resolve/main/starcoder2-7b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/starcoder2-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/starcoder2-7b-GGUF/resolve/main/starcoder2-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "starcoder2-7b.Q2_K.gguf"
      },
      {
        "model_id": "TechxGenus/starcoder2-7b-instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TechxGenus/starcoder2-7b-instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4523270456,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bigcode/starcoder2-7b"
  },
  {
    "model_id": "K-intelligence/Midm-2.0-Base-Instruct",
    "label": "Midm 2.0 Base",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 42383,
    "likes": 117,
    "last_updated": "2025-08-11T08:12:17+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "midm-2-0-base",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.02591775325977934,
      "math": 0.015550651955867602,
      "story": 0.005183550651955868,
      "roleplay": 0.005183550651955868
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/Midm-2.0-Base-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Midm-2.0-Base-Instruct-GGUF/resolve/main/Midm-2.0-Base-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 23097821216,
        "notes": null,
        "revision": "main",
        "filename": "Midm-2.0-Base-Instruct-bf16.gguf"
      },
      {
        "model_id": "mykor/Midm-2.0-Base-Instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mykor/Midm-2.0-Base-Instruct-gguf/resolve/main/Midm-2.0-Base-Instruct-F32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 46188382080,
        "notes": null,
        "revision": "main",
        "filename": "Midm-2.0-Base-Instruct-F32.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/K-intelligence/Midm-2.0-Base-Instruct"
  },
  {
    "model_id": "Salesforce/codegen-350M-mono",
    "label": "Codegen 350M Mono",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 41169,
    "likes": 96,
    "last_updated": "2025-01-31T20:16:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegen-350m-mono",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07356068204613841,
      "code": 0.11607142857142858,
      "math": 0.022068204613841524,
      "story": 0.004356068204613842,
      "roleplay": 0.004356068204613842
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Xenova/codegen-350M-mono",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 1.5,
    "ram_recommended_gb": 1.88,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 1.5,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.35,
    "tier": "high",
    "model_url": "https://huggingface.co/Salesforce/codegen-350M-mono"
  },
  {
    "model_id": "PowerInfer/SmallThinker-21BA3B-Instruct-GGUF",
    "label": "Smallthinker 21Ba3B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 40810,
    "likes": 31,
    "last_updated": "2025-08-05T01:14:18+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "smallthinker-21ba3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.022043630892678034,
      "math": 0.01322617853560682,
      "story": 0.004408726178535607,
      "roleplay": 0.004408726178535607
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/SmallThinker-21BA3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/SmallThinker-21BA3B-Instruct-GGUF/resolve/main/SmallThinker-21BA3B-Instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 43036667296,
        "notes": null,
        "revision": "main",
        "filename": "SmallThinker-21BA3B-Instruct-bf16.gguf"
      },
      {
        "model_id": "PowerInfer/SmallThinker-21BA3B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "gabriellarson/SmallThinker-21BA3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gabriellarson/SmallThinker-21BA3B-Instruct-GGUF/resolve/main/SmallThinker-21BA3B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "SmallThinker-21BA3B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF"
  },
  {
    "model_id": "microsoft/Phi-3-vision-128k-instruct",
    "label": "Phi 3 Vision 128K",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 39091,
    "likes": 964,
    "last_updated": "2024-08-20T19:56:22+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-vision-128k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.11607142857142858,
      "math": 0.02438891675025075,
      "story": 0.005129638916750251,
      "roleplay": 0.005129638916750251
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Phi-3-vision-128k-instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-vision-128k-instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2334279759,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 2334279759
      },
      {
        "model_id": "mlx-community/Phi-3-vision-128k-instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Phi-3-vision-128k-instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4407020396,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4407020396
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3-vision-128k-instruct"
  },
  {
    "model_id": "h2oai/h2o-danube3-4b-chat",
    "label": "H2O Danube3 4B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 39062,
    "likes": 67,
    "last_updated": "2024-07-15T06:52:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "h2o-danube3-4b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02379889669007021,
      "math": 0.014279338014042124,
      "story": 0.0047597793380140425,
      "roleplay": 0.0047597793380140425
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "h2oai/h2o-danube3-4b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/h2oai/h2o-danube3-4b-chat-GGUF/resolve/main/h2o-danube3-4b-chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "h2o-danube3-4b-chat-Q4_K_M.gguf"
      },
      {
        "model_id": "bartowski/h2o-danube3-4b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/h2o-danube3-4b-chat-GGUF/resolve/main/h2o-danube3-4b-chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "h2o-danube3-4b-chat-Q4_K_M.gguf"
      },
      {
        "model_id": "mav23/h2o-danube3-4b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/h2o-danube3-4b-chat-GGUF/resolve/main/h2o-danube3-4b-chat.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "h2o-danube3-4b-chat.Q4_K_M.gguf"
      },
      {
        "model_id": "DevQuasar/h2o-danube3-4b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/h2o-danube3-4b-chat-GGUF/resolve/main/h2o-danube3-4b-chat.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "h2o-danube3-4b-chat.Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/h2o-danube3-4b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/h2o-danube3-4b-chat-GGUF/resolve/main/h2o-danube3-4b-chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "h2o-danube3-4b-chat-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 3.82,
    "ram_recommended_gb": 4.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.82,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 4.0,
    "tier": "high",
    "model_url": "https://huggingface.co/h2oai/h2o-danube3-4b-chat"
  },
  {
    "model_id": "gradientai/Llama-3-8B-Instruct-Gradient-1048k",
    "label": "Llama 3 8B Gradient 1048K",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 38811,
    "likes": 678,
    "last_updated": "2024-10-29T16:13:18+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-8b-gradient-1048k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02431293881644935,
      "math": 0.014587763289869608,
      "story": 0.00486258776328987,
      "roleplay": 0.00486258776328987
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf"
      },
      {
        "model_id": "bartowski/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf"
      },
      {
        "model_id": "LiteLLMs/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Q8_0/Q8_0-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Q8_0/Q8_0-00001-of-00001.gguf"
      },
      {
        "model_id": "mav23/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/llama-3-8b-instruct-gradient-1048k.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-8b-instruct-gradient-1048k.Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-Gradient-1048k.Q8_0.gguf"
      },
      {
        "model_id": "vsevolodl/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/vsevolodl/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-Gradient-1048k.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-8B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-8B-Instruct-Gradient-1048k-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k"
  },
  {
    "model_id": "TinyLlama/TinyLlama_v1.1",
    "label": "Tinyllama",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 38668,
    "likes": 102,
    "last_updated": "2024-06-07T01:23:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "tinyllama",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.024457121364092275,
      "math": 0.014674272818455365,
      "story": 0.0048914242728184554,
      "roleplay": 0.0048914242728184554
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Maykeye/TinyLLama-v0",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "unsloth/tinyllama-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/tinyllama-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 762453544,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/tinyllama-chat-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/tinyllama-chat-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 762453371,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "cortexso/tinyllama",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cortexso/tinyllama/resolve/main/tinyllama-1.1b-chat-v1.0-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 432132160,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-chat-v1.0-q2_k.gguf"
      },
      {
        "model_id": "aladar/TinyLLama-v0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/aladar/TinyLLama-v0-GGUF/resolve/main/TinyLLama-v0.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 10007552,
        "notes": null,
        "revision": "main",
        "filename": "TinyLLama-v0.f16.gguf"
      },
      {
        "model_id": "afrideva/TinyLLama-v0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/TinyLLama-v0-GGUF/resolve/main/tinyllama-v0.fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 11081760,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-v0.fp16.gguf"
      },
      {
        "model_id": "PaddySeahorse/tinyllama-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/PaddySeahorse/tinyllama-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 807426286,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Durlabh/tinyllama",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Durlabh/tinyllama/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 668788096,
        "notes": null,
        "revision": "main",
        "filename": "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/TinyLlama/TinyLlama_v1.1"
  },
  {
    "model_id": "internlm/internlm2_5-7b-chat",
    "label": "Internlm2 5 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 37848,
    "likes": 198,
    "last_updated": "2025-03-13T07:04:49+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "internlm2-5-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.024093530591775325,
      "math": 0.014456118355065195,
      "story": 0.004818706118355065,
      "roleplay": 0.004818706118355065
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "internlm/internlm2_5-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/internlm/internlm2_5-7b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15475442896,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15475442896
      },
      {
        "model_id": "internlm/internlm2_5-7b-chat-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/internlm/internlm2_5-7b-chat-gguf/resolve/main/internlm2_5-7b-chat-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092608,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-fp16.gguf"
      },
      {
        "model_id": "internlm/internlm2_5-7b-chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "second-state/internlm2_5-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/internlm2_5-7b-chat-GGUF/resolve/main/internlm2_5-7b-chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092608,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-f16.gguf"
      },
      {
        "model_id": "mlx-community/internlm2_5-7b-chat-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/internlm2_5-7b-chat-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "gaianet/internlm2_5-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/internlm2_5-7b-chat-GGUF/resolve/main/internlm2_5-7b-chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092608,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-f16.gguf"
      },
      {
        "model_id": "bartowski/internlm2_5-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/internlm2_5-7b-chat-GGUF/resolve/main/internlm2_5-7b-chat-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 30952977248,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-f32.gguf"
      },
      {
        "model_id": "mav23/internlm2_5-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/internlm2_5-7b-chat-GGUF/resolve/main/internlm2_5-7b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/internlm2_5-7b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/internlm2_5-7b-chat-GGUF/resolve/main/internlm2_5-7b-chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 9.58,
    "ram_recommended_gb": 11.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/internlm/internlm2_5-7b-chat"
  },
  {
    "model_id": "Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8",
    "label": "Qwen3 Coder 30B A3B Fp8",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 37510,
    "likes": 52,
    "last_updated": "2025-08-07T07:04:49+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "canonical_base": "qwen3-coder-30b-a3b-fp8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.3196798886005112,
      "code": 0.2576871877880832,
      "math": 0.061255480889849605,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 60.8,
    "ram_recommended_gb": 76.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 60.8,
    "quant_method": "a3b",
    "quant_class": "a3b",
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"
  },
  {
    "model_id": "nvidia/Llama-3.1-Nemotron-8B-UltraLong-4M-Instruct",
    "label": "Llama 3.1 Nemotron 8B Ultralong 4M",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 37487,
    "likes": 117,
    "last_updated": "2025-04-17T03:57:20+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-nemotron-8b-ultralong-4m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.022018555667001005,
      "math": 0.013211133400200603,
      "story": 0.004403711133400201,
      "roleplay": 0.004403711133400201
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "LogicBombaklot/Llama-3.1-Nemotron-8B-UltraLong-4M-Instruct-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LogicBombaklot/Llama-3.1-Nemotron-8B-UltraLong-4M-Instruct-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-8B-UltraLong-4M-Instruct"
  },
  {
    "model_id": "ibm-granite/granite-3.1-8b-instruct",
    "label": "Granite 3.1 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 36422,
    "likes": 162,
    "last_updated": "2025-04-16T14:57:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-1-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.022657973921765297,
      "math": 0.013594784353059178,
      "story": 0.00453159478435306,
      "roleplay": 0.00453159478435306
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "RedHatAI/granite-3.1-8b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/RedHatAI/granite-3.1-8b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 16341738616,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16341738616
      },
      {
        "model_id": "lmstudio-community/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "Mungert/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "bartowski/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "Alcoft/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct_Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct_Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/granite-3.1-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/granite-3.1-8b-instruct-GGUF/resolve/main/granite-3.1-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "EasierAI/Granite-3.1-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/EasierAI/Granite-3.1-8B/resolve/main/Granite-3.1-8B-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Granite-3.1-8B-instruct-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.1-8b-instruct"
  },
  {
    "model_id": "openthaigpt/openthaigpt1.5-14b-instruct",
    "label": "Openthaigpt1.5 14B",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 35317,
    "likes": 6,
    "last_updated": "2024-11-15T04:55:37+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "openthaigpt1-5-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.29370317441444366,
      "code": 0.01697349274347047,
      "math": 0.008458056028446275,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 8.5,
    "ram_recommended_gb": 10.63,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.5,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/openthaigpt/openthaigpt1.5-14b-instruct"
  },
  {
    "model_id": "utter-project/EuroLLM-1.7B-Instruct",
    "label": "Eurollm 1.7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 35105,
    "likes": 77,
    "last_updated": "2024-12-16T12:46:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "eurollm-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.022319458375125376,
      "math": 0.013391675025075225,
      "story": 0.004463891675025075,
      "roleplay": 0.004463891675025075
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "utter-project/EuroLLM-1.7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/utter-project/EuroLLM-1.7B/resolve/main/pytorch_model.bin?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3313771830,
        "notes": null,
        "revision": "main",
        "filename": "pytorch_model.bin"
      }
    ],
    "ram_estimate_gb": 4.2,
    "ram_recommended_gb": 5.25,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 4.2,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.7,
    "tier": "high",
    "model_url": "https://huggingface.co/utter-project/EuroLLM-1.7B-Instruct"
  },
  {
    "model_id": "meta-llama/Llama-3.1-405B-Instruct",
    "label": "Llama 3.1 405B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 34877,
    "likes": 575,
    "last_updated": "2024-09-25T17:02:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-405b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02172392176529589,
      "math": 0.013034353059177533,
      "story": 0.004344784353059178,
      "roleplay": 0.004344784353059178
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "meta-llama/Llama-3.1-405B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/Llama-3.1-405B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.1-405B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-405B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 405314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "clowman/Llama-3.1-405B-Instruct-AWQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/clowman/Llama-3.1-405B-Instruct-AWQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 243314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 487.18,
    "ram_recommended_gb": 608.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 487.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 405.0,
    "tier": "high",
    "model_url": "https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct"
  },
  {
    "model_id": "Zyphra/Zamba2-1.2B-instruct",
    "label": "Zamba2 1.2B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 34790,
    "likes": 28,
    "last_updated": "2025-02-07T02:04:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "zamba2-1-2b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02462011033099298,
      "math": 0.014772066198595788,
      "story": 0.004924022066198596,
      "roleplay": 0.004924022066198596
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Zyphra/Zamba2-1.2B-Instruct-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Zyphra/Zamba2-1.2B-Instruct-v2/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 2430175896,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 3.2,
    "ram_recommended_gb": 4.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.2,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.2,
    "tier": "high",
    "model_url": "https://huggingface.co/Zyphra/Zamba2-1.2B-instruct"
  },
  {
    "model_id": "K-intelligence/Midm-2.0-Mini-Instruct",
    "label": "Midm 2.0 Mini",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 33387,
    "likes": 57,
    "last_updated": "2025-08-11T08:13:37+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "midm-2-0-mini",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.020219408224674024,
      "math": 0.012131644934804413,
      "story": 0.004043881644934805,
      "roleplay": 0.004043881644934805
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mykor/Midm-2.0-Mini-Instruct-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mykor/Midm-2.0-Mini-Instruct-gguf/resolve/main/Midm-2.0-Mini-Instruct-F32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 9227740160,
        "notes": null,
        "revision": "main",
        "filename": "Midm-2.0-Mini-Instruct-F32.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/K-intelligence/Midm-2.0-Mini-Instruct"
  },
  {
    "model_id": "unsloth/OpenReasoning-Nemotron-32B-GGUF",
    "label": "Openreasoning Nemotron 32B",
    "tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 32804,
    "likes": 8,
    "last_updated": "2025-07-21T20:55:30+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "openreasoning-nemotron-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07161735205616851,
      "code": 0.11928736263736264,
      "math": 0.021485205616850554,
      "story": 0.0041617352056168505,
      "roleplay": 0.0041617352056168505
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "nvidia/OpenReasoning-Nemotron-32B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "gabriellarson/OpenReasoning-Nemotron-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenReasoning-Nemotron-32B-Q2_K.gguf"
      },
      {
        "model_id": "Mungert/OpenReasoning-Nemotron-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 17914572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenReasoning-Nemotron-32B-q4_0.gguf"
      },
      {
        "model_id": "lmstudio-community/OpenReasoning-Nemotron-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/OpenReasoning-Nemotron-32B-GGUF/resolve/main/OpenReasoning-Nemotron-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenReasoning-Nemotron-32B-Q6_K.gguf"
      },
      {
        "model_id": "cpatonn/OpenReasoning-Nemotron-32B-AWQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cpatonn/OpenReasoning-Nemotron-32B-AWQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/OpenReasoning-Nemotron-32B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/OpenReasoning-Nemotron-32B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "LogicBombaklot/OpenReasoning-Nemotron-32B-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LogicBombaklot/OpenReasoning-Nemotron-32B-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 12.7,
    "ram_recommended_gb": 15.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 12.7,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/OpenReasoning-Nemotron-32B-GGUF"
  },
  {
    "model_id": "nvidia/DeepSeek-R1-FP4",
    "label": "Deepseek R1 Fp4",
    "tags": [
      "code",
      "cuda"
    ],
    "raw_tags": [
      "code",
      "cuda"
    ],
    "dropped_tags": [],
    "downloads": 28912,
    "likes": 263,
    "last_updated": "2025-06-06T16:37:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-r1-fp4",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0762813440320963,
      "code": 0.12107142857142857,
      "math": 0.022884403209628888,
      "story": 0.004628134403209629,
      "roleplay": 0.004628134403209629
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "nvidia/DeepSeek-R1-FP4-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nvidia/DeepSeek-R1-FP4-v2/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 410908748976,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 410908748976
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/DeepSeek-R1-FP4"
  },
  {
    "model_id": "ibm-granite/granite-3.0-8b-instruct",
    "label": "Granite 3.0 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 28242,
    "likes": 201,
    "last_updated": "2024-12-19T19:44:27+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-0-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.021423019057171516,
      "math": 0.01285381143430291,
      "story": 0.004284603811434303,
      "roleplay": 0.004284603811434303
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "bartowski/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "mav23/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "lmstudio-community/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/granite-3.0-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/granite-3.0-8b-instruct-GGUF/resolve/main/granite-3.0-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.0-8b-instruct-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.0-8b-instruct"
  },
  {
    "model_id": "Dream-org/Dream-v0-Instruct-7B",
    "label": "Dream 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0"
    ],
    "dropped_tags": [
      "v0"
    ],
    "downloads": 26972,
    "likes": 122,
    "last_updated": "2025-07-15T09:23:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dream-v0-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.024845787362086258,
      "math": 0.014907472417251754,
      "story": 0.004969157472417252,
      "roleplay": 0.004969157472417252
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "smoorsmith/Dream-v0-Instruct-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/smoorsmith/Dream-v0-Instruct-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15231271864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15231271864
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Dream-org/Dream-v0-Instruct-7B"
  },
  {
    "model_id": "ibm-granite/granite-3.1-3b-a800m-instruct",
    "label": "Granite 3.1 3B A800M",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 26797,
    "likes": 25,
    "last_updated": "2025-01-31T04:05:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-1-3b-a800m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.020357321965897693,
      "math": 0.012214393179538615,
      "story": 0.004071464393179539,
      "roleplay": 0.004071464393179539
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6603463232,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct-f16.gguf"
      },
      {
        "model_id": "Mungert/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6603463648,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct-bf16.gguf"
      },
      {
        "model_id": "Alcoft/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6603463168,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct_f16.gguf"
      },
      {
        "model_id": "tensorblock/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/granite-3.1-3b-a800m-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.1-3b-a800m-instruct-GGUF/resolve/main/granite-3.1-3b-a800m-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-3b-a800m-instruct-Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.1-3b-a800m-instruct"
  },
  {
    "model_id": "tiiuae/falcon-mamba-7b-instruct",
    "label": "Falcon Mamba 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 26671,
    "likes": 68,
    "last_updated": "2024-12-17T11:11:40+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon-mamba-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02196840521564694,
      "math": 0.013181043129388165,
      "story": 0.004393681043129388,
      "roleplay": 0.004393681043129388
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tiiuae/falcon-mamba-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/falcon-mamba-7b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14545401832,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14545401832
      },
      {
        "model_id": "bartowski/falcon-mamba-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/falcon-mamba-7b-GGUF/resolve/main/falcon-mamba-7b-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14572304096,
        "notes": null,
        "revision": "main",
        "filename": "falcon-mamba-7b-f16.gguf"
      },
      {
        "model_id": "tensorblock/falcon-mamba-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/falcon-mamba-7b-instruct-GGUF/resolve/main/falcon-mamba-7b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "falcon-mamba-7b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/falcon-mamba-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/falcon-mamba-7b-instruct-GGUF/resolve/main/falcon-mamba-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "falcon-mamba-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "tiiuae/falcon-mamba-7b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/falcon-mamba-7b-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/falcon-mamba-7b-8bit-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/falcon-mamba-7b-8bit-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 9.58,
    "ram_recommended_gb": 11.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/falcon-mamba-7b-instruct"
  },
  {
    "model_id": "bartowski/magnum-v4-12b-GGUF",
    "label": "Magnum 12B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small",
      "v4"
    ],
    "dropped_tags": [
      "v4"
    ],
    "downloads": 26605,
    "likes": 7,
    "last_updated": "2024-10-20T19:15:39+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "magnum-v4-12b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.22684395604395607,
      "code": 0.025761033099297892,
      "math": 0.015456619859578734,
      "story": 0.005152206619859579,
      "roleplay": 0.005152206619859579
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "anthracite-org/magnum-v4-12b-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/anthracite-org/magnum-v4-12b-gguf/resolve/main/magnum-v4-12b-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "magnum-v4-12b-Q4_K_M.gguf"
      },
      {
        "model_id": "anthracite-org/magnum-v4-12b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/magnum-v4-12b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/magnum-v4-12b-GGUF/resolve/main/magnum-v4-12b-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "magnum-v4-12b-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/magnum-v4-12b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/magnum-v4-12b-GGUF/resolve/main/magnum-v4-12b.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "magnum-v4-12b.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 9.1,
    "ram_recommended_gb": 11.38,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.1,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "13B",
    "params_b": 12.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/magnum-v4-12b-GGUF"
  },
  {
    "model_id": "baichuan-inc/Baichuan2-7B-Chat",
    "label": "Baichuan2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 26582,
    "likes": 166,
    "last_updated": "2024-02-26T08:58:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "baichuan2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02210631895687061,
      "math": 0.013263791374122366,
      "story": 0.004421263791374122,
      "roleplay": 0.004421263791374122
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "shaowenchen/baichuan2-7b-chat-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shaowenchen/baichuan2-7b-chat-gguf/resolve/main/baichuan2-7b-chat.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15015357728,
        "notes": null,
        "revision": "main",
        "filename": "baichuan2-7b-chat.gguf"
      },
      {
        "model_id": "second-state/Baichuan2-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Baichuan2-7B-Chat-GGUF/resolve/main/Baichuan2-7B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Baichuan2-7B-Chat-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat"
  },
  {
    "model_id": "tiiuae/Falcon3-7B-Instruct",
    "label": "Falcon3 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 26450,
    "likes": 72,
    "last_updated": "2025-05-31T08:24:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon3-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.023504262788365097,
      "math": 0.014102557673019057,
      "story": 0.00470085255767302,
      "roleplay": 0.00470085255767302
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tiiuae/Falcon3-7B-Instruct-1.58bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/Falcon3-7B-Instruct-1.58bit/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3273630320,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tiiuae/Falcon3-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/Falcon3-7B-Instruct-GGUF/resolve/main/Falcon3-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14916197792,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "bartowski/Falcon3-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Falcon3-7B-Instruct-GGUF/resolve/main/Falcon3-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14916197568,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Falcon3-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Falcon3-7B-Instruct-GGUF/resolve/main/Falcon3-7B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-7B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "second-state/Falcon3-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Falcon3-7B-Instruct-GGUF/resolve/main/Falcon3-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14916197568,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Falcon3-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Falcon3-7B-Instruct-GGUF/resolve/main/Falcon3-7B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14916197568,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-7B-Instruct-f16.gguf"
      },
      {
        "model_id": "alekgomez/Falcon3-7B-Instruct-4bit-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/alekgomez/Falcon3-7B-Instruct-4bit-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/Falcon3-7B-Instruct"
  },
  {
    "model_id": "tiiuae/Falcon3-10B-Instruct",
    "label": "Falcon3 10B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 25141,
    "likes": 114,
    "last_updated": "2025-01-14T11:53:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon3-10b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02250752256770311,
      "math": 0.013504513540621864,
      "story": 0.004501504513540622,
      "roleplay": 0.004501504513540622
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tiiuae/Falcon3-10B-Instruct-1.58bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/Falcon3-10B-Instruct-1.58bit/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 3986209008,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 20616557984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct-f16.gguf"
      },
      {
        "model_id": "tiiuae/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 20616558208,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "second-state/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 20616557984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 20616557984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct-f16.gguf"
      },
      {
        "model_id": "mlx-community/Falcon3-10B-Instruct-1.58bit-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Falcon3-10B-Instruct-1.58bit-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 10314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "alfonsogarciacaro/Falcon3-10B-Instruct-1.58bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 10314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "MaziyarPanahi/Falcon3-10B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Falcon3-10B-Instruct-GGUF/resolve/main/Falcon3-10B-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-10B-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "nebuxcloud/Falcon3-10B-Instruct-1.58bit-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 10314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Falcon3-10B-Instruct-1.58bit-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Falcon3-10B-Instruct-1.58bit-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 13.18,
    "ram_recommended_gb": 16.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 13.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "10B",
    "params_b": 10.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/Falcon3-10B-Instruct"
  },
  {
    "model_id": "alexm-nm/tinyllama-24-marlin24-4bit-g128",
    "label": "Tinyllama 24 Marlin24 4Bit G128",
    "tags": [
      "chat",
      "cuda",
      "gptq",
      "small"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "gptq",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 25058,
    "likes": 1,
    "last_updated": "2024-05-08T13:37:29+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gptq",
    "quant_bits": 4,
    "canonical_base": "tinyllama-24-marlin24-g128",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.20768791208791207,
      "code": 0.022752006018054164,
      "math": 0.013651203610832498,
      "story": 0.004550401203610833,
      "roleplay": 0.004550401203610833
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "alexm-nm/tinyllama-24-marlin24-8bit-g128",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gptq",
    "quant_class": "gptq-q4",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/alexm-nm/tinyllama-24-marlin24-4bit-g128"
  },
  {
    "model_id": "bartowski/Ministral-8B-Instruct-2410-GGUF",
    "label": "Ministral 8B 2410",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 24642,
    "likes": 48,
    "last_updated": "2024-10-21T17:27:47+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "ministral-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23722857142857146,
      "code": 0.025491474423269808,
      "math": 0.015294884653961885,
      "story": 0.005098294884653962,
      "roleplay": 0.005098294884653962
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/Ministral-8B-Instruct-2410-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Ministral-8B-Instruct-2410-GGUF/resolve/main/Ministral-8B-Instruct-2410.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Ministral-8B-Instruct-2410.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Ministral-8B-Instruct-2410-GGUF"
  },
  {
    "model_id": "tiiuae/Falcon3-3B-Instruct",
    "label": "Falcon3 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 24158,
    "likes": 26,
    "last_updated": "2025-01-10T06:58:36+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon3-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02325977933801404,
      "math": 0.013955867602808425,
      "story": 0.004651955867602808,
      "roleplay": 0.004651955867602808
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Falcon3-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Falcon3-3B-Instruct-GGUF/resolve/main/Falcon3-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6460329984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "second-state/Falcon3-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Falcon3-3B-Instruct-GGUF/resolve/main/Falcon3-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6460329984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Falcon3-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Falcon3-3B-Instruct-GGUF/resolve/main/Falcon3-3B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6460329984,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-3B-Instruct-f16.gguf"
      },
      {
        "model_id": "tiiuae/Falcon3-3B-Instruct-1.58bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct-1.58bit/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 2216482588,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/Falcon3-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Falcon3-3B-Instruct-GGUF/resolve/main/Falcon3-3B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-3B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Falcon3-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Falcon3-3B-Instruct-GGUF/resolve/main/Falcon3-3B-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 2714572800,
        "notes": null,
        "revision": "main",
        "filename": "Falcon3-3B-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "nebuxcloud/Falcon3-3B-Instruct-1.58bit-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 4.78,
    "ram_recommended_gb": 5.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 4.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct"
  },
  {
    "model_id": "RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16",
    "label": "Meta Llama 3.1 8B Quantized.W4A16",
    "tags": [
      "chat",
      "cuda",
      "gptq"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "gptq"
    ],
    "dropped_tags": [],
    "downloads": 23894,
    "likes": 29,
    "last_updated": "2025-05-30T20:15:45+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gptq",
    "quant_bits": 8,
    "canonical_base": "meta-llama-3-1-8b-quantized-w4a16",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.32437944161935606,
      "code": 0.017899080618403455,
      "math": 0.011148422821643453,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 9.2,
    "ram_recommended_gb": 11.51,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 9.2,
    "format": "gptq",
    "quant_class": "gptq",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16"
  },
  {
    "model_id": "DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF",
    "label": "Llama 3.2 8X4B Dark Champion Uncensored Abliterated 21B",
    "tags": [
      "chat",
      "gguf",
      "moe",
      "mps",
      "roleplay",
      "story"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "moe",
      "mps",
      "roleplay",
      "story",
      "v2"
    ],
    "dropped_tags": [
      "v2"
    ],
    "downloads": 23478,
    "likes": 76,
    "last_updated": "2025-07-28T00:17:56+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "llama-3-2-8x4b-moe-v2-dark-champion-uncensored-ablerated-21b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.02450100300902708,
      "math": 0.014700601805416248,
      "story": 0.024722857142857144,
      "roleplay": 0.024722857142857144
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Eric1227/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B_MLX_8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Eric1227/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B_MLX_8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 23537533261,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 23537533261
      }
    ],
    "ram_estimate_gb": 5.98,
    "ram_recommended_gb": 7.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.98,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 4.0,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/Llama-3.2-8X4B-MOE-V2-Dark-Champion-Instruct-uncensored-abliterated-21B-GGUF"
  },
  {
    "model_id": "bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF",
    "label": "Cognitivecomputations Dolphin Mistral 24B Venice Edition",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 23213,
    "likes": 32,
    "last_updated": "2025-07-07T22:30:02+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "cognivecomputations-dolphin-mistral-24b-venice-edion",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.025008776328986963,
      "math": 0.015005265797392177,
      "story": 0.005001755265797393,
      "roleplay": 0.005001755265797393
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.0,
    "ram_recommended_gb": 17.51,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin-Mistral-24B-Venice-Edition-GGUF",
    "variants": [
      {
        "model_id": "DevQuasar/cognitivecomputations.Dolphin-Mistral-24B-Venice-Edition-GGUF",
        "format": "gguf",
        "quant_method": "gguf",
        "quant_bits": 4,
        "filename": "cognitivecomputations.Dolphin-Mistral-24B-Venice-Edition.Q4_K_M.gguf",
        "source": "huggingface",
        "revision": "main",
        "download_url": "https://huggingface.co/DevQuasar/cognitivecomputations.Dolphin-Mistral-24B-Venice-Edition-GGUF/resolve/main/cognitivecomputations.Dolphin-Mistral-24B-Venice-Edition.Q4_K_M.gguf?download=true"
      }
    ]
  },
  {
    "model_id": "bartowski/PocketDoc_Dans-PersonalityEngine-V1.2.0-24b-GGUF",
    "label": "Pocketdoc Dans Personalityengine 24B",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "v1.2.0"
    ],
    "dropped_tags": [
      "v1.2.0"
    ],
    "downloads": 23191,
    "likes": 28,
    "last_updated": "2025-02-20T02:16:38+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "pocketdoc-dans-personalyengine-v1-2-0-24b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07361083249749248,
      "code": 0.12361428571428572,
      "math": 0.022083249749247743,
      "story": 0.004361083249749248,
      "roleplay": 0.004361083249749248
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 14.0,
    "ram_recommended_gb": 17.51,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.2.0-24b-GGUF",
    "variants": [
      {
        "model_id": "DevQuasar/PocketDoc.Dans-PersonalityEngine-V1.2.0-24b-GGUF",
        "format": "gguf",
        "quant_method": "gguf",
        "quant_bits": 4,
        "filename": "PocketDoc.Dans-PersonalityEngine-V1.2.0-24b.Q4_K_M.gguf",
        "source": "huggingface",
        "revision": "main",
        "download_url": "https://huggingface.co/DevQuasar/PocketDoc.Dans-PersonalityEngine-V1.2.0-24b-GGUF/resolve/main/PocketDoc.Dans-PersonalityEngine-V1.2.0-24b.Q4_K_M.gguf?download=true"
      }
    ]
  },
  {
    "model_id": "ministral/Ministral-3b-instruct",
    "label": "Ministral 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 22830,
    "likes": 65,
    "last_updated": "2024-03-21T14:39:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "ministral-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02490220661985958,
      "math": 0.014941323971915747,
      "story": 0.0049804413239719165,
      "roleplay": 0.0049804413239719165
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/Ministral-3b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Ministral-3b-instruct-GGUF/resolve/main/Ministral-3b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Ministral-3b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Ministral-3b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Ministral-3b-instruct-GGUF/resolve/main/Ministral-3b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Ministral-3b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Ministral-3b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Ministral-3b-instruct-GGUF/resolve/main/ministral-3b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "ministral-3b-instruct.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ministral/Ministral-3b-instruct"
  },
  {
    "model_id": "hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF",
    "label": "Llama 3.2 1B 0",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "q8_0"
    ],
    "dropped_tags": [
      "q8_0"
    ],
    "downloads": 22800,
    "likes": 34,
    "last_updated": "2024-09-25T16:14:40+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "llama-3-2-1b-q8",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23722857142857146,
      "code": 0.02378009027081244,
      "math": 0.014268054162487463,
      "story": 0.004756018054162488,
      "roleplay": 0.004756018054162488
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mahmad-10xe/Llama-3.2-1B-Instruct-Q8_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mahmad-10xe/Llama-3.2-1B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-1b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-1b-instruct-q8_0.gguf"
      },
      {
        "model_id": "professorf/Llama-3.2-1B-Instruct-q8_0-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/professorf/Llama-3.2-1B-Instruct-q8_0-gguf/resolve/main/Llama-3.2-1B-Instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-1B-Instruct-q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 2.38,
    "ram_recommended_gb": 2.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.38,
    "quant_bits": 8,
    "format": "gguf",
    "quant_class": "gguf-q8",
    "size_hint": "<2B",
    "params_b": 1.0,
    "tier": "high",
    "model_url": "https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF"
  },
  {
    "model_id": "01-ai/Yi-6B-Chat",
    "label": "Yi 6B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 22267,
    "likes": 69,
    "last_updated": "2024-11-11T03:31:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "yi-6b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.020018806419257774,
      "math": 0.012011283851554665,
      "story": 0.004003761283851555,
      "roleplay": 0.004003761283851555
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-6B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/01-ai/Yi-6B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 12122104832,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 12122104832
      },
      {
        "model_id": "TheBloke/Yi-6B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Yi-6B-GGUF/resolve/main/yi-6b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "yi-6b.Q6_K.gguf"
      },
      {
        "model_id": "unsloth/yi-6b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/yi-6b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Yi-6B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-6B-Chat-GGUF/resolve/main/Yi-6B-Chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-6B-Chat-Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/Yi-6B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Yi-6B-GGUF/resolve/main/Yi-6B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-6B-Q6_K.gguf"
      },
      {
        "model_id": "mav23/Yi-6B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Yi-6B-GGUF/resolve/main/yi-6b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "yi-6b.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 5.5,
    "ram_recommended_gb": 6.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.5,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 6.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-6B-Chat"
  },
  {
    "model_id": "m-a-p/OpenCodeInterpreter-DS-6.7B",
    "label": "Opencodeinterpreter Ds 6.7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 22235,
    "likes": 136,
    "last_updated": "2024-03-03T11:45:14+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "opencodeinterpreter-ds-6-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07737211634904714,
      "code": 0.11232142857142857,
      "math": 0.023211634904714142,
      "story": 0.004737211634904715,
      "roleplay": 0.004737211634904715
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "LoneStriker/OpenCodeInterpreter-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/OpenCodeInterpreter-DS-6.7B-GGUF/resolve/main/OpenCodeInterpreter-DS-6.7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeInterpreter-DS-6.7B-Q6_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/OpenCodeInterpreter-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/OpenCodeInterpreter-DS-6.7B-GGUF/resolve/main/OpenCodeInterpreter-DS-6.7B.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeInterpreter-DS-6.7B.Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/OpenCodeInterpreter-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/OpenCodeInterpreter-DS-6.7B-GGUF/resolve/main/OpenCodeInterpreter-DS-6.7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeInterpreter-DS-6.7B-Q6_K.gguf"
      },
      {
        "model_id": "brittlewis12/OpenCodeInterpreter-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/OpenCodeInterpreter-DS-6.7B-GGUF/resolve/main/opencodeinterpreter-ds-6.7b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "opencodeinterpreter-ds-6.7b.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 7.61,
    "ram_recommended_gb": 9.52,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.61,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 6.7,
    "tier": "high",
    "model_url": "https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-6.7B"
  },
  {
    "model_id": "trillionlabs/Tri-7B",
    "label": "Tri 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 22087,
    "likes": 19,
    "last_updated": "2025-07-25T06:54:45+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "tri-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.31870512060700673,
      "code": 0.024015830027983263,
      "math": 0.01975018970550789,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/trillionlabs/Tri-7B"
  },
  {
    "model_id": "QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
    "label": "Darkidol Llama 3.1 8B 1.2 Uncensored",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 21683,
    "likes": 111,
    "last_updated": "2024-07-29T06:43:25+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "darkidol-llama-3-1-8b-1-2-uncensored",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22972857142857145,
      "code": 0.020526579739217652,
      "math": 0.012315947843530592,
      "story": 0.00410531594784353,
      "roleplay": 0.00410531594784353
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-Q8_0.gguf"
      },
      {
        "model_id": "aifeifei798/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-Q8_0.gguf"
      },
      {
        "model_id": "mav23/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/darkidol-llama-3.1-8b-instruct-1.2-uncensored.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "darkidol-llama-3.1-8b-instruct-1.2-uncensored.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF/resolve/main/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/QuantFactory/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored-GGUF"
  },
  {
    "model_id": "ibm-granite/granite-3.2-8b-instruct",
    "label": "Granite 3.2 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 21523,
    "likes": 84,
    "last_updated": "2025-04-17T11:40:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-2-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.025786108324974924,
      "math": 0.015471664994984953,
      "story": 0.005157221664994985,
      "roleplay": 0.005157221664994985
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/granite-3.2-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.2-8b-instruct-GGUF/resolve/main/granite-3.2-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.2-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "ibm-research/granite-3.2-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ibm-research/granite-3.2-8b-instruct-GGUF/resolve/main/granite-3.2-8b-instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.2-8b-instruct-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/granite-3.2-8b-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/granite-3.2-8b-instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Mungert/granite-3.2-8b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.2-8b-instruct-GGUF/resolve/main/granite-3.2-8b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.2-8b-instruct-q8_0.gguf"
      },
      {
        "model_id": "EasierAI/Granite-3.2-8B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/EasierAI/Granite-3.2-8B/resolve/main/Granite-3.2-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Granite-3.2-8B-Q8_0.gguf"
      },
      {
        "model_id": "unsloth/granite-3.2-8b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/granite-3.2-8b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 16341738616,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16341738616
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.2-8b-instruct"
  },
  {
    "model_id": "silma-ai/SILMA-9B-Instruct-v1.0",
    "label": "Silma 9B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "v1.0"
    ],
    "dropped_tags": [
      "v1.0"
    ],
    "downloads": 21488,
    "likes": 78,
    "last_updated": "2025-06-25T09:48:13+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "silma-9b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.02160481444332999,
      "math": 0.012962888665997993,
      "story": 0.004320962888665999,
      "roleplay": 0.004320962888665999
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/SILMA-9B-Instruct-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/SILMA-9B-Instruct-v1.0-GGUF/resolve/main/SILMA-9B-Instruct-v1.0-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 18490680256,
        "notes": null,
        "revision": "main",
        "filename": "SILMA-9B-Instruct-v1.0-f16.gguf"
      },
      {
        "model_id": "tensorblock/SILMA-9B-Instruct-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/SILMA-9B-Instruct-v1.0-GGUF/resolve/main/SILMA-9B-Instruct-v1.0-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "SILMA-9B-Instruct-v1.0-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/SILMA-9B-Instruct-v1.0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/SILMA-9B-Instruct-v1.0-GGUF/resolve/main/SILMA-9B-Instruct-v1.0.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "SILMA-9B-Instruct-v1.0.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 4.42,
    "ram_recommended_gb": 5.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 4.42,
    "quant_class": null,
    "format": "hf",
    "size_hint": "9B",
    "params_b": 9.0,
    "tier": "high",
    "model_url": "https://huggingface.co/silma-ai/SILMA-9B-Instruct-v1.0"
  },
  {
    "model_id": "01-ai/Yi-1.5-9B-Chat",
    "label": "Yi 1.5 9B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 20822,
    "likes": 145,
    "last_updated": "2024-06-26T10:41:03+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "yi-1-5-9b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02293380140421264,
      "math": 0.013760280842527584,
      "story": 0.004586760280842528,
      "roleplay": 0.004586760280842528
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-1.5-9B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/01-ai/Yi-1.5-9B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 17658864984,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 17658864984
      },
      {
        "model_id": "bartowski/Yi-1.5-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-1.5-9B-Chat-GGUF/resolve/main/Yi-1.5-9B-Chat-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 35319132416,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat-f32.gguf"
      },
      {
        "model_id": "second-state/Yi-1.5-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-1.5-9B-Chat-GGUF/resolve/main/Yi-1.5-9B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17661112672,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat-f16.gguf"
      },
      {
        "model_id": "gaianet/Yi-1.5-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-1.5-9B-Chat-GGUF/resolve/main/Yi-1.5-9B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17661112672,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Yi-1.5-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-1.5-9B-Chat-GGUF/resolve/main/Yi-1.5-9B-Chat-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 35319132416,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat-f32.gguf"
      },
      {
        "model_id": "QuantFactory/Yi-1.5-9B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Yi-1.5-9B-GGUF/resolve/main/Yi-1.5-9B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Yi-1.5-9B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Yi-1.5-9B-Chat-GGUF/resolve/main/Yi-1.5-9B-Chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Yi-1.5-9B-Chat-GGUF-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Yi-1.5-9B-Chat-GGUF-v2/resolve/main/Yi-1.5-9B-Chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-9B-Chat.Q2_K.gguf"
      },
      {
        "model_id": "modelscope/Yi-1.5-9B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/modelscope/Yi-1.5-9B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5364058776,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5364058776
      }
    ],
    "ram_estimate_gb": 4.42,
    "ram_recommended_gb": 5.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 4.42,
    "quant_class": null,
    "format": "hf",
    "size_hint": "9B",
    "params_b": 9.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-1.5-9B-Chat"
  },
  {
    "model_id": "allenai/OLMoE-1B-7B-0924-Instruct",
    "label": "Olmoe 1B 7B 0924",
    "tags": [
      "chat",
      "hf",
      "moe",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "moe",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 20747,
    "likes": 91,
    "last_updated": "2024-09-13T17:15:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olmoe-1b-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.022112587763289872,
      "math": 0.013267552657973922,
      "story": 0.004422517552657975,
      "roleplay": 0.004422517552657975
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "allenai/OLMoE-1B-7B-0924",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0924/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 13838721960,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 13838721960
      },
      {
        "model_id": "bartowski/OLMoE-1B-7B-0924-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/OLMoE-1B-7B-0924-Instruct-GGUF/resolve/main/OLMoE-1B-7B-0924-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMoE-1B-7B-0924-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "DevQuasar/OLMoE-1B-7B-0924-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevQuasar/OLMoE-1B-7B-0924-Instruct-GGUF/resolve/main/OLMoE-1B-7B-0924-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 864572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMoE-1B-7B-0924-Instruct.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 1.84,
    "ram_recommended_gb": 2.3,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.84,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.0,
    "tier": "high",
    "model_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0924-Instruct"
  },
  {
    "model_id": "ibm-granite/granite-3.1-2b-instruct",
    "label": "Granite 3.1 2B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 20533,
    "likes": 53,
    "last_updated": "2025-04-16T14:58:24+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-3-1-2b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.02430667001003009,
      "math": 0.014584002006018053,
      "story": 0.004861334002006019,
      "roleplay": 0.004861334002006019
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5069140320,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct-f16.gguf"
      },
      {
        "model_id": "Mungert/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5069140736,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct-bf16.gguf"
      },
      {
        "model_id": "QuantFactory/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "Alcoft/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct_f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5069140288,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct_f16.gguf"
      },
      {
        "model_id": "lmstudio-community/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 1914572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct-Q6_K.gguf"
      },
      {
        "model_id": "ZeroWw/granite-3.1-2b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ZeroWw/granite-3.1-2b-instruct-GGUF/resolve/main/granite-3.1-2b-instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 5069140640,
        "notes": null,
        "revision": "main",
        "filename": "granite-3.1-2b-instruct.f16.gguf"
      }
    ],
    "ram_estimate_gb": 1.9,
    "ram_recommended_gb": 2.38,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 2.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-3.1-2b-instruct"
  },
  {
    "model_id": "internlm/internlm-chat-7b",
    "label": "Internlm 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 20479,
    "likes": 101,
    "last_updated": "2024-07-03T06:26:25+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "internlm-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02394307923771314,
      "math": 0.014365847542627883,
      "story": 0.0047886158475426285,
      "roleplay": 0.0047886158475426285
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "internlm/internlm-7b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/internlm/internlm-chat-7b"
  },
  {
    "model_id": "microsoft/Phi-4-mini-flash-reasoning",
    "label": "Phi 4 Mini Flash Reasoning",
    "tags": [
      "chat",
      "code",
      "hf",
      "math"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "math"
    ],
    "dropped_tags": [],
    "downloads": 20448,
    "likes": 217,
    "last_updated": "2025-08-12T17:56:31+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-4-mini-flash-reasoning",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.3191810026378392,
      "code": 0.2581092540451416,
      "math": 0.35,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning"
  },
  {
    "model_id": "bartowski/open-r1_OlympicCoder-7B-GGUF",
    "label": "Open R1 Olympiccoder 7B",
    "tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 19880,
    "likes": 10,
    "last_updated": "2025-03-11T23:43:44+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "open-r1-olympiccoder-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07389919759277834,
      "code": 0.12101813186813187,
      "math": 0.0221697592778335,
      "story": 0.004389919759277833,
      "roleplay": 0.004389919759277833
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/open-r1_OlympicCoder-7B-GGUF",
    "variants": [
      {
        "model_id": "DevQuasar/open-r1.OlympicCoder-7B-GGUF",
        "format": "gguf",
        "quant_method": "gguf",
        "quant_bits": null,
        "filename": "open-r1.OlympicCoder-7B.f16.gguf",
        "source": "huggingface",
        "revision": "main",
        "download_url": "https://huggingface.co/DevQuasar/open-r1.OlympicCoder-7B-GGUF/resolve/main/open-r1.OlympicCoder-7B.f16.gguf?download=true"
      }
    ]
  },
  {
    "model_id": "Qwen/Qwen1.5-32B-Chat",
    "label": "Qwen1.5 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 19747,
    "likes": 108,
    "last_updated": "2024-04-30T07:23:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen1-5-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02090270812437312,
      "math": 0.012541624874623871,
      "story": 0.004180541624874624,
      "roleplay": 0.004180541624874624
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen1.5-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-32B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 65024525272,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 65024525272
      },
      {
        "model_id": "Qwen/Qwen1.5-32B-Chat-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-32B-Chat-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen1.5-32B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-32B-Chat-GGUF/resolve/main/qwen1_5-32b-chat-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1_5-32b-chat-q2_k.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen1.5-32B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen1.5-32B-Chat-GGUF/resolve/main/Qwen1.5-32B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-32B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen1.5-32B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-32B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 21011959248,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 21011959248
      },
      {
        "model_id": "bartowski/Qwen1.5-32B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen1.5-32B-Chat-GGUF/resolve/main/Qwen1.5-32B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-32B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen1.5-32B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen1.5-32B-Chat-GGUF/resolve/main/Qwen1.5-32B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-32B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen1.5-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen1.5-32B-GGUF/resolve/main/Qwen1.5-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen1.5-32B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 24.22,
    "ram_recommended_gb": 30.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 24.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen1.5-32B-Chat"
  },
  {
    "model_id": "BSC-LT/salamandra-7b-instruct",
    "label": "Salamandra 7B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 19724,
    "likes": 64,
    "last_updated": "2025-05-23T14:14:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "salamandra-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.12107142857142857,
      "math": 0.024204613841524576,
      "story": 0.005068204613841525,
      "roleplay": 0.005068204613841525
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "BSC-LT/salamandra-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/BSC-LT/salamandra-7b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 15536268344,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15536268344
      },
      {
        "model_id": "tensorblock/salamandra-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/salamandra-7b-instruct-GGUF/resolve/main/salamandra-7b-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "salamandra-7b-instruct-Q2_K.gguf"
      },
      {
        "model_id": "cstr/salamandra-7b-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cstr/salamandra-7b-instruct-GGUF/resolve/main/salamandra-7b-instruct.Q4_K_M-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "salamandra-7b-instruct.Q4_K_M-f32.gguf"
      },
      {
        "model_id": "BSC-LT/salamandra-7b-instruct-gptq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/BSC-LT/salamandra-7b-instruct-gptq/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7145604688,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7145604688
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/BSC-LT/salamandra-7b-instruct"
  },
  {
    "model_id": "FlagAlpha/Llama3-Chinese-8B-Instruct",
    "label": "Llama3 Chinese 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 19370,
    "likes": 78,
    "last_updated": "2024-04-24T02:33:43+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3-chinese-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2928884861412841,
      "code": 0.01827540582906535,
      "math": 0.012493396649434578,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 16.8,
    "ram_recommended_gb": 21.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 16.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/FlagAlpha/Llama3-Chinese-8B-Instruct"
  },
  {
    "model_id": "Derur/Best-smal-LLM-GGUF",
    "label": "Best Smal Llm",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 19183,
    "likes": 1,
    "last_updated": "2025-08-13T13:30:54+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "best-smal-llm",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2965116365175348,
      "code": 0.017467644879001792,
      "math": 0.010813282826704818,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/Derur/Best-smal-LLM-GGUF"
  },
  {
    "model_id": "tiiuae/Falcon3-Mamba-7B-Instruct",
    "label": "Falcon3 Mamba 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 18907,
    "likes": 30,
    "last_updated": "2025-06-03T06:58:40+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "falcon3-mamba-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.3187929480272658,
      "code": 0.010608728464781725,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tiiuae/Falcon3-Mamba-7B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2.5-Coder-0.5B-Instruct",
    "label": "Qwen2.5 Coder 0.5B",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 18177,
    "likes": 50,
    "last_updated": "2024-11-18T12:52:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-coder-0-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.11607142857142858,
      "math": 0.021823721163490472,
      "story": 0.00427457372116349,
      "roleplay": 0.00427457372116349
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2.5-Coder-0.5B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 988097824,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-0.5b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 1266425728,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-0.5b-instruct-fp16.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-0.5B-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-0.5B-Instruct-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/Qwen2.5-Coder-0.5B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-Coder-0.5B-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-0.5B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 730652248,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "gaianet/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156928,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-0.5B-Instruct-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GPTQ-Int8/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Qwen2.5-Coder-0.5B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-Coder-0.5B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156928,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "bartowski/Qwen2.5-Coder-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-Coder-0.5B-GGUF/resolve/main/Qwen2.5-Coder-0.5B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156768,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-f16.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-0.5B-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ThomasBaruzier/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ThomasBaruzier/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156928,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-F16.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156928,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "kolosal/qwen2.5-coder-0.5b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/kolosal/qwen2.5-coder-0.5b/resolve/main/qwen2.5-coder-0.5b-instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 1266425728,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-0.5b-instruct-fp16.gguf"
      },
      {
        "model_id": "Qwen/Qwen2.5-Coder-0.5B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 614572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/Qwen2.5-Coder-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-Coder-0.5B-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 464572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-Coder-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-0.5B-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 714572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Q6_K.gguf"
      },
      {
        "model_id": "Alcoft/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Alcoft/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/Qwen2.5-Coder-0.5B-Instruct.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 994156384,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-Coder-0.5B-Instruct.gguf"
      },
      {
        "model_id": "ikw/Qwen2.5-Coder-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ikw/Qwen2.5-Coder-0.5B-GGUF/resolve/main/qwen2.5-coder-0.5b-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 814572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-0.5b-q8_0.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-0.5B-GGUF/resolve/main/qwen2.5-coder-0.5b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-0.5b.Q6_K.gguf"
      },
      {
        "model_id": "Volko76/Qwen2.5-Coder-0.5B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Volko76/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-0.5b-instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 714572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-0.5b-instruct.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 1.54,
    "ram_recommended_gb": 1.93,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.5,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct"
  },
  {
    "model_id": "bartowski/Llama-3.2-3B-Instruct-uncensored-GGUF",
    "label": "Llama 3.2 3B Uncensored",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 18507,
    "likes": 67,
    "last_updated": "2024-10-26T00:35:56+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "llama-3-2-3b-uncensored",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23722857142857146,
      "code": 0.023385155466399198,
      "math": 0.01403109327983952,
      "story": 0.0046770310932798395,
      "roleplay": 0.0046770310932798395
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "chuanli11/Llama-3.2-3B-Instruct-uncensored",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/Llama-3.2-3B-Instruct-uncensored-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-uncensored-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 2564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "second-state/Llama-3.2-3B-Instruct-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3.2-3B-Instruct-Uncensored-GGUF/resolve/main/Llama-3.2-3B-Instruct-Uncensored-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7221692544,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-Uncensored-f16.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3.2-3B-Instruct-uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3.2-3B-Instruct-uncensored-GGUF/resolve/main/Llama-3.2-3B-Instruct-uncensored.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-uncensored.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Llama-3.2-3B-Instruct-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3.2-3B-Instruct-Uncensored-GGUF/resolve/main/Llama-3.2-3B-Instruct-Uncensored-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7221692544,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.2-3B-Instruct-Uncensored-f16.gguf"
      },
      {
        "model_id": "Shyamnath/Llama-3.2-3b-Uncensored-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Shyamnath/Llama-3.2-3b-Uncensored-GGUF/resolve/main/model.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 3840526432,
        "notes": null,
        "revision": "main",
        "filename": "model.gguf"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-uncensored-GGUF"
  },
  {
    "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit",
    "label": "Deepseek R1 Distill Qwen 7B Unsloth Bnb 4Bit",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 18260,
    "likes": 23,
    "last_updated": "2025-02-14T23:55:26+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "bnb",
    "quant_bits": 4,
    "canonical_base": "deepseek-r1-distill-qwen-7b-unsloth",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07621972533510828,
      "code": 0.24513870113489217,
      "math": 0.06185927874253527,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 4.65,
    "ram_recommended_gb": 5.82,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 4.65,
    "format": "bnb",
    "quant_class": "bnb-q4",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit"
  },
  {
    "model_id": "nvidia/AceReason-Nemotron-14B",
    "label": "Acereason Nemotron 14B",
    "tags": [
      "code",
      "cuda",
      "hf",
      "math"
    ],
    "raw_tags": [
      "code",
      "cuda",
      "hf",
      "math"
    ],
    "dropped_tags": [],
    "downloads": 17929,
    "likes": 88,
    "last_updated": "2025-06-17T23:03:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "acereason-nemotron-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.0746765295887663,
      "code": 0.12107142857142857,
      "math": 0.07264285714285713,
      "story": 0.00446765295887663,
      "roleplay": 0.00446765295887663
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/AceReason-Nemotron-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/AceReason-Nemotron-14B-GGUF/resolve/main/AceReason-Nemotron-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/AceReason-Nemotron-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/AceReason-Nemotron-14B-GGUF/resolve/main/AceReason-Nemotron-14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-14B-Q4_K_M.gguf"
      },
      {
        "model_id": "unsloth/AceReason-Nemotron-14B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/AceReason-Nemotron-14B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 29540133960,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133960
      },
      {
        "model_id": "QuantFactory/AceReason-Nemotron-14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/AceReason-Nemotron-14B-GGUF/resolve/main/AceReason-Nemotron-14B.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-14B.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/AceReason-Nemotron-14B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/AceReason-Nemotron-14B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 9.58,
    "ram_recommended_gb": 11.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/AceReason-Nemotron-14B"
  },
  {
    "model_id": "deepseek-ai/DeepSeek-V2.5-1210",
    "label": "Deepseek 1210",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf",
      "v2.5"
    ],
    "dropped_tags": [
      "v2.5"
    ],
    "downloads": 17800,
    "likes": 254,
    "last_updated": "2024-12-11T12:06:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-v2-5",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07683299899699098,
      "code": 0.11607142857142858,
      "math": 0.023049899699097293,
      "story": 0.0046832998996990975,
      "roleplay": 0.0046832998996990975
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/DeepSeek-V2.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/DeepSeek-V2.5-1210-GGUF/resolve/main/DeepSeek-V2.5-1210-Q6_K-00001-of-00005.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 39228610720,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2.5-1210-Q6_K-00001-of-00005.gguf"
      },
      {
        "model_id": "bartowski/DeepSeek-V2.5-1210-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/DeepSeek-V2.5-1210-GGUF/resolve/main/DeepSeek-V2.5-1210-IQ1_S.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 47392226944,
        "notes": null,
        "revision": "main",
        "filename": "DeepSeek-V2.5-1210-IQ1_S.gguf"
      },
      {
        "model_id": "mlx-community/DeepSeek-V2.5-1210-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/DeepSeek-V2.5-1210-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 132675379683,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 132675379683
      },
      {
        "model_id": "dong-99/DeepSeek-V2.5-1210-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/dong-99/DeepSeek-V2.5-1210-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 191598470527,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 191598470527
      },
      {
        "model_id": "dong-99/DeepSeek-V2.5-1210-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/dong-99/DeepSeek-V2.5-1210-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 250521560231,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 250521560231
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210"
  },
  {
    "model_id": "bartowski/Qwen_Qwen3-30B-A3B-Instruct-2507-GGUF",
    "label": "Qwen Qwen3 30B A3B 2507",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 17687,
    "likes": 17,
    "last_updated": "2025-07-29T16:53:23+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "a3b",
    "canonical_base": "qwen-qwen3-30b-a3b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.022488716148445338,
      "math": 0.013493229689067203,
      "story": 0.0044977432296890675,
      "roleplay": 0.0044977432296890675
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Qwen_Qwen3-30B-A3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen_Qwen3-30B-A3B-Q2_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 2,
        "format": null,
        "size_bytes": 7814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen_Qwen3-30B-A3B-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen_Qwen3-30B-A3B-Instruct-2507-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen_Qwen3-30B-A3B-Instruct-2507-GGUF/resolve/main/Qwen3-30B-A3B-Instruct-2507-Q2_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 2,
        "format": null,
        "size_bytes": 7814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-30B-A3B-Instruct-2507-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen_Qwen3-30B-A3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen_Qwen3-30B-A3B-GGUF/resolve/main/Qwen3-30B-A3B-Q2_K.gguf?download=true",
        "quant_method": "a3b",
        "quant_bits": 2,
        "format": null,
        "size_bytes": 7814572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen3-30B-A3B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 10.18,
    "ram_recommended_gb": 12.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.18,
    "quant_class": "a3b",
    "format": "gguf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-Instruct-2507-GGUF"
  },
  {
    "model_id": "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic",
    "label": "Llama 3.3 70B Fp8 Dynamic",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 17610,
    "likes": 9,
    "last_updated": "2025-05-30T20:11:56+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-3-70b-fp8-dynamic",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2352197802197802,
      "code": 0.022795887662988967,
      "math": 0.01367753259779338,
      "story": 0.004559177532597793,
      "roleplay": 0.004559177532597793
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Infermatic/Llama-3.3-70B-Instruct-FP8-Dynamic",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Infermatic/Llama-3.3-70B-Instruct-FP8-Dynamic/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 72669954704,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 72669954704
      }
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
  },
  {
    "model_id": "chujiezheng/internlm2-chat-7b-ExPO",
    "label": "Internlm2 7B Expo",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 17524,
    "likes": 0,
    "last_updated": "2024-05-27T18:15:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "internlm2-7b-expo",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22861942141470382,
      "code": 0.01611914672337602,
      "math": 0.01033816766286617,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/chujiezheng/internlm2-chat-7b-ExPO"
  },
  {
    "model_id": "nvidia/AceReason-Nemotron-1.1-7B",
    "label": "Acereason Nemotron 1.1 7B",
    "tags": [
      "code",
      "cuda",
      "hf",
      "math",
      "small"
    ],
    "raw_tags": [
      "code",
      "cuda",
      "hf",
      "math",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 17349,
    "likes": 55,
    "last_updated": "2025-07-11T05:49:43+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "acereason-nemotron-1-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07831243731193581,
      "code": 0.12107142857142857,
      "math": 0.07264285714285713,
      "story": 0.004831243731193581,
      "roleplay": 0.004831243731193581
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/AceReason-Nemotron-1.1-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/AceReason-Nemotron-1.1-7B-GGUF/resolve/main/AceReason-Nemotron-1.1-7B-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853664,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-1.1-7B-bf16.gguf"
      },
      {
        "model_id": "gabriellarson/AceReason-Nemotron-1.1-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gabriellarson/AceReason-Nemotron-1.1-7B-GGUF/resolve/main/AceReason-Nemotron-1.1-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-1.1-7B-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/AceReason-Nemotron-1.1-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/AceReason-Nemotron-1.1-7B-GGUF/resolve/main/AceReason-Nemotron-1.1-7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-1.1-7B-Q6_K.gguf"
      },
      {
        "model_id": "QuantFactory/AceReason-Nemotron-1.1-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/AceReason-Nemotron-1.1-7B-GGUF/resolve/main/AceReason-Nemotron-1.1-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "AceReason-Nemotron-1.1-7B.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/AceReason-Nemotron-1.1-7B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/AceReason-Nemotron-1.1-7B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B"
  },
  {
    "model_id": "RedHatAI/Qwen2-7B-Instruct-FP8",
    "label": "Qwen2 7B Fp8",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 17214,
    "likes": 2,
    "last_updated": "2024-07-18T19:14:31+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-7b-fp8",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.26637663035136705,
      "code": 0.02052301032094437,
      "math": 0.014462636196740198,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Qwen2-7B-Instruct-FP8"
  },
  {
    "model_id": "JetBrains/Mellum-4b-base",
    "label": "Mellum 4B Base",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 16765,
    "likes": 415,
    "last_updated": "2025-05-07T10:59:31+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "mellum-4b-base",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08228686058174524,
      "code": 0.12107142857142857,
      "math": 0.02468605817452357,
      "story": 0.005228686058174524,
      "roleplay": 0.005228686058174524
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Mellum-4b-base-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mellum-4b-base-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 2314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Mellum-4b-base",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mellum-4b-base/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 8038527852,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 8038527852
      },
      {
        "model_id": "mlx-community/Mellum-4b-base-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mellum-4b-base-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 3.58,
    "ram_recommended_gb": 4.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 4.0,
    "tier": "high",
    "model_url": "https://huggingface.co/JetBrains/Mellum-4b-base"
  },
  {
    "model_id": "openGPT-X/Teuken-7B-instruct-commercial-v0.4",
    "label": "Teuken 7B Commercial",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.4"
    ],
    "dropped_tags": [
      "v0.4"
    ],
    "downloads": 16709,
    "likes": 74,
    "last_updated": "2024-12-11T09:17:59+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "teuken-7b-commercial",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.025616850551654965,
      "math": 0.015370110330992979,
      "story": 0.005123370110330993,
      "roleplay": 0.005123370110330993
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tensorblock/Teuken-7B-instruct-commercial-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Teuken-7B-instruct-commercial-v0.4-GGUF/resolve/main/Teuken-7B-instruct-commercial-v0.4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Teuken-7B-instruct-commercial-v0.4-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/Teuken-7B-instruct-commercial-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Teuken-7B-instruct-commercial-v0.4-GGUF/resolve/main/Teuken-7B-instruct-commercial-v0.4.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Teuken-7B-instruct-commercial-v0.4.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/Teuken-7B-instruct-commercial-v0.4-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Teuken-7B-instruct-commercial-v0.4-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "stelterlab/Teuken-7B-instruct-commercial-v0.4-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/Teuken-7B-instruct-commercial-v0.4-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/openGPT-X/Teuken-7B-instruct-commercial-v0.4"
  },
  {
    "model_id": "microsoft/Phi-3-medium-4k-instruct",
    "label": "Phi 3 Medium 4K",
    "tags": [
      "chat",
      "code",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 16552,
    "likes": 221,
    "last_updated": "2025-03-11T15:49:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-medium-4k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.12107142857142857,
      "math": 0.023986459378134404,
      "story": 0.004995486459378135,
      "roleplay": 0.004995486459378135
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/Phi-3-medium-4k-instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3-medium-4k-instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7690127431,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 7690127431
      },
      {
        "model_id": "bartowski/Phi-3-medium-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Phi-3-medium-4k-instruct-GGUF/resolve/main/Phi-3-medium-4k-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 5143000448,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-medium-4k-instruct-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/Phi-3-medium-4k-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Phi-3-medium-4k-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 27920518456,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 27920518456
      },
      {
        "model_id": "tensorblock/Phi-3-medium-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Phi-3-medium-4k-instruct-GGUF/resolve/main/Phi-3-medium-4k-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 5143000160,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-medium-4k-instruct-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Phi-3-medium-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Phi-3-medium-4k-instruct-GGUF/resolve/main/Phi-3-medium-4k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 27922046048,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-medium-4k-instruct-f16.gguf"
      },
      {
        "model_id": "gaianet/Phi-3-medium-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Phi-3-medium-4k-instruct-GGUF/resolve/main/Phi-3-medium-4k-instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 27922046048,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-medium-4k-instruct-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Phi-3-medium-4k-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Phi-3-medium-4k-instruct-GGUF/resolve/main/Phi-3-medium-4k-instruct.Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 7897124448,
        "notes": null,
        "revision": "main",
        "filename": "Phi-3-medium-4k-instruct.Q4_0.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3-medium-4k-instruct"
  },
  {
    "model_id": "stabilityai/stablelm-zephyr-3b",
    "label": "Stablelm Zephyr 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 16527,
    "likes": 257,
    "last_updated": "2024-07-10T12:01:23+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "stablelm-zephyr-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.024406970912738215,
      "math": 0.014644182547642928,
      "story": 0.0048813941825476435,
      "roleplay": 0.0048813941825476435
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "brittlewis12/stablelm-zephyr-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/stablelm-zephyr-3b-GGUF/resolve/main/stablelm-zephyr-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stablelm-zephyr-3b.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/stablelm-zephyr-3b-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/stablelm-zephyr-3b-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1838811216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/stabilityai/stablelm-zephyr-3b"
  },
  {
    "model_id": "allenai/OLMo-2-1124-7B-Instruct",
    "label": "Olmo 2 1124 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 16196,
    "likes": 38,
    "last_updated": "2025-01-06T01:02:35+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olmo-2-1124-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02136033099297894,
      "math": 0.012816198595787363,
      "story": 0.004272066198595788,
      "roleplay": 0.004272066198595788
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/OLMo-2-1124-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/OLMo-2-1124-7B-Instruct-GGUF/resolve/main/OLMo-2-1124-7B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMo-2-1124-7B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "eaddario/OLMo-2-1124-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/eaddario/OLMo-2-1124-7B-Instruct-GGUF/resolve/main/OLMo-2-1124-7B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMo-2-1124-7B-Instruct-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 5.8,
    "ram_recommended_gb": 7.25,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/allenai/OLMo-2-1124-7B-Instruct"
  },
  {
    "model_id": "deepseek-ai/deepseek-coder-33b-instruct",
    "label": "Deepseek Coder 33B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 16168,
    "likes": 537,
    "last_updated": "2024-03-07T08:25:20+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-coder-33b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.11232142857142857,
      "math": 0.023155215646940824,
      "story": 0.0047184052156469414,
      "roleplay": 0.0047184052156469414
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/deepseek-coder-33B-instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 18008816752,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 18008816752
      },
      {
        "model_id": "TheBloke/deepseek-coder-33B-instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 17399444712,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/deepseek-coder-33b-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/deepseek-coder-33b-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 18756885168,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 18756885168
      }
    ],
    "ram_estimate_gb": 66.8,
    "ram_recommended_gb": 83.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 66.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct"
  },
  {
    "model_id": "microsoft/Phi-3-mini-4k-instruct-onnx",
    "label": "Phi 3 Mini 4K Onnx",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 15960,
    "likes": 142,
    "last_updated": "2025-05-30T21:00:22+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "phi-3-mini-4k-onnx",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.3181884705648415,
      "code": 0.012873254469518659,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-onnx"
  },
  {
    "model_id": "DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF",
    "label": "Qwen3 Zero Coder Reasoning 0.8B Neo Ex",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 15755,
    "likes": 12,
    "last_updated": "2025-07-28T00:14:32+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "qwen3-zero-coder-reasoning-0-8b-neo-ex",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.32457002022196785,
      "code": 0.2618051603678186,
      "math": 0.06266157225542172,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 1.6,
    "ram_recommended_gb": 2.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 1.6,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "<2B",
    "params_b": 0.8,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/Qwen3-Zero-Coder-Reasoning-0.8B-NEO-EX-GGUF"
  },
  {
    "model_id": "VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct",
    "label": "Llama 3 Sauerkrautlm 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 15397,
    "likes": 55,
    "last_updated": "2024-04-29T18:28:16+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-sauerkrautlm-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.023842778335005015,
      "math": 0.014305667001003008,
      "story": 0.004768555667001004,
      "roleplay": 0.004768555667001004
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Llama-3-SauerkrautLM-8b-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3-SauerkrautLM-8b-Instruct-GGUF/resolve/main/Llama-3-SauerkrautLM-8b-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-SauerkrautLM-8b-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3-SauerkrautLM-8b-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3-SauerkrautLM-8b-Instruct-GGUF/resolve/main/Llama-3-SauerkrautLM-8b-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-SauerkrautLM-8b-Instruct.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct"
  },
  {
    "model_id": "defog/llama-3-sqlcoder-8b",
    "label": "Llama 3 Sqlcoder 8B",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 14133,
    "likes": 258,
    "last_updated": "2024-07-24T11:18:07+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-sqlcoder-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07422517552657974,
      "code": 0.11232142857142857,
      "math": 0.02226755265797392,
      "story": 0.004422517552657975,
      "roleplay": 0.004422517552657975
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/llama-3-sqlcoder-8b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-sqlcoder-8b.Q8_0.gguf"
      },
      {
        "model_id": "bartowski/llama-3-sqlcoder-8b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-sqlcoder-8b-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/llama-3-sqlcoder-8b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-sqlcoder-8b-Q8_0.gguf"
      },
      {
        "model_id": "qdtomassi/llama-3-sqlcoder-8b-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/qdtomassi/llama-3-sqlcoder-8b-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "SandLogicTechnologies/Llama-3-Sqlcoder-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "aspenita/llama-3-sqlcoder-8b-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/aspenita/llama-3-sqlcoder-8b-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mav23/llama-3-sqlcoder-8b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/llama-3-sqlcoder-8b-GGUF/resolve/main/llama-3-sqlcoder-8b.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-sqlcoder-8b.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 5.98,
    "ram_recommended_gb": 7.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/defog/llama-3-sqlcoder-8b"
  },
  {
    "model_id": "tokyotech-llm/Swallow-7b-instruct-hf",
    "label": "Swallow 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 13629,
    "likes": 43,
    "last_updated": "2024-10-08T13:38:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "swallow-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.025002507522567705,
      "math": 0.015001504513540622,
      "story": 0.005000501504513541,
      "roleplay": 0.005000501504513541
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tokyotech-llm/Swallow-7b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tokyotech-llm/Swallow-7b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 13659980488,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 13659980488
      },
      {
        "model_id": "TheBloke/Swallow-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Swallow-7B-Instruct-GGUF/resolve/main/swallow-7b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "swallow-7b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Swallow-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Swallow-7B-GGUF/resolve/main/swallow-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "swallow-7b.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Swallow-7b-instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Swallow-7b-instruct-hf-GGUF/resolve/main/Swallow-7b-instruct-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Swallow-7b-instruct-hf-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tokyotech-llm/Swallow-7b-instruct-hf"
  },
  {
    "model_id": "Qwen/Qwen2.5-14B-Instruct-1M",
    "label": "Qwen2.5 14B 1M",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 13511,
    "likes": 317,
    "last_updated": "2025-01-29T12:38:27+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-5-14b-1m",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02281469408224674,
      "math": 0.013688816449348044,
      "story": 0.004562938816449348,
      "roleplay": 0.004562938816449348
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf"
      },
      {
        "model_id": "Mungert/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M-q4_k_m.gguf"
      },
      {
        "model_id": "unsloth/Qwen2.5-14B-Instruct-1M",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Qwen2.5-14B-Instruct-1M/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 29540133960,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 29540133960
      },
      {
        "model_id": "lmstudio-community/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2.5-14B-Instruct-1M-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2.5-14B-Instruct-1M-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "second-state/Qwen2.5-14B-Instruct-1M-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2.5-14B-Instruct-1M-GGUF/resolve/main/Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2.5-14B-Instruct-1M-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 17.98,
    "ram_recommended_gb": 22.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 17.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-1M"
  },
  {
    "model_id": "openchat/openchat-3.6-8b-20240522",
    "label": "Openchat 3.6 8B 20240522",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 13434,
    "likes": 155,
    "last_updated": "2024-05-28T05:23:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "open-3-6-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02438816449348044,
      "math": 0.014632898696088264,
      "story": 0.004877632898696089,
      "roleplay": 0.004877632898696089
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522-Q6_K.gguf"
      },
      {
        "model_id": "NeuralNet-Hub/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/NeuralNet-Hub/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522-q6_K.gguf"
      },
      {
        "model_id": "LiteLLMs/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/openchat-3.6-8b-20240522-GGUF/resolve/main/Q6_K/Q6_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "Q6_K/Q6_K-00001-of-00001.gguf"
      },
      {
        "model_id": "thesven/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/thesven/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-GGUF-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522-GGUF-Q6_K.gguf"
      },
      {
        "model_id": "QuantFactory/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522.Q6_K.gguf"
      },
      {
        "model_id": "mav23/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522.Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522-Q6_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/openchat-3.6-8b-20240522-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 6714572800,
        "notes": null,
        "revision": "main",
        "filename": "openchat-3.6-8b-20240522.Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/openchat-3.6-8b-20240522-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/openchat-3.6-8b-20240522-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/openchat/openchat-3.6-8b-20240522"
  },
  {
    "model_id": "PowerInfer/SmallThinker-4BA0.6B-Instruct-GGUF",
    "label": "Smallthinker 4Ba0.6B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 13241,
    "likes": 26,
    "last_updated": "2025-08-05T01:12:11+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 6,
    "canonical_base": "smallthinker-4ba0-6b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.020263289869608826,
      "math": 0.012157973921765295,
      "story": 0.004052657973921766,
      "roleplay": 0.004052657973921766
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "PowerInfer/SmallThinker-4BA0.6B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "Mungert/SmallThinker-4BA0.6B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/SmallThinker-4BA0.6B-Instruct/resolve/main/SmallThinker-4BA0.6B-Instruct-q6_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 794572800,
        "notes": null,
        "revision": "main",
        "filename": "SmallThinker-4BA0.6B-Instruct-q6_k_m.gguf"
      },
      {
        "model_id": "gabriellarson/SmallThinker-4BA0.6B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gabriellarson/SmallThinker-4BA0.6B-Instruct-GGUF/resolve/main/SmallThinker-4BA0.6B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 794572800,
        "notes": null,
        "revision": "main",
        "filename": "SmallThinker-4BA0.6B-Instruct-Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 1.75,
    "ram_recommended_gb": 2.2,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.75,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "<2B",
    "params_b": 0.6,
    "tier": "high",
    "model_url": "https://huggingface.co/PowerInfer/SmallThinker-4BA0.6B-Instruct-GGUF"
  },
  {
    "model_id": "RedHatAI/Meta-Llama-3.1-70B-Instruct-quantized.w8a8",
    "label": "Meta Llama 3.1 70B Quantized.W8A8",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 13229,
    "likes": 21,
    "last_updated": "2025-02-11T16:39:13+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-1-70b-quantized-w8a8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.3042905167135286,
      "code": 0.016025475892817335,
      "math": 0.007582496568318208,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Meta-Llama-3.1-70B-Instruct-quantized.w8a8"
  },
  {
    "model_id": "openchat/openchat_3.5",
    "label": "Openchat 3.5",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 12895,
    "likes": 1136,
    "last_updated": "2024-05-18T18:09:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "open",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22571428571428573,
      "code": 0.024124874623871615,
      "math": 0.014474924774322969,
      "story": 0.004824974924774323,
      "roleplay": 0.004824974924774323
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "openchat/openchat_8192",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "second-state/OpenChat-3.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/OpenChat-3.5-GGUF/resolve/main/openchat_3.5-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2719251648,
        "notes": null,
        "revision": "main",
        "filename": "openchat_3.5-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat_3.5-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat_3.5-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158694864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/openchat_3.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/openchat_3.5-GGUF/resolve/main/openchat_3.5-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2719254208,
        "notes": null,
        "revision": "main",
        "filename": "openchat_3.5-Q2_K.gguf"
      },
      {
        "model_id": "mav23/openchat_3.5-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/openchat_3.5-GGUF/resolve/main/openchat_3.5.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2719252384,
        "notes": null,
        "revision": "main",
        "filename": "openchat_3.5.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/openchat_3.5-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat_3.5-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150913000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/openchat_v2-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/openchat_v2-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7454817784,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Honkware/openchat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Honkware/openchat-GPTQ/resolve/main/openchat-GPTQ.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7255179696,
        "notes": null,
        "revision": "main",
        "filename": "openchat-GPTQ.safetensors"
      },
      {
        "model_id": "TheBloke/OpenChat_v3.2-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/OpenChat_v3.2-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259490616,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/openchat/openchat_3.5"
  },
  {
    "model_id": "ggml-org/Qwen2.5-Coder-0.5B-Q8_0-GGUF",
    "label": "Qwen2.5 Coder 0.5B 0",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "q8_0"
    ],
    "dropped_tags": [
      "q8_0"
    ],
    "downloads": 12831,
    "likes": 6,
    "last_updated": "2025-01-31T10:38:51+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "qwen2-5-coder-0-5b-q8",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08556446061524536,
      "code": 0.23613526473828106,
      "math": 0.07501751458535529,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 1.3,
    "ram_recommended_gb": 1.63,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 1.3,
    "quant_bits": 8,
    "format": "gguf",
    "quant_class": "gguf-q8",
    "size_hint": "<2B",
    "params_b": 0.5,
    "tier": "high",
    "model_url": "https://huggingface.co/ggml-org/Qwen2.5-Coder-0.5B-Q8_0-GGUF"
  },
  {
    "model_id": "codellama/CodeLlama-13b-Instruct-hf",
    "label": "Codellama 13B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 12751,
    "likes": 154,
    "last_updated": "2024-04-12T14:19:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.11232142857142857,
      "math": 0.02256093279839519,
      "story": 0.004520310932798395,
      "roleplay": 0.004520310932798395
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/CodeLlama-13B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-GGUF/resolve/main/codellama-13b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-13b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "codellama/CodeLlama-13b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/codellama/CodeLlama-13b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 26032098592,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 26032098592
      },
      {
        "model_id": "TheBloke/CodeLlama-13B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-GGUF/resolve/main/codellama-13b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-13b.Q2_K.gguf"
      },
      {
        "model_id": "second-state/CodeLlama-13B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/CodeLlama-13B-Instruct-GGUF/resolve/main/codellama-13b-instruct.Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 7464572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-13b-instruct.Q4_0.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-13b-Instruct-hf-4bit-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-13b-Instruct-hf-4bit-MLX/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 6814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-13B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259762872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-13B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7248314992,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-13B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7248314992,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "unsloth/codellama-13b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codellama-13b-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 8114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/CodeLlama-13b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-13b-hf-GGUF/resolve/main/CodeLlama-13b-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-13b-hf-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-13b-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-13b-hf-4bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 6814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-13b-hf-8bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-13b-hf-8bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-13b-Instruct-hf-8bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-13b-Instruct-hf-8bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/CodeLlama-13B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-13B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259762872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "DevShubham/Codellama-13B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/DevShubham/Codellama-13B-Instruct-GGUF/resolve/main/codellama-13b-instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-13b-instruct.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-13b-hf-6bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-13b-hf-6bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 10064572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ton-An/CodeLlama-13b-hf-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ton-An/CodeLlama-13b-hf-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 6814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 8.98,
    "ram_recommended_gb": 11.23,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 8.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-13b-Instruct-hf"
  },
  {
    "model_id": "01-ai/Yi-1.5-34B-Chat",
    "label": "Yi 1.5 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 12724,
    "likes": 272,
    "last_updated": "2024-08-27T07:11:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "yi-1-5-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.02352306920762287,
      "math": 0.014113841524573722,
      "story": 0.004704613841524575,
      "roleplay": 0.004704613841524575
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-1.5-34B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/01-ai/Yi-1.5-34B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 68777898032,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 68777898032
      },
      {
        "model_id": "second-state/Yi-1.5-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-1.5-34B-Chat-GGUF/resolve/main/Yi-1.5-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "bartowski/Yi-1.5-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-1.5-34B-Chat-GGUF/resolve/main/Yi-1.5-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "lmstudio-community/Yi-1.5-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Yi-1.5-34B-Chat-GGUF/resolve/main/Yi-1.5-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "gaianet/Yi-1.5-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-1.5-34B-Chat-GGUF/resolve/main/Yi-1.5-34B-Chat-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Yi-1.5-34B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Yi-1.5-34B-Chat-GGUF/resolve/main/Yi-1.5-34B-Chat.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat.Q4_K_M.gguf"
      },
      {
        "model_id": "modelscope/Yi-1.5-34B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/modelscope/Yi-1.5-34B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 25.66,
    "ram_recommended_gb": 32.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 25.66,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-1.5-34B-Chat"
  },
  {
    "model_id": "ggml-org/Qwen2.5-Coder-14B-Q8_0-GGUF",
    "label": "Qwen2.5 Coder 14B 0",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "q8_0"
    ],
    "dropped_tags": [
      "q8_0"
    ],
    "downloads": 12583,
    "likes": 1,
    "last_updated": "2024-11-18T13:53:03+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "qwen2-5-coder-14b-q8",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07842527582748246,
      "code": 0.10822967032967033,
      "math": 0.02352758274824474,
      "story": 0.004842527582748245,
      "roleplay": 0.004842527582748245
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "ggml-org/Qwen2.5-Coder-14B-Instruct-Q8_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ggml-org/Qwen2.5-Coder-14B-Instruct-Q8_0-GGUF/resolve/main/qwen2.5-coder-14b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 14314572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2.5-coder-14b-instruct-q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 17.98,
    "ram_recommended_gb": 22.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 17.98,
    "format": "gguf",
    "quant_class": "gguf-q8",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ggml-org/Qwen2.5-Coder-14B-Q8_0-GGUF"
  },
  {
    "model_id": "nvidia/Llama3-ChatQA-1.5-8B",
    "label": "Llama3 Chatqa 1.5 8B",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 12386,
    "likes": 552,
    "last_updated": "2024-05-24T17:28:49+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3qa-1-5-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02278961885656971,
      "math": 0.013673771313941825,
      "story": 0.004557923771313942,
      "roleplay": 0.004557923771313942
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/Llama3-ChatQA-1.5-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Llama3-ChatQA-1.5-8B-GGUF/resolve/main/Llama3-ChatQA-1.5-8B-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-8B-q8_0.gguf"
      },
      {
        "model_id": "lmstudio-community/Llama3-ChatQA-1.5-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama3-ChatQA-1.5-8B-GGUF/resolve/main/ChatQA-1.5-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "ChatQA-1.5-8B-Q8_0.gguf"
      },
      {
        "model_id": "duyntnet/Llama3-ChatQA-1.5-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/duyntnet/Llama3-ChatQA-1.5-8B-GGUF/resolve/main/Llama3-ChatQA-1.5-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-8B-Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama3-ChatQA-1.5-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama3-ChatQA-1.5-8B-GGUF/resolve/main/Llama3-ChatQA-1.5-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-8B-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Llama3-ChatQA-1.5-8B"
  },
  {
    "model_id": "DavidAU/Qwen3-128k-30B-A3B-NEO-MAX-Imatrix-gguf",
    "label": "Qwen3 128K 30B A3B Neo Max Imatrix",
    "tags": [
      "gguf",
      "moe",
      "mps",
      "small",
      "story"
    ],
    "raw_tags": [
      "gguf",
      "moe",
      "mps",
      "small",
      "story"
    ],
    "dropped_tags": [],
    "downloads": 12278,
    "likes": 23,
    "last_updated": "2025-07-28T00:18:21+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "a3b",
    "canonical_base": "qwen3-128k-30b-a3b-neo-max-imatrix",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.068231900244252,
      "code": 0.0097439800380925,
      "math": 0.0,
      "story": 0.35,
      "roleplay": 0.038044166181065514
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 60.8,
    "ram_recommended_gb": 76.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 60.8,
    "quant_class": "a3b",
    "format": "gguf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/Qwen3-128k-30B-A3B-NEO-MAX-Imatrix-gguf"
  },
  {
    "model_id": "Snowflake/snowflake-arctic-instruct",
    "label": "Snowflake Arctic",
    "tags": [
      "chat",
      "hf",
      "moe"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "moe"
    ],
    "dropped_tags": [],
    "downloads": 12134,
    "likes": 358,
    "last_updated": "2024-05-21T01:08:33+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "snowflake-arctic",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2942757219021708,
      "code": 0.022186530466821733,
      "math": 0.019376045174454643,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/Snowflake/snowflake-arctic-instruct"
  },
  {
    "model_id": "databricks/dbrx-instruct",
    "label": "Dbrx",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 12092,
    "likes": 1116,
    "last_updated": "2024-04-19T07:33:52+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dbrx",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.29502273373832943,
      "code": 0.0220569058150411,
      "math": 0.015922942179009737,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/databricks/dbrx-instruct"
  },
  {
    "model_id": "ALLaM-AI/ALLaM-7B-Instruct-preview",
    "label": "Allam 7B Preview",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 11948,
    "likes": 125,
    "last_updated": "2025-07-14T09:06:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "allam-7b-preview",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.021535857572718156,
      "math": 0.012921514543630894,
      "story": 0.004307171514543631,
      "roleplay": 0.004307171514543631
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tensorblock/ALLaM-7B-Instruct-preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/ALLaM-7B-Instruct-preview-GGUF/resolve/main/ALLaM-7B-Instruct-preview-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "ALLaM-7B-Instruct-preview-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ALLaM-AI/ALLaM-7B-Instruct-preview"
  },
  {
    "model_id": "speakleash/Bielik-11B-v2.3-Instruct",
    "label": "Bielik 11B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "v2.3"
    ],
    "dropped_tags": [
      "v2.3"
    ],
    "downloads": 11719,
    "likes": 51,
    "last_updated": "2025-06-06T08:17:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "bielik-11b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.0241123370110331,
      "math": 0.014467402206619859,
      "story": 0.00482246740220662,
      "roleplay": 0.00482246740220662
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.3-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.3-Instruct-GGUF/resolve/main/Bielik-11B-v2.3-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 9114572800,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.3-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 8564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct-GGUF/resolve/main/Bielik-11B-v2.6-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 9114572800,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.6-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.2-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct-GGUF/resolve/main/Bielik-11B-v2.2-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 9114572800,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.2-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.2-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6200751216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6200751216
      },
      {
        "model_id": "bartowski/Bielik-11B-v2.2-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Bielik-11B-v2.2-Instruct-GGUF/resolve/main/Bielik-11B-v2.2-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 22339170304,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.2-Instruct-f16.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.2-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 11314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.5-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.5-Instruct-GGUF/resolve/main/Bielik-11B-v2.5-Instruct-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 22339170912,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.5-Instruct-fp16.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.3-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.3-Instruct-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6200751216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6200751216
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.6-Instruct-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.6-Instruct-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 11314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.5-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.5-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6192930808,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6192930808
      },
      {
        "model_id": "QuantFactory/Bielik-11B-v2-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Bielik-11B-v2-GGUF/resolve/main/Bielik-11B-v2.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 3614572800,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.Q2_K.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.0-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.0-Instruct-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6200751216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6200751216
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.2-Instruct-MLX-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct-MLX-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 5814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.2-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.2-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6192930808,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6192930808
      },
      {
        "model_id": "second-state/Bielik-11B-v2.3-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Bielik-11B-v2.3-Instruct-GGUF/resolve/main/Bielik-11B-v2.3-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 22339171200,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.3-Instruct-f16.gguf"
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.1-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.1-Instruct-GPTQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6200751216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6200751216
      },
      {
        "model_id": "speakleash/Bielik-11B-v2.1-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-11B-v2.1-Instruct-GGUF/resolve/main/Bielik-11B-v2.1-Instruct.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 9114572800,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.1-Instruct.Q6_K.gguf"
      },
      {
        "model_id": "gaianet/Bielik-11B-v2.3-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Bielik-11B-v2.3-Instruct-GGUF/resolve/main/Bielik-11B-v2.3-Instruct-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 22339171200,
        "notes": null,
        "revision": "main",
        "filename": "Bielik-11B-v2.3-Instruct-f16.gguf"
      },
      {
        "model_id": "lknik/Bielik-11B-v2.3-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lknik/Bielik-11B-v2.3-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 11314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 11.08,
    "ram_recommended_gb": 13.85,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 11.08,
    "quant_class": null,
    "format": "hf",
    "size_hint": "11B",
    "params_b": 11.0,
    "tier": "high",
    "model_url": "https://huggingface.co/speakleash/Bielik-11B-v2.3-Instruct"
  },
  {
    "model_id": "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B",
    "label": "Hyperclovax Seed Text 0.5B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 11659,
    "likes": 71,
    "last_updated": "2025-07-21T15:13:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hyperclovax-seed-text-0-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.025171765295887664,
      "math": 0.015103059177532598,
      "story": 0.005034353059177533,
      "roleplay": 0.005034353059177533
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/HyperCLOVAX-SEED-Text-Instruct-0.5B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/HyperCLOVAX-SEED-Text-Instruct-0.5B-GGUF/resolve/main/HyperCLOVAX-SEED-Text-Instruct-0.5B-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 1136722944,
        "notes": null,
        "revision": "main",
        "filename": "HyperCLOVAX-SEED-Text-Instruct-0.5B-bf16.gguf"
      }
    ],
    "ram_estimate_gb": 1.8,
    "ram_recommended_gb": 2.25,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 1.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.5,
    "tier": "high",
    "model_url": "https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B"
  },
  {
    "model_id": "RedHatAI/Meta-Llama-3.1-70B-Instruct-quantized.w4a16",
    "label": "Meta Llama 3.1 70B Quantized.W4A16",
    "tags": [
      "chat",
      "cuda",
      "gptq",
      "large"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "gptq",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 11569,
    "likes": 32,
    "last_updated": "2025-02-12T16:49:27+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gptq",
    "quant_bits": 6,
    "canonical_base": "meta-llama-3-1-70b-quantized-w4a16",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.31036407344881983,
      "code": 0.021363401870119234,
      "math": 0.015608152215666344,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 59.6,
    "ram_recommended_gb": 74.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 59.6,
    "format": "gptq",
    "quant_class": "gptq",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Meta-Llama-3.1-70B-Instruct-quantized.w4a16"
  },
  {
    "model_id": "allenai/OLMo-2-0325-32B-Instruct",
    "label": "Olmo 2 0325 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 11506,
    "likes": 141,
    "last_updated": "2025-03-14T22:45:15+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olmo-2-0325-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.024852056168505516,
      "math": 0.014911233701103309,
      "story": 0.004970411233701104,
      "roleplay": 0.004970411233701104
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "allenai/OLMo-2-0325-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/allenai/OLMo-2-0325-32B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 128937202568,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 128937202568
      },
      {
        "model_id": "unsloth/OLMo-2-0325-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/OLMo-2-0325-32B-Instruct-GGUF/resolve/main/OLMo-2-0325-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMo-2-0325-32B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/OLMo-2-0325-32B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/OLMo-2-0325-32B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/OLMo-2-0325-32B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/OLMo-2-0325-32B-Instruct-GGUF/resolve/main/OLMo-2-0325-32B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "OLMo-2-0325-32B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 20.38,
    "ram_recommended_gb": 25.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 20.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/allenai/OLMo-2-0325-32B-Instruct"
  },
  {
    "model_id": "Qwen/Qwen2-57B-A14B-Instruct",
    "label": "Qwen2 57B A14B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10690,
    "likes": 81,
    "last_updated": "2024-08-21T10:24:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-57b-a14b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.025309679037111336,
      "math": 0.0151858074222668,
      "story": 0.005061935807422268,
      "roleplay": 0.005061935807422268
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen2-57B-A14B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-57B-A14B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 114818032896,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 114818032896
      },
      {
        "model_id": "Qwen/Qwen2-57B-A14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct-GGUF/resolve/main/qwen2-57b-a14b-instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 31664572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen2-57b-a14b-instruct-q4_k_m.gguf"
      },
      {
        "model_id": "legraphista/Qwen2-57B-A14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/legraphista/Qwen2-57B-A14B-Instruct-GGUF/resolve/main/Qwen2-57B-A14B-Instruct.Q4_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 31664572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-57B-A14B-Instruct.Q4_K.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2-57B-A14B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2-57B-A14B-GGUF/resolve/main/Qwen2-57B-A14B-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 31664572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-57B-A14B-Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Qwen2-57B-A14B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Qwen2-57B-A14B-Instruct-GGUF/resolve/main/Qwen2-57B-A14B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 31664572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-57B-A14B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-57B-A14B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 34514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen2-57B-A14B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-57B-A14B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 28814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 42.22,
    "ram_recommended_gb": 52.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 42.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "57B",
    "params_b": 57.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct"
  },
  {
    "model_id": "DavidAU/Qwen2.5-MOE-2x-4x-6x-8x__7B__Power-CODER__19B-30B-42B-53B-gguf",
    "label": "Qwen2.5 2X 4X 6X 8X 7B Power Coder 19B 30B 42B 53B",
    "tags": [
      "chat",
      "code",
      "gguf",
      "moe",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "moe",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 11260,
    "likes": 3,
    "last_updated": "2025-07-28T00:17:35+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "qwen2-5-moe-2x-4x-6x-8x-7b-power-coder-19b-30b-42b-53b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.3006204642744865,
      "code": 0.24269494535070343,
      "math": 0.07115712657715638,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 38.8,
    "ram_recommended_gb": 48.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 38.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "19B",
    "params_b": 19.0,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/Qwen2.5-MOE-2x-4x-6x-8x__7B__Power-CODER__19B-30B-42B-53B-gguf"
  },
  {
    "model_id": "bigcode/starcoder",
    "label": "Starcoder",
    "tags": [
      "code",
      "hf"
    ],
    "raw_tags": [
      "code",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 11187,
    "likes": 2891,
    "last_updated": "2024-10-08T20:53:18+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "starcoder",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0720060180541625,
      "code": 0.11660714285714285,
      "math": 0.02160180541624875,
      "story": 0.0042006018054162484,
      "roleplay": 0.0042006018054162484
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Narsil/starcoder-gptq",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Narsil/starcoder-gptq/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 9198404552,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/starcoder-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/starcoder-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 8906589576,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/bigcode/starcoder"
  },
  {
    "model_id": "OrionStarAI/Orion-14B-Chat",
    "label": "Orion 14B",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 11070,
    "likes": 66,
    "last_updated": "2024-04-11T10:48:51+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "orion-14b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.30045831685849755,
      "code": 0.2422420402582709,
      "math": 0.06847552541996278,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 8.5,
    "ram_recommended_gb": 10.63,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.5,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat"
  },
  {
    "model_id": "failspy/Meta-Llama-3-8B-Instruct-abliterated-v3",
    "label": "Meta Llama 3 8B Abliterated",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 11063,
    "likes": 52,
    "last_updated": "2024-05-30T12:39:03+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-8b-ablerated",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.021786609829488466,
      "math": 0.01307196589769308,
      "story": 0.004357321965897693,
      "roleplay": 0.004357321965897693
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-abliterated-v3-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-abliterated-v3-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-abliterated-v3-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-abliterated-v3.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Meta-Llama-3-8B-Instruct-abliterated-v3.Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/failspy/Meta-Llama-3-8B-Instruct-abliterated-v3"
  },
  {
    "model_id": "yanolja/EEVE-Korean-Instruct-10.8B-v1.0",
    "label": "Eeve Korean 10.8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "v1.0"
    ],
    "dropped_tags": [
      "v1.0"
    ],
    "downloads": 11006,
    "likes": 159,
    "last_updated": "2024-06-26T03:27:44+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "eeve-korean-10-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.022839769307923773,
      "math": 0.013703861584754264,
      "story": 0.0045679538615847545,
      "roleplay": 0.0045679538615847545
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf/resolve/main/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 11114572800,
        "notes": null,
        "revision": "main",
        "filename": "EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf"
      },
      {
        "model_id": "yanolja/EEVE-Korean-10.8B-v1.0",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/yanolja/EEVE-Korean-10.8B-v1.0/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 21609899456,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 21609899456
      },
      {
        "model_id": "Copycats/EEVE-Korean-Instruct-10.8B-v1.0-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Copycats/EEVE-Korean-Instruct-10.8B-v1.0-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 11114572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 14.14,
    "ram_recommended_gb": 17.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 14.14,
    "quant_class": null,
    "format": "hf",
    "size_hint": "10.8B",
    "params_b": 10.8,
    "tier": "high",
    "model_url": "https://huggingface.co/yanolja/EEVE-Korean-Instruct-10.8B-v1.0"
  },
  {
    "model_id": "Qwen/Qwen1.5-72B-Chat",
    "label": "Qwen1.5 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10945,
    "likes": 218,
    "last_updated": "2024-10-08T05:17:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen1-5-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23214285714285715,
      "code": 0.0238302407221665,
      "math": 0.014298144433299898,
      "story": 0.0047660481444333005,
      "roleplay": 0.0047660481444333005
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Qwen/Qwen1.5-72B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-72B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 144575951856,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 144575951856
      },
      {
        "model_id": "Qwen/Qwen1.5-72B-Chat-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Qwen/Qwen1.5-72B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 41249398584,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 41249398584
      },
      {
        "model_id": "Qwen/Qwen1.5-72B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat-GGUF/resolve/main/qwen1_5-72b-chat-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "qwen1_5-72b-chat-q2_k.gguf"
      },
      {
        "model_id": "Qwen/Qwen1.5-72B-Chat-GPTQ-Int8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat-GPTQ-Int8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Qwen1.5-72B-Chat-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen1.5-72B-Chat-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 53.02,
    "ram_recommended_gb": 66.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 53.02,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen1.5-72B-Chat"
  },
  {
    "model_id": "nvidia/Llama-3_1-Nemotron-51B-Instruct",
    "label": "Llama 3 1 Nemotron 51B",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 10926,
    "likes": 209,
    "last_updated": "2025-07-06T15:52:27+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-nemotron-51b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24214285714285713,
      "code": 0.022319458375125376,
      "math": 0.013391675025075225,
      "story": 0.004463891675025075,
      "roleplay": 0.004463891675025075
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "ymcki/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ymcki/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct.imatrix.Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 28364572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct.imatrix.Q4_0.gguf"
      },
      {
        "model_id": "lmstudio-community/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 41114572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct-Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Llama-3_1-Nemotron-51B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3_1-Nemotron-51B-Instruct-GGUF/resolve/main/Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 15614572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3_1-Nemotron-51B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 19.54,
    "ram_recommended_gb": 24.43,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 19.54,
    "quant_class": null,
    "format": "hf",
    "size_hint": "51B",
    "params_b": 51.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Llama-3_1-Nemotron-51B-Instruct"
  },
  {
    "model_id": "OpenVINO/TinyLlama-1.1B-Chat-v1.0-int4-ov",
    "label": "Tinyllama 1.1B Ov",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "int4",
      "small",
      "v1.0"
    ],
    "dropped_tags": [
      "int4",
      "v1.0"
    ],
    "downloads": 10850,
    "likes": 0,
    "last_updated": "2024-10-31T05:49:29+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "int",
    "quant_bits": 4,
    "canonical_base": "tinyllama-1-1b-v1-0-ov",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.18714285714285714,
      "code": 0.023993229689067204,
      "math": 0.014395937813440321,
      "story": 0.004798645937813441,
      "roleplay": 0.004798645937813441
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "OpenVINO/TinyLlama-1.1B-Chat-v1.0-int8-ov",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "int",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 1414572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "OpenVINO/TinyLlama-1.1B-Chat-v1.0-fp16-ov",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 2.5,
    "ram_recommended_gb": 3.13,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.5,
    "quant_class": "q4",
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.1,
    "tier": "high",
    "model_url": "https://huggingface.co/OpenVINO/TinyLlama-1.1B-Chat-v1.0-int4-ov"
  },
  {
    "model_id": "curiousmind147/microsoft-phi-4-AWQ-4bit-GEMM",
    "label": "Microsoft Phi 4 4Bit Gemm",
    "tags": [
      "awq",
      "chat",
      "cuda"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "cuda"
    ],
    "dropped_tags": [],
    "downloads": 10548,
    "likes": 1,
    "last_updated": "2025-02-04T07:46:22+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "quant_bits": 4,
    "canonical_base": "microsoft-phi-4-gemm",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2798693151628025,
      "code": 0.010602613217322405,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "awq",
    "quant_class": "awq-q4",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/curiousmind147/microsoft-phi-4-AWQ-4bit-GEMM"
  },
  {
    "model_id": "dphn/dolphin-2.9.1-mixtral-1x22b",
    "label": "Dolphin 2.9.1 Mixtral 1X22B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10461,
    "likes": 44,
    "last_updated": "2024-05-22T22:05:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-1-mixtral-1x22b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.024356820461384154,
      "math": 0.014614092276830491,
      "story": 0.0048713640922768316,
      "roleplay": 0.0048713640922768316
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/dolphin-2.9.1-mixtral-1x22b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/dolphin-2.9.1-mixtral-1x22b-GGUF/resolve/main/dolphin-2.9.1-mixtral-1x22b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 6914572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9.1-mixtral-1x22b-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 9.1,
    "ram_recommended_gb": 11.38,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.1,
    "quant_class": null,
    "format": "hf",
    "size_hint": "22B",
    "params_b": 22.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9.1-mixtral-1x22b"
  },
  {
    "model_id": "abacusai/Smaug-Llama-3-70B-Instruct",
    "label": "Smaug Llama 3 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10444,
    "likes": 144,
    "last_updated": "2024-06-04T21:41:27+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smaug-llama-3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02515295887662989,
      "math": 0.015091775325977934,
      "story": 0.005030591775325978,
      "roleplay": 0.005030591775325978
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Smaug-Llama-3-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Smaug-Llama-3-70B-Instruct-GGUF/resolve/main/Smaug-Llama-3-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Smaug-Llama-3-70B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct"
  },
  {
    "model_id": "abacusai/Smaug-Llama-3-70B-Instruct-32K",
    "label": "Smaug Llama 3 70B 32K",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10416,
    "likes": 21,
    "last_updated": "2024-08-06T14:18:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smaug-llama-3-70b-32k",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02137913741223671,
      "math": 0.012827482447342026,
      "story": 0.004275827482447342,
      "roleplay": 0.004275827482447342
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Smaug-Llama-3-70B-Instruct-32K-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Smaug-Llama-3-70B-Instruct-32K-GGUF/resolve/main/Smaug-Llama-3-70B-Instruct-32K-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Smaug-Llama-3-70B-Instruct-32K-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct-32K"
  },
  {
    "model_id": "bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF",
    "label": "Pocketdoc Dans Personalityengine 24B",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "v1.3.0"
    ],
    "dropped_tags": [
      "v1.3.0"
    ],
    "downloads": 10409,
    "likes": 29,
    "last_updated": "2025-05-23T19:20:31+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "pocketdoc-dans-personalyengine-v1-3-0-24b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07663239719157473,
      "code": 0.12361428571428572,
      "math": 0.02298971915747242,
      "story": 0.004663239719157473,
      "roleplay": 0.004663239719157473
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 14.0,
    "ram_recommended_gb": 17.51,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/PocketDoc_Dans-PersonalityEngine-V1.3.0-24b-GGUF",
    "variants": [
      {
        "model_id": "DevQuasar/PocketDoc.Dans-PersonalityEngine-V1.3.0-24b-GGUF",
        "format": "gguf",
        "quant_method": "gguf",
        "quant_bits": 4,
        "filename": "PocketDoc.Dans-PersonalityEngine-V1.3.0-24b.Q4_K_M.gguf",
        "source": "huggingface",
        "revision": "main",
        "download_url": "https://huggingface.co/DevQuasar/PocketDoc.Dans-PersonalityEngine-V1.3.0-24b-GGUF/resolve/main/PocketDoc.Dans-PersonalityEngine-V1.3.0-24b.Q4_K_M.gguf?download=true"
      }
    ]
  },
  {
    "model_id": "failspy/llama-3-70B-Instruct-abliterated",
    "label": "Llama 3 70B Abliterated",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10338,
    "likes": 110,
    "last_updated": "2024-05-07T15:36:53+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-70b-ablerated",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.024325476429287864,
      "math": 0.014595285857572717,
      "story": 0.0048650952858575736,
      "roleplay": 0.0048650952858575736
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "failspy/Llama-3-70B-Instruct-abliterated-v3",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/failspy/Llama-3-70B-Instruct-abliterated-v3/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 141107497872,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 141107497872
      },
      {
        "model_id": "bartowski/llama-3-70B-Instruct-abliterated-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/llama-3-70B-Instruct-abliterated-GGUF/resolve/main/llama-3-70B-Instruct-abliterated-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-70B-Instruct-abliterated-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/failspy/llama-3-70B-Instruct-abliterated"
  },
  {
    "model_id": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5",
    "label": "Meta Llama 3 70B Abliterated",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large",
      "v3.5"
    ],
    "dropped_tags": [
      "v3.5"
    ],
    "downloads": 10185,
    "likes": 45,
    "last_updated": "2024-05-30T14:27:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-70b-ablerated",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.29252419738533963,
      "code": 0.013958488322504146,
      "math": 0.004964783101867752,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5"
  },
  {
    "model_id": "failspy/Smaug-Llama-3-70B-Instruct-abliterated-v3",
    "label": "Smaug Llama 3 70B Abliterated",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 10129,
    "likes": 13,
    "last_updated": "2024-05-22T05:46:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smaug-llama-3-70b-ablerated",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.29245160615134713,
      "code": 0.016279349311027484,
      "math": 0.010200498882866922,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/failspy/Smaug-Llama-3-70B-Instruct-abliterated-v3"
  },
  {
    "model_id": "chujiezheng/Smaug-Llama-3-70B-Instruct-ExPO",
    "label": "Smaug Llama 3 70B Expo",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10086,
    "likes": 2,
    "last_updated": "2024-05-27T18:19:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "smaug-llama-3-70b-expo",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2665040473726547,
      "code": 0.01426297075417798,
      "math": 0.004456191780299651,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/chujiezheng/Smaug-Llama-3-70B-Instruct-ExPO"
  },
  {
    "model_id": "tenyx/Llama3-TenyxChat-70B",
    "label": "Llama3 Tenyxchat 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10060,
    "likes": 64,
    "last_updated": "2024-05-08T00:42:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3-tenyx-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2941392643718015,
      "code": 0.01964693981927836,
      "math": 0.013138262085740178,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tenyx/Llama3-TenyxChat-70B"
  },
  {
    "model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
    "label": "Qwen3 Coder 480B A35B 1M",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 10039,
    "likes": 36,
    "last_updated": "2025-07-23T23:45:02+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "qwen3-coder-480b-a35b-1m",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24722857142857144,
      "code": 0.12361428571428572,
      "math": 0.02331318956870612,
      "story": 0.004771063189568707,
      "roleplay": 0.004771063189568707
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Qwen3-Coder-480B-A35B-Instruct-1M",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 960.8,
    "ram_recommended_gb": 1201.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 960.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "70B",
    "params_b": 480.0,
    "tier": "high",
    "model_url": "https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-1M-GGUF"
  },
  {
    "model_id": "01-ai/Yi-1.5-34B-Chat-16K",
    "label": "Yi 1.5 34B 16K",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10037,
    "likes": 27,
    "last_updated": "2024-06-26T10:42:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "yi-1-5-34b-16k",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.021680040120361083,
      "math": 0.01300802407221665,
      "story": 0.004336008024072217,
      "roleplay": 0.004336008024072217
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "second-state/Yi-1.5-34B-Chat-16K-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Yi-1.5-34B-Chat-16K-GGUF/resolve/main/Yi-1.5-34B-Chat-16K-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-16K-Q4_K_M.gguf"
      },
      {
        "model_id": "gaianet/Yi-1.5-34B-Chat-16K-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Yi-1.5-34B-Chat-16K-GGUF/resolve/main/Yi-1.5-34B-Chat-16K-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-16K-Q4_K_M.gguf"
      },
      {
        "model_id": "bartowski/Yi-1.5-34B-Chat-16K-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Yi-1.5-34B-Chat-16K-GGUF/resolve/main/Yi-1.5-34B-Chat-16K-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "Yi-1.5-34B-Chat-16K-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 23.62,
    "ram_recommended_gb": 29.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 23.62,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-1.5-34B-Chat-16K"
  },
  {
    "model_id": "BAAI/AquilaChat2-7B",
    "label": "Aquilachat2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10021,
    "likes": 15,
    "last_updated": "2024-08-15T07:24:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "aquila2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.02112211634904714,
      "math": 0.012673269809428284,
      "story": 0.004224423269809429,
      "roleplay": 0.004224423269809429
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "BAAI/Aquila2-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/BAAI/Aquila2-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 30622827376,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 30622827376
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/BAAI/AquilaChat2-7B"
  },
  {
    "model_id": "ValiantLabs/Llama3-70B-Fireplace",
    "label": "Llama3 70B Fireplace",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10020,
    "likes": 3,
    "last_updated": "2025-03-12T00:29:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3-70b-fireplace",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22483516483516483,
      "code": 0.022357071213640924,
      "math": 0.013414242728184554,
      "story": 0.004471414242728185,
      "roleplay": 0.004471414242728185
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "tensorblock/Llama3-70B-Fireplace-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama3-70B-Fireplace-GGUF/resolve/main/Llama3-70B-Fireplace-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-70B-Fireplace-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ValiantLabs/Llama3-70B-Fireplace"
  },
  {
    "model_id": "UnicomLLM/Unichat-llama3-Chinese-8B",
    "label": "Unichat Llama3 Chinese 8B",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 10014,
    "likes": 73,
    "last_updated": "2024-04-22T01:11:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "uni-llama3-chinese-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.023961885656970914,
      "math": 0.014377131394182547,
      "story": 0.004792377131394183,
      "roleplay": 0.004792377131394183
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/Unichat-llama3-Chinese-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Unichat-llama3-Chinese-8B-GGUF/resolve/main/Unichat-llama3-Chinese-8B.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Unichat-llama3-Chinese-8B.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Unichat-llama3-Chinese-8B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Unichat-llama3-Chinese-8B-GGUF/resolve/main/Unichat-llama3-Chinese-8B-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Unichat-llama3-Chinese-8B-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/UnicomLLM/Unichat-llama3-Chinese-8B"
  },
  {
    "model_id": "turboderp/Cat-Llama-3-70B-instruct",
    "label": "Cat Llama 3 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10011,
    "likes": 53,
    "last_updated": "2024-05-08T19:29:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "cat-llama-3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.023335005015045138,
      "math": 0.014001003009027083,
      "story": 0.0046670010030090275,
      "roleplay": 0.0046670010030090275
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Cat-Llama-3-70B-instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Cat-Llama-3-70B-instruct-GGUF/resolve/main/Cat-Llama-3-70B-instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Cat-Llama-3-70B-instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/turboderp/Cat-Llama-3-70B-instruct"
  },
  {
    "model_id": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3",
    "label": "Llama 3 8B Sppo Iter3",
    "tags": [
      "chat",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 10009,
    "likes": 83,
    "last_updated": "2024-06-28T19:36:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-8b-sppoer3",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22464285714285714,
      "code": 0.023811434302908725,
      "math": 0.014286860581745234,
      "story": 0.004762286860581746,
      "roleplay": 0.004762286860581746
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Llama-3-Instruct-8B-SPPO-Iter3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama-3-Instruct-8B-SPPO-Iter3-GGUF/resolve/main/Llama-3-Instruct-8B-SPPO-Iter3-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Instruct-8B-SPPO-Iter3-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Llama-3-Instruct-8B-SPPO-Iter3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama-3-Instruct-8B-SPPO-Iter3-GGUF/resolve/main/Llama-3-Instruct-8B-SPPO-Iter3.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Instruct-8B-SPPO-Iter3.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-Instruct-8B-SPPO-Iter3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-Instruct-8B-SPPO-Iter3-GGUF/resolve/main/Llama-3-Instruct-8B-SPPO-Iter3-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Instruct-8B-SPPO-Iter3-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3"
  },
  {
    "model_id": "ValiantLabs/Llama3-70B-ShiningValiant2",
    "label": "Llama3 70B Shiningvaliant2",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 10008,
    "likes": 5,
    "last_updated": "2025-03-12T00:28:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3-70b-shiningvaliant2",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.29908356028602884,
      "code": 0.017317132935221885,
      "math": 0.01204573580914134,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ValiantLabs/Llama3-70B-ShiningValiant2"
  },
  {
    "model_id": "SenseLLM/ReflectionCoder-DS-33B",
    "label": "Reflectioncoder Ds 33B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 10000,
    "likes": 4,
    "last_updated": "2024-07-01T11:01:15+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "reflectioncoder-ds-33b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.08416827267527902,
      "code": 0.21813850449652733,
      "math": 0.07287982845854582,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 66.8,
    "ram_recommended_gb": 83.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 66.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/SenseLLM/ReflectionCoder-DS-33B"
  },
  {
    "model_id": "google/codegemma-2b",
    "label": "Codegemma 2B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 9852,
    "likes": 84,
    "last_updated": "2024-08-07T18:27:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegemma-2b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08041875626880643,
      "code": 0.11125,
      "math": 0.024125626880641928,
      "story": 0.005041875626880642,
      "roleplay": 0.005041875626880642
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "unsloth/codegemma-2b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codegemma-2b/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 5012363856,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "bartowski/codegemma-2b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-2b-Q2_K.gguf"
      },
      {
        "model_id": "unsloth/codegemma-2b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codegemma-2b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/codegemma-2b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/codegemma-2b-GGUF/resolve/main/codegemma-2b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-2b-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/codegemma-2b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/codegemma-2b-GGUF/resolve/main/codegemma-2b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 914572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-2b.Q2_K.gguf"
      },
      {
        "model_id": "google/codegemma-2b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/google/codegemma-2b-GGUF/resolve/main/codegemma-2b.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-2b.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-2b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-2b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 2.62,
    "ram_recommended_gb": 3.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.62,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 2.0,
    "tier": "high",
    "model_url": "https://huggingface.co/google/codegemma-2b"
  },
  {
    "model_id": "stabilityai/stable-code-3b",
    "label": "Stable Code 3B",
    "tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 9546,
    "likes": 649,
    "last_updated": "2024-07-10T12:13:37+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "stable-code-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07768555667001004,
      "code": 0.11375,
      "math": 0.02330566700100301,
      "story": 0.004768555667001004,
      "roleplay": 0.004768555667001004
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "stabilityai/stable-code-instruct-3b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stabilityai/stable-code-instruct-3b/resolve/main/stable-code-3b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1964572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-3b-q4_k_m.gguf"
      },
      {
        "model_id": "bartowski/stable-code-instruct-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/stable-code-instruct-3b-GGUF/resolve/main/stable-code-instruct-3b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-instruct-3b-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/stable-code-instruct-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/stable-code-instruct-3b-GGUF/resolve/main/stable-code-instruct-3b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-instruct-3b-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/stable-code-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/stable-code-3b-GGUF/resolve/main/stable-code-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-3b.Q2_K.gguf"
      },
      {
        "model_id": "dgtalbug/stable-code-instruct-3b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/dgtalbug/stable-code-instruct-3b/resolve/main/stable-code-3b-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 1964572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-3b-q4_k_m.gguf"
      },
      {
        "model_id": "QuantFactory/stable-code-instruct-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/stable-code-instruct-3b-GGUF/resolve/main/stable-code-instruct-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-instruct-3b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/stable-code-instruct-3b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/stable-code-instruct-3b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "brittlewis12/stable-code-3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/stable-code-3b-GGUF/resolve/main/stable-code-3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "stable-code-3b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/stable-code-3b-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/stable-code-3b-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5590927105,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "mlx-community/stable-code-3b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/stable-code-3b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 2.26,
    "ram_recommended_gb": 2.83,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.26,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/stabilityai/stable-code-3b"
  },
  {
    "model_id": "dphn/dolphin-2.6-mixtral-8x7b",
    "label": "Dolphin 2.6 Mixtral 8X7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 9369,
    "likes": 211,
    "last_updated": "2024-05-20T15:08:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-6-mixtral-8x7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.026087011033099298,
      "math": 0.01565220661985958,
      "story": 0.00521740220661986,
      "roleplay": 0.00521740220661986
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/dolphin-2.6-mixtral-8x7b-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.6-mixtral-8x7b-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 7.48,
    "ram_recommended_gb": 9.35,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.48,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.6-mixtral-8x7b"
  },
  {
    "model_id": "NousResearch/Hermes-3-Llama-3.2-3B",
    "label": "Hermes 3 Llama 3.2 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 7903,
    "likes": 169,
    "last_updated": "2024-12-18T22:32:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hermes-3-llama-3-2-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.02611208625877633,
      "math": 0.015667251755265798,
      "story": 0.005222417251755266,
      "roleplay": 0.005222417251755266
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Hermes-3-Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Hermes-3-Llama-3.2-3B-GGUF/resolve/main/Hermes-3-Llama-3.2-3B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6433684576,
        "notes": null,
        "revision": "main",
        "filename": "Hermes-3-Llama-3.2-3B-f16.gguf"
      },
      {
        "model_id": "mlx-community/Hermes-3-Llama-3.2-3B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hermes-3-Llama-3.2-3B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "federicoramos77/Hermes-3-Llama-3.2-3B-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/federicoramos77/Hermes-3-Llama-3.2-3B-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "MaziyarPanahi/Hermes-3-Llama-3.2-3B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Hermes-3-Llama-3.2-3B-GGUF/resolve/main/Hermes-3-Llama-3.2-3B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1214572800,
        "notes": null,
        "revision": "main",
        "filename": "Hermes-3-Llama-3.2-3B.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Hermes-3-Llama-3.2-3B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hermes-3-Llama-3.2-3B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "divkix/Hermes-3-Llama-3.2-3B-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/divkix/Hermes-3-Llama-3.2-3B-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6425528971,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6425528971
      },
      {
        "model_id": "rudrankriyam/hermes-3-llama-3.2-3b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/rudrankriyam/hermes-3-llama-3.2-3b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 1807496278,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1807496278
      }
    ],
    "ram_estimate_gb": 2.98,
    "ram_recommended_gb": 3.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 2.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/NousResearch/Hermes-3-Llama-3.2-3B"
  },
  {
    "model_id": "HuggingFaceH4/zephyr-7b-alpha",
    "label": "Zephyr 7B Alpha",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 9068,
    "likes": 1111,
    "last_updated": "2024-10-16T11:53:22+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "zephyr-7b-alpha",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2310714285714286,
      "code": 0.02262036108324975,
      "math": 0.013572216649949849,
      "story": 0.00452407221664995,
      "roleplay": 0.00452407221664995
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/zephyr-7B-alpha-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/zephyr-7B-alpha-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662096,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/zephyr-7B-alpha-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/zephyr-7B-alpha-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880232,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "second-state/Zephyr-7B-Alpha-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Zephyr-7B-Alpha-GGUF/resolve/main/zephyr-7b-alpha-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-alpha-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/zephyr-7b-alpha-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/zephyr-7b-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-alpha.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/zephyr-7b-alpha-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/zephyr-7b-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-alpha.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha"
  },
  {
    "model_id": "Intel/neural-chat-7b-v3-3",
    "label": "Neural 7B 3",
    "tags": [
      "chat",
      "hf",
      "math",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "math",
      "small",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 8652,
    "likes": 78,
    "last_updated": "2024-11-11T05:17:37+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "neural-7b-v3",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.04032848545636911,
      "math": 0.06899999999999999,
      "story": 0.005065697091273822,
      "roleplay": 0.005065697091273822
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Intel/neural-chat-7b-v3-1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Intel/neural-chat-7b-v3-1/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14483497752,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14483497752
      },
      {
        "model_id": "QuantFactory/neural-chat-7b-v3-1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/neural-chat-7b-v3-1-GGUF/resolve/main/neural-chat-7b-v3-1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3-1.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/neural-chat-7B-v3-3-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/neural-chat-7B-v3-3-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158662216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/neural-chat-7B-v3-1-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/neural-chat-7B-v3-1-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150880232,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/neural-chat-7b-v3-1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/neural-chat-7b-v3-1-GGUF/resolve/main/neural-chat-7b-v3-1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3-1-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Neural-Chat-7B-v3-1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Neural-Chat-7B-v3-1-GGUF/resolve/main/neural-chat-7b-v3-1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3-1-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Neural-Chat-7B-v3-3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Neural-Chat-7B-v3-3-GGUF/resolve/main/neural-chat-7b-v3-3-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3-3-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/neural-chat-7b-v3-1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/neural-chat-7b-v3-1-GGUF/resolve/main/neural-chat-7b-v3-1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3-1.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Intel/neural-chat-7b-v3-3"
  },
  {
    "model_id": "codellama/CodeLlama-34b-Instruct-hf",
    "label": "Codellama 34B",
    "tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 8370,
    "likes": 292,
    "last_updated": "2024-04-12T14:20:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.11125,
      "math": 0.02218480441323972,
      "story": 0.00439493480441324,
      "roleplay": 0.00439493480441324
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "codellama/CodeLlama-34b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/codellama/CodeLlama-34b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 67487991400,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 67487991400
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-GGUF/resolve/main/codellama-34b.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-34b.Q4_K_M.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-GGUF/resolve/main/codellama-34b-instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-34b-instruct.Q4_K_M.gguf"
      },
      {
        "model_id": "unsloth/codellama-34b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codellama-34b-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "MaziyarPanahi/CodeLlama-34b-Instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/CodeLlama-34b-Instruct-hf-GGUF/resolve/main/CodeLlama-34b-Instruct-hf.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-34b-Instruct-hf.Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-34b-Instruct-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-34b-Instruct-hf-4bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 17314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-34b-Instruct-hf-6bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-34b-Instruct-hf-6bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 25814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-34b-Instruct-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-34b-Instruct-hf-4bit/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 17314572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "tensorblock/CodeLlama-34b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-34b-hf-GGUF/resolve/main/CodeLlama-34b-hf-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-34b-hf-Q4_K_M.gguf"
      },
      {
        "model_id": "mav23/CodeLlama-34b-Instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/CodeLlama-34b-Instruct-hf-GGUF/resolve/main/codellama-34b-instruct-hf.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-34b-instruct-hf.Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/CodeLlama-34b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/CodeLlama-34b-hf-GGUF/resolve/main/CodeLlama-34b-hf.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-34b-hf.Q4_K_M.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ipetrukha/CodeLlama-34b-Instruct-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ipetrukha/CodeLlama-34b-Instruct-hf-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 25.66,
    "ram_recommended_gb": 32.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 25.66,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf"
  },
  {
    "model_id": "inceptionai/jais-13b-chat",
    "label": "Jais 13B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 7658,
    "likes": 154,
    "last_updated": "2024-09-11T11:22:44+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "jais-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.022237963891675025,
      "math": 0.013342778335005015,
      "story": 0.004447592778335005,
      "roleplay": 0.004447592778335005
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "inceptionai/jais-13b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "asas-ai/jais_13B_8bit",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "8bit",
        "quant_bits": 8,
        "format": null,
        "size_bytes": 13314572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 16.78,
    "ram_recommended_gb": 20.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 16.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/inceptionai/jais-13b-chat"
  },
  {
    "model_id": "Zyphra/Zamba2-7B-Instruct",
    "label": "Zamba2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 7646,
    "likes": 91,
    "last_updated": "2025-05-16T01:50:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "zamba2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.024012036108324974,
      "math": 0.014407221664994984,
      "story": 0.004802407221664995,
      "roleplay": 0.004802407221664995
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Zyphra/Zamba2-7B-Instruct-v2",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Zyphra/Zamba2-7B-Instruct-v2/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14713587120,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14713587120
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Zyphra/Zamba2-7B-Instruct"
  },
  {
    "model_id": "codellama/CodeLlama-7b-Python-hf",
    "label": "Codellama 7B Python",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 7558,
    "likes": 143,
    "last_updated": "2024-04-12T14:16:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-7b-python",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08014292878635909,
      "code": 0.11125,
      "math": 0.024042878635907726,
      "story": 0.005014292878635908,
      "roleplay": 0.005014292878635908
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/CodeLlama-7B-Python-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b-python.Q2_K.gguf"
      },
      {
        "model_id": "meta-llama/CodeLlama-7b-Python-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/meta-llama/CodeLlama-7b-Python-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Python-4bit-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Python-4bit-MLX/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Python-mlx",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tensorblock/CodeLlama-7b-Python-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-7b-Python-hf-GGUF/resolve/main/CodeLlama-7b-Python-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-7b-Python-hf-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Python-hf-8bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Python-hf-8bit-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "mav23/CodeLlama-7b-Python-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/CodeLlama-7b-Python-hf-GGUF/resolve/main/codellama-7b-python-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-7b-python-hf.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Python-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Python-hf-4bit-mlx/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "mlx-community/CodeLlama-7b-Python-hf-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/CodeLlama-7b-Python-hf-4bit/resolve/main/weights.00.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "weights.00.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-Python-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Python-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896714728,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-7B-Python-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-7B-Python-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889391512,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-7b-Python-hf"
  },
  {
    "model_id": "baichuan-inc/Baichuan2-13B-Chat",
    "label": "Baichuan2 13B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 7433,
    "likes": 428,
    "last_updated": "2024-02-26T08:58:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "baichuan2-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.023504262788365097,
      "math": 0.014102557673019057,
      "story": 0.00470085255767302,
      "roleplay": 0.00470085255767302
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/Baichuan2-13B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Baichuan2-13B-Chat-GGUF/resolve/main/Baichuan2-13B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 4214572800,
        "notes": null,
        "revision": "main",
        "filename": "Baichuan2-13B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/Baichuan2-13B-Chat-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Baichuan2-13B-Chat-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 9135747368,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 5.86,
    "ram_recommended_gb": 7.33,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.86,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat"
  },
  {
    "model_id": "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407",
    "label": "Llama 3.1 70B Japanese 2407",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 7322,
    "likes": 76,
    "last_updated": "2024-07-26T02:30:17+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-1-70b-japanese",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.023146940822467404,
      "math": 0.013888164493480442,
      "story": 0.004629388164493481,
      "roleplay": 0.004629388164493481
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Llama-3.1-70B-Japanese-Instruct-2407-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-70B-Japanese-Instruct-2407-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3.1-70B-Japanese-Instruct-2407-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3.1-70B-Japanese-Instruct-2407-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/Llama-3.1-70B-Japanese-Instruct-2407-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3.1-70B-Japanese-Instruct-2407-GGUF/resolve/main/Llama-3.1-70B-Japanese-Instruct-2407-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3.1-70B-Japanese-Instruct-2407-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 85.18,
    "ram_recommended_gb": 106.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 85.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/cyberagent/Llama-3.1-70B-Japanese-Instruct-2407"
  },
  {
    "model_id": "OrionStarAI/OrionStar-Yi-34B-Chat",
    "label": "Orionstar Yi 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 6322,
    "likes": 60,
    "last_updated": "2024-03-26T10:27:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "orionstar-yi-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2902704323627503,
      "code": 0.01813023876357263,
      "math": 0.011150419708376304,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 68.8,
    "ram_recommended_gb": 86.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 68.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/OrionStarAI/OrionStar-Yi-34B-Chat"
  },
  {
    "model_id": "mosaicml/mpt-30b-chat",
    "label": "Mpt 30B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 5685,
    "likes": 202,
    "last_updated": "2024-03-05T20:26:11+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "mpt-30b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.020940320962888666,
      "math": 0.0125641925777332,
      "story": 0.004188064192577733,
      "roleplay": 0.004188064192577733
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "mosaicml/mpt-30b-instruct",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 60.8,
    "ram_recommended_gb": 76.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 60.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 30.0,
    "tier": "high",
    "model_url": "https://huggingface.co/mosaicml/mpt-30b-chat"
  },
  {
    "model_id": "microsoft/bitnet-b1.58-2B-4T",
    "label": "Bitnet B1.58 2B 4T",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 5532,
    "likes": 1149,
    "last_updated": "2025-05-01T05:21:59+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "bnet-b1-58-2b-4t",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24107142857142858,
      "code": 0.022156469408224674,
      "math": 0.013293881644934804,
      "story": 0.004431293881644935,
      "roleplay": 0.004431293881644935
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "microsoft/bitnet-b1.58-2B-4T-gguf",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tdh111/bitnet-b1.58-2B-4T-GGUF",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 2314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/bitnet-b1.58-2B-4T-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/bitnet-b1.58-2B-4T-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 2314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/bitnet-b1.58-2B-4T-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/bitnet-b1.58-2B-4T-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 1314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/bitnet-b1.58-2B-4T",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/bitnet-b1.58-2B-4T/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1178623935,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 1178623935
      },
      {
        "model_id": "mlx-community/bitnet-b1.58-2B-4T-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/bitnet-b1.58-2B-4T-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 1814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 3.58,
    "ram_recommended_gb": 4.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 2.0,
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T"
  },
  {
    "model_id": "RedHatAI/Meta-Llama-3.1-70B-Instruct-FP8",
    "label": "Meta Llama 3.1 70B Fp8",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 5399,
    "likes": 50,
    "last_updated": "2025-03-25T18:36:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "meta-llama-3-1-70b-fp8",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.023792627883650955,
      "math": 0.014275576730190573,
      "story": 0.004758525576730191,
      "roleplay": 0.004758525576730191
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "RedHatAI/Meta-Llama-3.1-70B-FP8",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/RedHatAI/Meta-Llama-3.1-70B-FP8/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 72656575880,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 72656575880
      }
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/RedHatAI/Meta-Llama-3.1-70B-Instruct-FP8"
  },
  {
    "model_id": "stabilityai/stablelm-2-zephyr-1_6b",
    "label": "Stablelm 2 Zephyr 1 6B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 5395,
    "likes": 185,
    "last_updated": "2024-06-03T15:16:39+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 6,
    "canonical_base": "stablelm-2-zephyr-1-6b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.022632898696088265,
      "math": 0.013579739217652959,
      "story": 0.004526579739217653,
      "roleplay": 0.004526579739217653
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "brittlewis12/stablelm-2-zephyr-1_6b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/brittlewis12/stablelm-2-zephyr-1_6b-GGUF/resolve/main/stablelm-2-zephyr-1_6b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "stablelm-2-zephyr-1_6b.Q6_K.gguf"
      },
      {
        "model_id": "afrideva/stablelm-2-zephyr-1_6b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/stablelm-2-zephyr-1_6b-GGUF/resolve/main/stablelm-2-zephyr-1_6b.q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main",
        "filename": "stablelm-2-zephyr-1_6b.q6_k.gguf"
      },
      {
        "model_id": "teleprint-me/stablelm-2-zephyr-1_6b",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": null,
        "size_bytes": 5114572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 6.94,
    "ram_recommended_gb": 8.68,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.94,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 6.0,
    "tier": "high",
    "model_url": "https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b"
  },
  {
    "model_id": "deepseek-ai/deepseek-math-7b-rl",
    "label": "Deepseek Math 7B Rl",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 5138,
    "likes": 85,
    "last_updated": "2024-03-19T03:54:22+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-math-7b-rl",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07245737211634905,
      "code": 0.11125,
      "math": 0.021737211634904715,
      "story": 0.004245737211634905,
      "roleplay": 0.004245737211634905
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/deepseek-math-7b-rl-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/deepseek-math-7b-rl-GGUF/resolve/main/deepseek-math-7b-rl.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "deepseek-math-7b-rl.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/deepseek-math-7b-rl"
  },
  {
    "model_id": "bartowski/cognitivecomputations_Dolphin3.0-R1-Mistral-24B-GGUF",
    "label": "Cognitivecomputations Dolphin3.0 R1 Mistral 24B",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 5027,
    "likes": 73,
    "last_updated": "2025-02-07T03:24:49+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "cognivecomputations-dolphin3-0-r1-mistral-24b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.235,
      "code": 0.02192452357071214,
      "math": 0.013154714142427283,
      "story": 0.004384904714142428,
      "roleplay": 0.004384904714142428
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.0,
    "ram_recommended_gb": 17.51,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "24B",
    "params_b": 24.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/cognitivecomputations_Dolphin3.0-R1-Mistral-24B-GGUF",
    "variants": [
      {
        "model_id": "DevQuasar/cognitivecomputations.Dolphin3.0-R1-Mistral-24B-GGUF",
        "format": "gguf",
        "quant_method": "gguf",
        "quant_bits": 4,
        "filename": "cognitivecomputations.Dolphin3.0-R1-Mistral-24B.Q4_K_M.gguf",
        "source": "huggingface",
        "revision": "main",
        "download_url": "https://huggingface.co/DevQuasar/cognitivecomputations.Dolphin3.0-R1-Mistral-24B-GGUF/resolve/main/cognitivecomputations.Dolphin3.0-R1-Mistral-24B.Q4_K_M.gguf?download=true"
      }
    ]
  },
  {
    "model_id": "dphn/dolphin-2.2.1-mistral-7b",
    "label": "Dolphin 2.2.1 Mistral 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4973,
    "likes": 199,
    "last_updated": "2024-05-20T14:50:39+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-2-1-mistral-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.02262036108324975,
      "math": 0.013572216649949849,
      "story": 0.00452407221664995,
      "roleplay": 0.00452407221664995
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/dolphin-2.2.1-mistral-7B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150913000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "QuantFactory/dolphin-2.2.1-mistral-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/dolphin-2.2.1-mistral-7b-GGUF/resolve/main/dolphin-2.2.1-mistral-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.2.1-mistral-7b.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/dolphin-2.2.1-mistral-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158694864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.2.1-mistral-7b"
  },
  {
    "model_id": "shenzhi-wang/Llama3.1-8B-Chinese-Chat",
    "label": "Llama3.1 8B Chinese",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 4955,
    "likes": 262,
    "last_updated": "2024-07-29T08:10:54+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 8,
    "canonical_base": "llama3-1-8b-chinese",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.02164242728184554,
      "math": 0.012985456369107322,
      "story": 0.004328485456369108,
      "roleplay": 0.004328485456369108
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/Llama3.1-8B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Llama3.1-8B-Chinese-Chat-GGUF/resolve/main/Llama3.1-8B-Chinese-Chat.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3.1-8B-Chinese-Chat.Q8_0.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Llama3.1-8B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama3.1-8B-Chinese-Chat-GGUF/resolve/main/Llama3.1-8B-Chinese-Chat.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3.1-8B-Chinese-Chat.Q8_0.gguf"
      },
      {
        "model_id": "mav23/Llama3.1-8B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Llama3.1-8B-Chinese-Chat-GGUF/resolve/main/llama3.1-8b-chinese-chat.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama3.1-8b-chinese-chat.Q8_0.gguf"
      },
      {
        "model_id": "second-state/Llama3.1-8B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama3.1-8B-Chinese-Chat-GGUF/resolve/main/Llama3.1-8B-Chinese-Chat-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3.1-8B-Chinese-Chat-Q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/shenzhi-wang/Llama3.1-8B-Chinese-Chat"
  },
  {
    "model_id": "dphn/dolphin-2.1-mistral-7b",
    "label": "Dolphin 2.1 Mistral 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4934,
    "likes": 256,
    "last_updated": "2024-05-20T15:06:12+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-1-mistral-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.021253761283851556,
      "math": 0.012752256770310933,
      "story": 0.004250752256770312,
      "roleplay": 0.004250752256770312
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/dolphin-2.1-mistral-7B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.1-mistral-7B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4158694864,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/dolphin-2.1-mistral-7B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.1-mistral-7B-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4150913000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "ddh0/dolphin-2.1-mistral-7b-GGUF-fp16",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "QuantFactory/dolphin-2.1-mistral-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/dolphin-2.1-mistral-7b-GGUF/resolve/main/dolphin-2.1-mistral-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.1-mistral-7b.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 7.9,
    "ram_recommended_gb": 9.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.1-mistral-7b"
  },
  {
    "model_id": "moonshotai/Kimi-Dev-72B",
    "label": "Kimi Dev 72B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4773,
    "likes": 358,
    "last_updated": "2025-06-17T06:27:40+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "kimi-dev-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07977933801404213,
      "code": 0.12,
      "math": 0.02393380140421264,
      "story": 0.004977933801404213,
      "roleplay": 0.004977933801404213
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Kimi-Dev-72B-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Kimi-Dev-72B-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "btbtyler09/Kimi-Dev-72B-GPTQ-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/btbtyler09/Kimi-Dev-72B-GPTQ-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 43514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "cnfusion/Kimi-Dev-72B-mlx-4Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/cnfusion/Kimi-Dev-72B-mlx-4Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Kimi-Dev-72B-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Kimi-Dev-72B-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 54314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Kimi-Dev-72B-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Kimi-Dev-72B-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ubergarm/Kimi-Dev-72B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ubergarm/Kimi-Dev-72B-GGUF/resolve/main/Kimi-Dev-72B-smol-IQ3_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 34658477504,
        "notes": null,
        "revision": "main",
        "filename": "Kimi-Dev-72B-smol-IQ3_K.gguf"
      },
      {
        "model_id": "theAIDataExec/Kimi-Dev-72B-mlx-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/theAIDataExec/Kimi-Dev-72B-mlx-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 145412517649,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 145412517649
      },
      {
        "model_id": "osxest/Kimi-Dev-72B-mlx-6Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/osxest/Kimi-Dev-72B-mlx-6Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 54314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "btbtyler09/Kimi-Dev-72B-GPTQ-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/btbtyler09/Kimi-Dev-72B-GPTQ-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 87.58,
    "ram_recommended_gb": 109.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 87.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/moonshotai/Kimi-Dev-72B"
  },
  {
    "model_id": "bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF",
    "label": "Qwen2.5 14B Uncensored",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 4740,
    "likes": 52,
    "last_updated": "2024-09-22T23:01:24+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "qwen2-5-14b-uncensored",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.30819681366521734,
      "code": 0.020643680708918984,
      "math": 0.015648335953580204,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Qwen2.5-14B_Uncensored_Instruct-GGUF"
  },
  {
    "model_id": "hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
    "label": "Llama 3.2 3B 0",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "q8_0",
      "small"
    ],
    "dropped_tags": [
      "q8_0"
    ],
    "downloads": 4694,
    "likes": 50,
    "last_updated": "2024-09-25T16:11:19+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "llama-3-2-3b-q8",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.235,
      "code": 0.02562938816449348,
      "math": 0.015377632898696088,
      "story": 0.005125877632898696,
      "roleplay": 0.005125877632898696
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "PonyWen/Llama-3.2-3B-Instruct-Q8_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/PonyWen/Llama-3.2-3B-Instruct-Q8_0-GGUF/resolve/main/llama-3.2-3b-instruct-q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 3314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3.2-3b-instruct-q8_0.gguf"
      }
    ],
    "ram_estimate_gb": 4.78,
    "ram_recommended_gb": 5.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 4.78,
    "quant_bits": 8,
    "format": "gguf",
    "quant_class": "gguf-q8",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF"
  },
  {
    "model_id": "google/codegemma-7b-it",
    "label": "Codegemma 7B It",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4599,
    "likes": 227,
    "last_updated": "2024-08-07T18:27:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegemma-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07443831494483451,
      "code": 0.11125,
      "math": 0.022331494483450353,
      "story": 0.00444383149448345,
      "roleplay": 0.00444383149448345
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "google/codegemma-7b",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/google/codegemma-7b/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/codegemma-7b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codegemma-7b-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/codegemma-7b-it-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-7b-it-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/codegemma-7b-it-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/codegemma-7b-it-bnb-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "lmstudio-community/codegemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/codegemma-7b-it-GGUF/resolve/main/codegemma-7b-it-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-it-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/codegemma-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/codegemma-7b-GGUF/resolve/main/codegemma-7b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/codegemma-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/codegemma-7b-GGUF/resolve/main/codegemma-7b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/codegemma-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/codegemma-7b-GGUF/resolve/main/CodeGemma-7b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeGemma-7b-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/codegemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/codegemma-7b-it-GGUF/resolve/main/codegemma-7b-it.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-it.Q2_K.gguf"
      },
      {
        "model_id": "google/codegemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/google/codegemma-7b-it-GGUF/resolve/main/codegemma-7b-it.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-it.gguf"
      },
      {
        "model_id": "google/codegemma-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/google/codegemma-7b-GGUF/resolve/main/codegemma-7b.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b.gguf"
      },
      {
        "model_id": "second-state/CodeGemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/CodeGemma-7b-it-GGUF/resolve/main/codegemma-7b-it-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 17081756640,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-it-f16.gguf"
      },
      {
        "model_id": "bartowski/codegemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/codegemma-7b-it-GGUF/resolve/main/codegemma-7b-it-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b-it-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/codegemma-7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/codegemma-7b-GGUF/resolve/main/codegemma-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-7b.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-7b-it-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-7b-it-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "LiteLLMs/codegemma-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/codegemma-7b-it-GGUF/resolve/main/Q2_K/Q2_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Q2_K/Q2_K-00001-of-00001.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-7b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-7b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/google/codegemma-7b-it"
  },
  {
    "model_id": "lmsys/longchat-7b-v1.5-32k",
    "label": "Longchat 7B 32K",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1.5"
    ],
    "dropped_tags": [
      "v1.5"
    ],
    "downloads": 4267,
    "likes": 61,
    "last_updated": "2025-04-15T22:22:01+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "long-7b-v1-5-32k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.02313440320962889,
      "math": 0.013880641925777332,
      "story": 0.004626880641925778,
      "roleplay": 0.004626880641925778
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "shaowenchen/longchat-7b-v1.5-32k-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/shaowenchen/longchat-7b-v1.5-32k-gguf/resolve/main/longchat-7b-v1.5-32k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 13478104768,
        "notes": null,
        "revision": "main",
        "filename": "longchat-7b-v1.5-32k.gguf"
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/lmsys/longchat-7b-v1.5-32k"
  },
  {
    "model_id": "codellama/CodeLlama-70b-Instruct-hf",
    "label": "Codellama 70B",
    "tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 4243,
    "likes": 207,
    "last_updated": "2024-04-12T14:18:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.11125,
      "math": 0.02327933801404213,
      "story": 0.0047597793380140425,
      "roleplay": 0.0047597793380140425
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/CodeLlama-70B-Instruct-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-70B-Instruct-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 36614403944,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 36614403944
      },
      {
        "model_id": "TheBloke/CodeLlama-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-70B-Instruct-GGUF/resolve/main/codellama-70b-instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-70b-instruct.Q2_K.gguf"
      },
      {
        "model_id": "codellama/CodeLlama-70b-hf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/codellama/CodeLlama-70b-hf/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 137953905520,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 137953905520
      },
      {
        "model_id": "second-state/CodeLlama-70b-Instruct-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/CodeLlama-70b-Instruct-hf-GGUF/resolve/main/CodeLlama-70b-Instruct-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-70b-Instruct-hf-Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-70B-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-70B-hf-GGUF/resolve/main/codellama-70b-hf.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-70b-hf.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/CodeLlama-70b-Instruct-hf-4bit-MLX",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "mlx-community/CodeLlama-70b-hf-4bit-MLX",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "TheBloke/CodeLlama-70B-Instruct-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-70B-Instruct-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 35332728000,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tensorblock/CodeLlama-70b-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-70b-hf-GGUF/resolve/main/CodeLlama-70b-hf-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-70b-hf-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 43.18,
    "ram_recommended_gb": 53.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 43.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf"
  },
  {
    "model_id": "baichuan-inc/Baichuan-M2-32B",
    "label": "Baichuan M2 32B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4096,
    "likes": 71,
    "last_updated": "2025-08-11T06:46:24+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "baichuan-m2-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.025761033099297892,
      "math": 0.015456619859578734,
      "story": 0.005152206619859579,
      "roleplay": 0.005152206619859579
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "baichuan-inc/Baichuan-M2-32B-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/baichuan-inc/Baichuan-M2-32B-GPTQ-Int4/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 19514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "laukerry/Baichuan-M2-32B-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/laukerry/Baichuan-M2-32B-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 24.22,
    "ram_recommended_gb": 30.28,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 24.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/baichuan-inc/Baichuan-M2-32B"
  },
  {
    "model_id": "Rakuten/RakutenAI-7B-chat",
    "label": "Rakutenai 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 4005,
    "likes": 64,
    "last_updated": "2025-02-10T07:25:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "rakutenai-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.02441950852557673,
      "math": 0.014651705115346038,
      "story": 0.004883901705115347,
      "roleplay": 0.004883901705115347
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Rakuten/RakutenAI-7B-instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Rakuten/RakutenAI-7B-instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14745642040,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14745642040
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Rakuten/RakutenAI-7B-chat"
  },
  {
    "model_id": "Qwen/CodeQwen1.5-7B-Chat",
    "label": "Codeqwen1.5 7B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 3958,
    "likes": 339,
    "last_updated": "2024-04-30T07:18:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codeqwen1-5-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.11125,
      "math": 0.021541624874623872,
      "story": 0.004180541624874624,
      "roleplay": 0.004180541624874624
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Qwen/CodeQwen1.5-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/CodeQwen1.5-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14500613416,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14500613416
      },
      {
        "model_id": "Qwen/CodeQwen1.5-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat-GGUF/resolve/main/codeqwen-1_5-7b-chat-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codeqwen-1_5-7b-chat-q2_k.gguf"
      },
      {
        "model_id": "bartowski/CodeQwen1.5-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/CodeQwen1.5-7B-Chat-GGUF/resolve/main/CodeQwen1.5-7B-Chat-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeQwen1.5-7B-Chat-Q2_K.gguf"
      },
      {
        "model_id": "second-state/CodeQwen1.5-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/CodeQwen1.5-7B-Chat-GGUF/resolve/main/CodeQwen1.5-7B-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14503511808,
        "notes": null,
        "revision": "main",
        "filename": "CodeQwen1.5-7B-Chat-f16.gguf"
      },
      {
        "model_id": "bartowski/CodeQwen1.5-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/CodeQwen1.5-7B-GGUF/resolve/main/CodeQwen1.5-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeQwen1.5-7B-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/CodeQwen1.5-7B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5268738344,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5268738344
      },
      {
        "model_id": "QuantFactory/CodeQwen1.5-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/CodeQwen1.5-7B-Chat-GGUF/resolve/main/CodeQwen1.5-7B-Chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeQwen1.5-7B-Chat.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/CodeQwen1.5-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeQwen1.5-7B-GGUF/resolve/main/CodeQwen1.5-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeQwen1.5-7B-Q2_K.gguf"
      },
      {
        "model_id": "mav23/CodeQwen1.5-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/CodeQwen1.5-7B-Chat-GGUF/resolve/main/codeqwen1.5-7b-chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "codeqwen1.5-7b-chat.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat"
  },
  {
    "model_id": "casperhansen/llama-3-70b-instruct-awq",
    "label": "Llama 3 70B",
    "tags": [
      "awq",
      "chat",
      "cuda",
      "large"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "cuda",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 3860,
    "likes": 69,
    "last_updated": "2024-04-19T21:19:18+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "canonical_base": "llama-3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22625,
      "code": 0.022068706118355066,
      "math": 0.013241223671013038,
      "story": 0.004413741223671014,
      "roleplay": 0.004413741223671014
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/llama-3-70b-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-3-70b-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "unsloth/llama-3-70b-Instruct-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/llama-3-70b-Instruct-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "casperhansen/llama-3-70b-fp16",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "MaziyarPanahi/Llama-3-70B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Llama-3-70B-Instruct-v0.1-GGUF/resolve/main/Llama-3-70B-Instruct-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-70B-Instruct-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-70B-GGUF/resolve/main/Llama-3-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-70B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "format": "awq",
    "quant_class": "awq",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/casperhansen/llama-3-70b-instruct-awq"
  },
  {
    "model_id": "bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF",
    "label": "Qwen2.5.1 Coder 7B",
    "tags": [
      "chat",
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 3468,
    "likes": 94,
    "last_updated": "2024-11-06T18:47:37+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "qwen2-5-1-coder-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.235,
      "code": 0.1175,
      "math": 0.021541624874623872,
      "story": 0.004180541624874624,
      "roleplay": 0.004180541624874624
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mlx-community/Qwen2.5.1-Coder-7B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2.5.1-Coder-7B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF"
  },
  {
    "model_id": "microsoft/wavecoder-ultra-6.7b",
    "label": "Wavecoder Ultra 6.7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 3460,
    "likes": 79,
    "last_updated": "2024-05-06T13:25:54+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "wavecoder-ultra-6-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07328485456369108,
      "code": 0.11125,
      "math": 0.02198545636910732,
      "story": 0.004328485456369108,
      "roleplay": 0.004328485456369108
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/wavecoder-ultra-6.7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/wavecoder-ultra-6.7b-GGUF/resolve/main/wavecoder-ultra-6.7b-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "wavecoder-ultra-6.7b-Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/wavecoder-ultra-6.7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/wavecoder-ultra-6.7b-GGUF/resolve/main/wavecoder-ultra-6.7b-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "wavecoder-ultra-6.7b-Q6_K.gguf"
      },
      {
        "model_id": "lmstudio-community/wavecoder-ultra-6.7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/wavecoder-ultra-6.7b-GGUF/resolve/main/wavecoder-ultra-6.7b-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "wavecoder-ultra-6.7b-Q6_K.gguf"
      },
      {
        "model_id": "QuantFactory/wavecoder-ultra-6.7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/wavecoder-ultra-6.7b-GGUF/resolve/main/wavecoder-ultra-6.7b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "wavecoder-ultra-6.7b.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 7.61,
    "ram_recommended_gb": 9.52,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.61,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 6.7,
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/wavecoder-ultra-6.7b"
  },
  {
    "model_id": "bartowski/Qwen_QwQ-32B-GGUF",
    "label": "Qwen Qwq 32B",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 3431,
    "likes": 164,
    "last_updated": "2025-03-05T18:46:44+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "qwen-qwq-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.245,
      "code": 0.02371740220661986,
      "math": 0.014230441323971915,
      "story": 0.004743480441323972,
      "roleplay": 0.004743480441323972
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "featherless-ai-quants/Qwen-QwQ-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/featherless-ai-quants/Qwen-QwQ-32B-GGUF/resolve/main/Qwen-QwQ-32B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 9914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen-QwQ-32B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 12.7,
    "ram_recommended_gb": 15.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 12.7,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/Qwen_QwQ-32B-GGUF"
  },
  {
    "model_id": "codellama/CodeLlama-34b-Python-hf",
    "label": "Codellama 34B Python",
    "tags": [
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 2050,
    "likes": 98,
    "last_updated": "2024-04-12T14:15:25+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codellama-34b-python",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07646940822467403,
      "code": 0.11125,
      "math": 0.02294082246740221,
      "story": 0.004646940822467402,
      "roleplay": 0.004646940822467402
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/CodeLlama-34B-Python-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 67487990976,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 67487990976
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Python-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "codellama-34b-python.Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/CodeLlama-34b-Python-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/CodeLlama-34b-Python-hf-GGUF/resolve/main/CodeLlama-34b-Python-hf-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-34b-Python-hf-Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/CodeLlama-34b-Python-hf-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/CodeLlama-34b-Python-hf-GGUF/resolve/main/CodeLlama-34b-Python-hf.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "CodeLlama-34b-Python-hf.Q4_K_M.gguf"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Python-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/CodeLlama-34B-Python-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 25.66,
    "ram_recommended_gb": 32.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 25.66,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codellama/CodeLlama-34b-Python-hf"
  },
  {
    "model_id": "dphn/dolphin-2.5-mixtral-8x7b",
    "label": "Dolphin 2.5 Mixtral 8X7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2830,
    "likes": 1235,
    "last_updated": "2024-05-21T16:20:06+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-5-mixtral-8x7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2235714285714286,
      "code": 0.025924022066198597,
      "math": 0.015554413239719157,
      "story": 0.00518480441323972,
      "roleplay": 0.00518480441323972
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/dolphin-2.5-mixtral-8x7b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/dolphin-2.5-mixtral-8x7b-GGUF/resolve/main/dolphin-2.5-mixtral-8x7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.5-mixtral-8x7b.Q2_K.gguf"
      },
      {
        "model_id": "TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 23811582112,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "Eric1227/dolphin-2.5-mixtral-8x7b-MLX-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Eric1227/dolphin-2.5-mixtral-8x7b-MLX-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "Eric1227/dolphin-2.5-mixtral-8x7b-MLX-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Eric1227/dolphin-2.5-mixtral-8x7b-MLX-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 7.48,
    "ram_recommended_gb": 9.35,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.48,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.5-mixtral-8x7b"
  },
  {
    "model_id": "apple/OpenELM-270M-Instruct",
    "label": "Openelm 270M",
    "tags": [
      "chat",
      "hf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 2445,
    "likes": 138,
    "last_updated": "2025-02-28T18:31:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "openelm-270m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.023654714142427282,
      "math": 0.014192828485456369,
      "story": 0.004730942828485457,
      "roleplay": 0.004730942828485457
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "apple/OpenELM-270M",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/apple/OpenELM-270M/resolve/main/model.safetensors?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 1086123184,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 1.34,
    "ram_recommended_gb": 1.68,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 1.34,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 0.27,
    "tier": "high",
    "model_url": "https://huggingface.co/apple/OpenELM-270M-Instruct"
  },
  {
    "model_id": "deepseek-ai/deepseek-coder-33b-base",
    "label": "Deepseek Coder 33B Base",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2389,
    "likes": 71,
    "last_updated": "2024-03-07T13:24:08+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-coder-33b-base",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.08092026078234704,
      "code": 0.11125,
      "math": 0.024276078234704113,
      "story": 0.005092026078234705,
      "roleplay": 0.005092026078234705
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/deepseek-coder-33B-base-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-33B-base-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 17399444712,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/deepseek-coder-33B-base-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/deepseek-coder-33B-base-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 18008816752,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 18008816752
      }
    ],
    "ram_estimate_gb": 66.8,
    "ram_recommended_gb": 83.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 66.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/deepseek-ai/deepseek-coder-33b-base"
  },
  {
    "model_id": "SciPhi/Triplex",
    "label": "Triplex",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 2274,
    "likes": 297,
    "last_updated": "2024-08-09T00:08:10+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "triplex",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.02284603811434303,
      "math": 0.013707622868605818,
      "story": 0.004569207622868606,
      "roleplay": 0.004569207622868606
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Triplex-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Triplex-GGUF/resolve/main/Triplex-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15285056736,
        "notes": null,
        "revision": "main",
        "filename": "Triplex-f32.gguf"
      },
      {
        "model_id": "QuantFactory/Triplex-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Triplex-GGUF/resolve/main/Triplex.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 1416203968,
        "notes": null,
        "revision": "main",
        "filename": "Triplex.Q2_K.gguf"
      },
      {
        "model_id": "second-state/Triplex-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Triplex-GGUF/resolve/main/Triplex-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 7643296992,
        "notes": null,
        "revision": "main",
        "filename": "Triplex-f16.gguf"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/SciPhi/Triplex"
  },
  {
    "model_id": "trillionlabs/Trillion-7B-preview",
    "label": "Trillion 7B Preview",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2215,
    "likes": 86,
    "last_updated": "2025-04-25T02:19:16+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "trillion-7b-preview",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.022582748244734205,
      "math": 0.013549648946840522,
      "story": 0.0045165496489468415,
      "roleplay": 0.0045165496489468415
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "trillionlabs/Trillion-7B-preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/trillionlabs/Trillion-7B-preview-GGUF/resolve/main/trillion-7b-preview.bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15057589568,
        "notes": null,
        "revision": "main",
        "filename": "trillion-7b-preview.bf16.gguf"
      },
      {
        "model_id": "trillionlabs/Trillion-7B-preview-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/trillionlabs/Trillion-7B-preview-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5464352768,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5464352768
      },
      {
        "model_id": "juyoung-trl/Trillion-7B-preview-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/juyoung-trl/Trillion-7B-preview-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 5464352768,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 5464352768
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/trillionlabs/Trillion-7B-preview"
  },
  {
    "model_id": "openGPT-X/Teuken-7B-instruct-research-v0.4",
    "label": "Teuken 7B Research",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.4"
    ],
    "dropped_tags": [
      "v0.4"
    ],
    "downloads": 2214,
    "likes": 88,
    "last_updated": "2025-01-07T11:59:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "teuken-7b-research",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.026093279839518556,
      "math": 0.015655967903711134,
      "story": 0.005218655967903711,
      "roleplay": 0.005218655967903711
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Teuken-7B-instruct-research-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Teuken-7B-instruct-research-v0.4-GGUF/resolve/main/Teuken-7B-instruct-research-v0.4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Teuken-7B-instruct-research-v0.4-Q4_K_M.gguf"
      },
      {
        "model_id": "QuantFactory/Teuken-7B-instruct-research-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Teuken-7B-instruct-research-v0.4-GGUF/resolve/main/Teuken-7B-instruct-research-v0.4.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Teuken-7B-instruct-research-v0.4.Q4_K_M.gguf"
      },
      {
        "model_id": "tensorblock/Teuken-7B-instruct-research-v0.4-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Teuken-7B-instruct-research-v0.4-GGUF/resolve/main/Teuken-7B-instruct-research-v0.4-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "Teuken-7B-instruct-research-v0.4-Q4_K_M.gguf"
      },
      {
        "model_id": "mlx-community/Teuken-7B-instruct-research-v0.4-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Teuken-7B-instruct-research-v0.4-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/openGPT-X/Teuken-7B-instruct-research-v0.4"
  },
  {
    "model_id": "georgesung/llama2_7b_chat_uncensored",
    "label": "Llama2 7B Uncensored",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2200,
    "likes": 392,
    "last_updated": "2024-05-13T15:01:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama2-7b-uncensored",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.022426028084252758,
      "math": 0.013455616850551655,
      "story": 0.0044852056168505515,
      "roleplay": 0.0044852056168505515
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/llama2_7b_chat_uncensored-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/llama2_7b_chat_uncensored-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3896726136,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/llama2_7b_chat_uncensored-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/llama2_7b_chat_uncensored-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 3889391512,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "digitalpipelines/llama2_7b_chat_uncensored",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 0.0,
    "ram_recommended_gb": 0.0,
    "ram_estimate_method": "unknown",
    "ram_estimate_confidence": "low",
    "estimated_ram_requirement": 0.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "unknown",
    "tier": "high",
    "model_url": "https://huggingface.co/georgesung/llama2_7b_chat_uncensored"
  },
  {
    "model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo",
    "label": "Japanese Gpt Neox 3.6B Instruction Ppo",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2140,
    "likes": 73,
    "last_updated": "2025-03-23T10:55:08+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "japanese-gpt-neox-3-6bion-ppo",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.31519500168739845,
      "code": 0.014311171530833024,
      "math": 0.0077808030570349785,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 8.0,
    "ram_recommended_gb": 10.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.6,
    "tier": "high",
    "model_url": "https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo"
  },
  {
    "model_id": "apple/OpenELM-3B-Instruct",
    "label": "Openelm 3B",
    "tags": [
      "chat",
      "hf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2138,
    "likes": 338,
    "last_updated": "2025-02-28T18:31:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "openelm-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.02410606820461384,
      "math": 0.014463640922768304,
      "story": 0.004821213640922768,
      "roleplay": 0.004821213640922768
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "apple/OpenELM-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/apple/OpenELM-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 12146622856,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 12146622856
      },
      {
        "model_id": "ZeroWw/OpenELM-3B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ZeroWw/OpenELM-3B-Instruct-GGUF/resolve/main/OpenELM-3B-Instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 6074505856,
        "notes": null,
        "revision": "main",
        "filename": "OpenELM-3B-Instruct.f16.gguf"
      },
      {
        "model_id": "mlx-community/OpenELM-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/OpenELM-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 6073328007,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6073328007
      }
    ],
    "ram_estimate_gb": 6.8,
    "ram_recommended_gb": 8.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 6.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/apple/OpenELM-3B-Instruct"
  },
  {
    "model_id": "yentinglin/Llama-3-Taiwan-70B-Instruct",
    "label": "Llama 3 Taiwan 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 2135,
    "likes": 78,
    "last_updated": "2025-04-20T02:17:42+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-taiwan-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.021303911735205617,
      "math": 0.01278234704112337,
      "story": 0.0042607823470411236,
      "roleplay": 0.0042607823470411236
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "chienweichang/Llama-3-Taiwan-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/chienweichang/Llama-3-Taiwan-70B-Instruct-GGUF/resolve/main/llama-3-taiwan-70b-instruct-q2_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "llama-3-taiwan-70b-instruct-q2_k.gguf"
      },
      {
        "model_id": "second-state/Llama-3-Taiwan-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Llama-3-Taiwan-70B-Instruct-GGUF/resolve/main/Llama-3-Taiwan-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Taiwan-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama-3-Taiwan-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama-3-Taiwan-70B-Instruct-GGUF/resolve/main/Llama-3-Taiwan-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Taiwan-70B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Llama-3-Taiwan-70B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Llama-3-Taiwan-70B-Instruct-GGUF/resolve/main/Llama-3-Taiwan-70B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-Taiwan-70B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/yentinglin/Llama-3-Taiwan-70B-Instruct"
  },
  {
    "model_id": "shenzhi-wang/Gemma-2-9B-Chinese-Chat",
    "label": "Gemma 2 9B Chinese",
    "tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 2116,
    "likes": 79,
    "last_updated": "2024-07-04T10:00:18+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "gemma-2-9b-chinese",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2275,
      "code": 0.024877131394182548,
      "math": 0.014926278836509528,
      "story": 0.00497542627883651,
      "roleplay": 0.00497542627883651
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/Gemma-2-9B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Gemma-2-9B-Chinese-Chat-GGUF/resolve/main/Gemma-2-9B-Chinese-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 18490680640,
        "notes": null,
        "revision": "main",
        "filename": "Gemma-2-9B-Chinese-Chat-f16.gguf"
      },
      {
        "model_id": "gaianet/Gemma-2-9B-Chinese-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Gemma-2-9B-Chinese-Chat-GGUF/resolve/main/Gemma-2-9B-Chinese-Chat-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 18490680640,
        "notes": null,
        "revision": "main",
        "filename": "Gemma-2-9B-Chinese-Chat-f16.gguf"
      }
    ],
    "ram_estimate_gb": 18.8,
    "ram_recommended_gb": 23.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 18.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "9B",
    "params_b": 9.0,
    "tier": "high",
    "model_url": "https://huggingface.co/shenzhi-wang/Gemma-2-9B-Chinese-Chat"
  },
  {
    "model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft",
    "label": "Japanese Gpt Neox 3.6B Instruction Sft",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2104,
    "likes": 105,
    "last_updated": "2025-03-23T10:53:58+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "japanese-gpt-neox-3-6bion-sft",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.02320962888665998,
      "math": 0.013925777331995988,
      "story": 0.004641925777331996,
      "roleplay": 0.004641925777331996
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 8.0,
    "ram_recommended_gb": 10.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.0,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.6,
    "tier": "high",
    "model_url": "https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft"
  },
  {
    "model_id": "SeaLLMs/SeaLLMs-v3-7B-Chat",
    "label": "Seallms 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 2088,
    "likes": 57,
    "last_updated": "2024-09-02T03:02:23+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "seallms-v3-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.023755015045135407,
      "math": 0.014253009027081244,
      "story": 0.004751003009027081,
      "roleplay": 0.004751003009027081
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "SeaLLMs/SeaLLMs-v3-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/SeaLLMs/SeaLLMs-v3-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 30462504632,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 30462504632
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/SeaLLMs/SeaLLMs-v3-7B-Chat"
  },
  {
    "model_id": "DavidAU/L3-DARKEST-PLANET-16.5B-GGUF",
    "label": "L3 Darkest Planet 16.5B",
    "tags": [
      "gguf",
      "mps",
      "roleplay",
      "story"
    ],
    "raw_tags": [
      "gguf",
      "mps",
      "roleplay",
      "story"
    ],
    "dropped_tags": [],
    "downloads": 2086,
    "likes": 66,
    "last_updated": "2025-07-28T00:14:20+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 6,
    "canonical_base": "l3-darkest-planet-16-5b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07210631895687061,
      "code": 0.021053159478435307,
      "math": 0.012631895687061185,
      "story": 0.0245,
      "roleplay": 0.0245
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "DavidAU/L3-DARKEST-PLANET-16.5B",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 14.66,
    "ram_recommended_gb": 18.33,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.66,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "16.5B",
    "params_b": 16.5,
    "tier": "high",
    "model_url": "https://huggingface.co/DavidAU/L3-DARKEST-PLANET-16.5B-GGUF"
  },
  {
    "model_id": "Viet-Mistral/Vistral-7B-Chat",
    "label": "Vistral 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2079,
    "likes": 140,
    "last_updated": "2024-02-27T19:49:13+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "vistral-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.02104062186559679,
      "math": 0.012624373119358075,
      "story": 0.004208124373119358,
      "roleplay": 0.004208124373119358
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "uonlp/Vistral-7B-Chat-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/uonlp/Vistral-7B-Chat-gguf/resolve/main/ggml-vistral-7B-chat-q8.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-vistral-7B-chat-q8.gguf"
      },
      {
        "model_id": "KhanhVan/Vistral-7B-Chat-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/KhanhVan/Vistral-7B-Chat-gguf/resolve/main/ggml-vistral-7B-chat-q8.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "ggml-vistral-7B-chat-q8.gguf"
      },
      {
        "model_id": "Viet-Mistral/Vistral-7B-Chat-mlx-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Viet-Mistral/Vistral-7B-Chat-mlx-4bit/resolve/main/model.safetensors?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "LuongNam/Vistral-7B-Chat-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LuongNam/Vistral-7B-Chat-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4255229928,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 5.38,
    "ram_recommended_gb": 6.73,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 5.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Viet-Mistral/Vistral-7B-Chat"
  },
  {
    "model_id": "ise-uiuc/Magicoder-S-DS-6.7B",
    "label": "Magicoder S Ds 6.7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 2063,
    "likes": 204,
    "last_updated": "2024-03-06T07:40:23+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "magicoder-s-ds-6-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07972918756268807,
      "code": 0.11125,
      "math": 0.02391875626880642,
      "story": 0.004972918756268807,
      "roleplay": 0.004972918756268807
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/Magicoder-S-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Magicoder-S-DS-6.7B-GGUF/resolve/main/magicoder-s-ds-6.7b.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "magicoder-s-ds-6.7b.Q6_K.gguf"
      },
      {
        "model_id": "milkowski/Magicoder-S-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/milkowski/Magicoder-S-DS-6.7B-GGUF/resolve/main/magicoder-s-ds-6.7b.q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "magicoder-s-ds-6.7b.q6_k.gguf"
      },
      {
        "model_id": "tensorblock/Magicoder-S-DS-6.7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Magicoder-S-DS-6.7B-GGUF/resolve/main/Magicoder-S-DS-6.7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5674572800,
        "notes": null,
        "revision": "main",
        "filename": "Magicoder-S-DS-6.7B-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/Magicoder-S-DS-6.7B-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Magicoder-S-DS-6.7B-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 13481059035,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 13481059035
      }
    ],
    "ram_estimate_gb": 7.61,
    "ram_recommended_gb": 9.52,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.61,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 6.7,
    "tier": "high",
    "model_url": "https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B"
  },
  {
    "model_id": "tencent/Hunyuan-7B-Instruct",
    "label": "Hunyuan 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1952,
    "likes": 72,
    "last_updated": "2025-08-06T07:02:38+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hunyuan-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.24,
      "code": 0.026231193580742225,
      "math": 0.015738716148445336,
      "story": 0.0052462387161484455,
      "roleplay": 0.0052462387161484455
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tencent/Hunyuan-7B-Instruct-0124",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main"
      },
      {
        "model_id": "tencent/Hunyuan-7B-Instruct-GPTQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tencent/Hunyuan-7B-Instruct-GPTQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "tencent/Hunyuan-7B-Instruct-AWQ-Int4",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tencent/Hunyuan-7B-Instruct-AWQ-Int4/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-2508-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-2508-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ZeroWw/Hunyuan-7B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ZeroWw/Hunyuan-7B-Instruct-GGUF/resolve/main/Hunyuan-7B-Instruct.f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15014548224,
        "notes": null,
        "revision": "main",
        "filename": "Hunyuan-7B-Instruct.f16.gguf"
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-2508-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-2508-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-fp16",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-fp16/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 15016198141,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 15016198141
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Hunyuan-7B-Instruct-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Hunyuan-7B-Instruct-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 6.22,
    "ram_recommended_gb": 7.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 6.22,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/tencent/Hunyuan-7B-Instruct"
  },
  {
    "model_id": "QuixiAI/WizardLM-33B-V1.0-Uncensored",
    "label": "Wizardlm 33B Uncensored",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1.0"
    ],
    "dropped_tags": [
      "v1.0"
    ],
    "downloads": 1989,
    "likes": 60,
    "last_updated": "2024-03-04T16:02:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "wizardlm-33b-v1-0-uncensored",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.02616223671013039,
      "math": 0.015697342026078233,
      "story": 0.005232447342026079,
      "roleplay": 0.005232447342026079
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16940128464,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 66.8,
    "ram_recommended_gb": 83.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 66.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/QuixiAI/WizardLM-33B-V1.0-Uncensored"
  },
  {
    "model_id": "Equall/Saul-7B-Instruct-v1",
    "label": "Saul 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1"
    ],
    "dropped_tags": [
      "v1"
    ],
    "downloads": 1966,
    "likes": 98,
    "last_updated": "2024-03-10T12:39:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "saul-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2899727083067867,
      "code": 0.012993559344534448,
      "math": 0.005859460456082992,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Equall/Saul-7B-Instruct-v1"
  },
  {
    "model_id": "speakleash/Bielik-7B-Instruct-v0.1",
    "label": "Bielik 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.1"
    ],
    "dropped_tags": [
      "v0.1"
    ],
    "downloads": 1925,
    "likes": 58,
    "last_updated": "2024-10-26T12:13:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "bielik-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.022946339017051155,
      "math": 0.013767803410230693,
      "story": 0.004589267803410231,
      "roleplay": 0.004589267803410231
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "speakleash/Bielik-7B-Instruct-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-7B-Instruct-v0.1-GGUF/resolve/main/bielik-7b-instruct-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "bielik-7b-instruct-v0.1.Q2_K.gguf"
      },
      {
        "model_id": "speakleash/Bielik-7B-v0.1",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-7B-v0.1/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14483498016,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14483498016
      },
      {
        "model_id": "speakleash/Bielik-7B-Instruct-v0.1-MLX",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/speakleash/Bielik-7B-Instruct-v0.1-MLX/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4262356972,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4262356972
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/speakleash/Bielik-7B-Instruct-v0.1"
  },
  {
    "model_id": "Alibaba-NLP/gte-Qwen1.5-7B-instruct",
    "label": "Gte Qwen1.5 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1906,
    "likes": 107,
    "last_updated": "2025-01-11T07:10:24+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "gte-qwen1-5-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2718095611979544,
      "code": 0.019583874691357233,
      "math": 0.013859842633500622,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Alibaba-NLP/gte-Qwen1.5-7B-instruct"
  },
  {
    "model_id": "dphn/dolphin-2.9.3-mistral-7B-32k",
    "label": "Dolphin 2.9.3 Mistral 7B 32K",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1902,
    "likes": 53,
    "last_updated": "2024-10-30T20:27:39+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-3-mistral-7b-32k",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.02606193580742227,
      "math": 0.01563716148445336,
      "story": 0.005212387161484454,
      "roleplay": 0.005212387161484454
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/dolphin-2.9.3-mistral-7B-32k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/dolphin-2.9.3-mistral-7B-32k-GGUF/resolve/main/dolphin-2.9.3-mistral-7B-32k-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 28992917408,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9.3-mistral-7B-32k-f32.gguf"
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-7B-32k"
  },
  {
    "model_id": "nvidia/Nemotron-Mini-4B-Instruct",
    "label": "Nemotron Mini 4B",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 1824,
    "likes": 167,
    "last_updated": "2025-02-14T19:03:33+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "nemotron-mini-4b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22999999999999998,
      "code": 0.02337888665997994,
      "math": 0.014027331995987964,
      "story": 0.004675777331995988,
      "roleplay": 0.004675777331995988
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/Nemotron-Mini-4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/Nemotron-Mini-4B-Instruct-GGUF/resolve/main/Nemotron-Mini-4B-Instruct-q4_k_m.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "Nemotron-Mini-4B-Instruct-q4_k_m.gguf"
      },
      {
        "model_id": "bartowski/Nemotron-Mini-4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Nemotron-Mini-4B-Instruct-GGUF/resolve/main/Nemotron-Mini-4B-Instruct-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "Nemotron-Mini-4B-Instruct-Q4_K_M.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Nemotron-Mini-4B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Nemotron-Mini-4B-Instruct-GGUF/resolve/main/Nemotron-Mini-4B-Instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 2514572800,
        "notes": null,
        "revision": "main",
        "filename": "Nemotron-Mini-4B-Instruct.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 3.82,
    "ram_recommended_gb": 4.78,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.82,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 4.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct"
  },
  {
    "model_id": "AI4Chem/ChemLLM-7B-Chat",
    "label": "Chemllm 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1762,
    "likes": 78,
    "last_updated": "2024-09-17T16:00:49+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "chemllm-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.3016602061717499,
      "code": 0.011759662361558353,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/AI4Chem/ChemLLM-7B-Chat"
  },
  {
    "model_id": "SUSTech/SUS-Chat-34B",
    "label": "Sus 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 1754,
    "likes": 122,
    "last_updated": "2024-07-09T13:40:45+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "sus-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.02421890672016048,
      "math": 0.014531344032096289,
      "story": 0.004843781344032096,
      "roleplay": 0.004843781344032096
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "TheBloke/SUS-Chat-34B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/SUS-Chat-34B-GGUF/resolve/main/sus-chat-34b.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "sus-chat-34b.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 23.62,
    "ram_recommended_gb": 29.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 23.62,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/SUSTech/SUS-Chat-34B"
  },
  {
    "model_id": "macadeliccc/laser-dolphin-mixtral-2x7b-dpo",
    "label": "Laser Dolphin Mixtral 2X7B Dpo",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1742,
    "likes": 58,
    "last_updated": "2024-03-04T19:20:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "laser-dolphin-mixtral-2x7b-dpo",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2225,
      "code": 0.022626629889669007,
      "math": 0.013575977933801404,
      "story": 0.004525325977933802,
      "roleplay": 0.004525325977933802
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/laser-dolphin-mixtral-2x7b-dpo-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/laser-dolphin-mixtral-2x7b-dpo-AWQ/resolve/main/model.safetensors?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7080139488,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      },
      {
        "model_id": "TheBloke/laser-dolphin-mixtral-2x7b-dpo-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/laser-dolphin-mixtral-2x7b-dpo-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7092929288,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/macadeliccc/laser-dolphin-mixtral-2x7b-dpo"
  },
  {
    "model_id": "nvidia/Mistral-NeMo-Minitron-8B-Instruct",
    "label": "Mistral Nemo Minitron 8B",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 1656,
    "likes": 80,
    "last_updated": "2024-10-09T22:44:46+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "mistral-nemo-minron-8b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2296458837772397,
      "code": 0.020576730190571716,
      "math": 0.01234603811434303,
      "story": 0.004115346038114343,
      "roleplay": 0.004115346038114343
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Mistral-NeMo-Minitron-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Mistral-NeMo-Minitron-8B-Instruct-GGUF/resolve/main/Mistral-NeMo-Minitron-8B-Instruct-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-NeMo-Minitron-8B-Instruct-Q8_0.gguf"
      },
      {
        "model_id": "QuantFactory/Mistral-NeMo-Minitron-8B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Mistral-NeMo-Minitron-8B-Chat-GGUF/resolve/main/Mistral-NeMo-Minitron-8B-Chat.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-NeMo-Minitron-8B-Chat.Q8_0.gguf"
      },
      {
        "model_id": "tensorblock/Mistral-NeMo-Minitron-8B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Mistral-NeMo-Minitron-8B-Chat-GGUF/resolve/main/Mistral-NeMo-Minitron-8B-Chat-Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-NeMo-Minitron-8B-Chat-Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Mistral-NeMo-Minitron-8B-Instruct",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mistral-NeMo-Minitron-8B-Instruct/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 16828253019,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 16828253019
      },
      {
        "model_id": "MaziyarPanahi/Mistral-NeMo-Minitron-8B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-NeMo-Minitron-8B-Instruct-GGUF/resolve/main/Mistral-NeMo-Minitron-8B-Instruct.Q8_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 8,
        "format": "gguf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "Mistral-NeMo-Minitron-8B-Instruct.Q8_0.gguf"
      },
      {
        "model_id": "mlx-community/Mistral-NeMo-Minitron-8B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Mistral-NeMo-Minitron-8B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 8314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 10.78,
    "ram_recommended_gb": 13.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.78,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 8.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Instruct"
  },
  {
    "model_id": "cyberagent/calm3-22b-chat",
    "label": "Calm3 22B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1651,
    "likes": 79,
    "last_updated": "2024-07-01T10:11:08+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "calm3-22b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.2901686925147969,
      "code": 0.011749209644349242,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 44.8,
    "ram_recommended_gb": 56.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 44.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "22B",
    "params_b": 22.0,
    "tier": "high",
    "model_url": "https://huggingface.co/cyberagent/calm3-22b-chat"
  },
  {
    "model_id": "dphn/dolphin-2.9.3-mistral-nemo-12b",
    "label": "Dolphin 2.9.3 Mistral Nemo 12B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1626,
    "likes": 101,
    "last_updated": "2024-07-26T04:16:15+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-3-mistral-nemo-12b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.289693076230563,
      "code": 0.021112976161768163,
      "math": 0.01402456917628181,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 24.8,
    "ram_recommended_gb": 31.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 24.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 12.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9.3-mistral-nemo-12b"
  },
  {
    "model_id": "NousResearch/Hermes-3-Llama-3.1-70B",
    "label": "Hermes 3 Llama 3.1 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 1435,
    "likes": 117,
    "last_updated": "2024-09-08T07:51:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hermes-3-llama-3-1-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22663589588377725,
      "code": 0.020131644934804415,
      "math": 0.01207898696088265,
      "story": 0.004026328986960883,
      "roleplay": 0.004026328986960883
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "unsloth/Hermes-3-Llama-3.1-70B-bnb-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/unsloth/Hermes-3-Llama-3.1-70B-bnb-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "bnb",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 42314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "bartowski/Hermes-3-Llama-3.1-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Hermes-3-Llama-3.1-70B-GGUF/resolve/main/Hermes-3-Llama-3.1-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Hermes-3-Llama-3.1-70B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 51.58,
    "ram_recommended_gb": 64.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 51.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-70B"
  },
  {
    "model_id": "bartowski/agentica-org_DeepCoder-14B-Preview-GGUF",
    "label": "Agentica Org Deepcoder 14B Preview",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 1417,
    "likes": 62,
    "last_updated": "2025-04-08T22:29:04+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "agentica-org-deepcoder-14b-preview",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07699598796389168,
      "code": 0.12069536924939468,
      "math": 0.0230987963891675,
      "story": 0.004699598796389168,
      "roleplay": 0.004699598796389168
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "tensorblock/agentica-org_DeepCoder-14B-Preview-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/agentica-org_DeepCoder-14B-Preview-GGUF/resolve/main/DeepCoder-14B-Preview-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 8014572800,
        "notes": null,
        "revision": "main",
        "filename": "DeepCoder-14B-Preview-Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 10.42,
    "ram_recommended_gb": 13.03,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 10.42,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/bartowski/agentica-org_DeepCoder-14B-Preview-GGUF"
  },
  {
    "model_id": "dphn/dolphin-2.9.2-qwen2-72b",
    "label": "Dolphin 2.9.2 Qwen2 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1353,
    "likes": 165,
    "last_updated": "2024-10-08T16:30:09+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-2-qwen2-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22551906779661016,
      "code": 0.024776830491474423,
      "math": 0.014866098294884653,
      "story": 0.004955366098294885,
      "roleplay": 0.004955366098294885
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/dolphin-2.9.2-qwen2-72b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/dolphin-2.9.2-qwen2-72b-GGUF/resolve/main/dolphin-2.9.2-qwen2-72b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9.2-qwen2-72b-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 27.1,
    "ram_recommended_gb": 33.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 27.1,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9.2-qwen2-72b"
  },
  {
    "model_id": "google/txgemma-27b-chat",
    "label": "Txgemma 27B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1322,
    "likes": 54,
    "last_updated": "2025-04-10T22:48:08+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "txgemma-27b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.23509685230024213,
      "code": 0.025027582748244737,
      "math": 0.015016549648946841,
      "story": 0.005005516549648948,
      "roleplay": 0.005005516549648948
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/txgemma-27b-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/txgemma-27b-chat-GGUF/resolve/main/txgemma-27b-chat-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "txgemma-27b-chat-Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 27.1,
    "ram_recommended_gb": 33.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 27.1,
    "quant_class": null,
    "format": "hf",
    "size_hint": "27B",
    "params_b": 27.0,
    "tier": "high",
    "model_url": "https://huggingface.co/google/txgemma-27b-chat"
  },
  {
    "model_id": "mkurman/Qwen2.5-14B-DeepSeek-R1-1M",
    "label": "Qwen2.5 14B Deepseek R1 1M",
    "tags": [
      "code",
      "gguf",
      "mps"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps"
    ],
    "dropped_tags": [],
    "downloads": 1308,
    "likes": 52,
    "last_updated": "2025-01-27T13:54:37+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "quant_bits": 4,
    "canonical_base": "qwen2-5-14b-deepseek-r1-1m",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.08531312370286678,
      "code": 0.24230158124168352,
      "math": 0.07411664904472537,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 8.5,
    "ram_recommended_gb": 10.63,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 8.5,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "14B",
    "params_b": 14.0,
    "tier": "high",
    "model_url": "https://huggingface.co/mkurman/Qwen2.5-14B-DeepSeek-R1-1M"
  },
  {
    "model_id": "shenzhi-wang/Gemma-2-27B-Chinese-Chat",
    "label": "Gemma 2 27B Chinese",
    "tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "chat",
      "gguf",
      "mps",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1307,
    "likes": 63,
    "last_updated": "2024-07-04T10:01:20+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "gemma-2-27b-chinese",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.29043016092091045,
      "code": 0.017881054889293452,
      "math": 0.010523507244034154,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 54.8,
    "ram_recommended_gb": 68.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 54.8,
    "format": "gguf",
    "quant_class": "gguf",
    "size_hint": "27B",
    "params_b": 27.0,
    "tier": "high",
    "model_url": "https://huggingface.co/shenzhi-wang/Gemma-2-27B-Chinese-Chat"
  },
  {
    "model_id": "open-r1/OlympicCoder-7B",
    "label": "Olympiccoder 7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1289,
    "likes": 180,
    "last_updated": "2025-03-17T14:40:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olympiccoder-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07033851554663993,
      "code": 0.1173236985472155,
      "math": 0.021101554663991978,
      "story": 0.0040338515546639924,
      "roleplay": 0.0040338515546639924
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "Mungert/OlympicCoder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/OlympicCoder-7B-GGUF/resolve/main/OlympicCoder-7B-bf16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237853984,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-7B-bf16.gguf"
      },
      {
        "model_id": "tensorblock/OlympicCoder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/OlympicCoder-7B-GGUF/resolve/main/OlympicCoder-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-7B-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/OlympicCoder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/OlympicCoder-7B-GGUF/resolve/main/OlympicCoder-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-7B.Q2_K.gguf"
      },
      {
        "model_id": "lmstudio-community/OlympicCoder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/OlympicCoder-7B-GGUF/resolve/main/OlympicCoder-7B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-7B-Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/open-r1/OlympicCoder-7B"
  },
  {
    "model_id": "Salesforce/codegen25-7b-multi_P",
    "label": "Codegen25 7B Multi P",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1288,
    "likes": 139,
    "last_updated": "2025-01-31T21:28:56+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegen25-7b-multi-p",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07086727586245359,
      "code": 0.2356178490849907,
      "math": 0.055980558944775764,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Salesforce/codegen25-7b-multi_P"
  },
  {
    "model_id": "NTQAI/Nxcode-CQ-7B-orpo",
    "label": "Nxcode Cq 7B Orpo",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1280,
    "likes": 139,
    "last_updated": "2024-05-30T07:04:52+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "nxcode-cq-7b-orpo",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0735481444332999,
      "code": 0.10851240920096852,
      "math": 0.022064443329989972,
      "story": 0.00435481444332999,
      "roleplay": 0.00435481444332999
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Nxcode-CQ-7B-orpo-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Nxcode-CQ-7B-orpo-GGUF/resolve/main/Nxcode-CQ-7B-orpo-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 29003220736,
        "notes": null,
        "revision": "main",
        "filename": "Nxcode-CQ-7B-orpo-f32.gguf"
      },
      {
        "model_id": "tensorblock/Nxcode-CQ-7B-orpo-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Nxcode-CQ-7B-orpo-GGUF/resolve/main/Nxcode-CQ-7B-orpo-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Nxcode-CQ-7B-orpo-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/Nxcode-CQ-7B-orpo-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Nxcode-CQ-7B-orpo-GGUF/resolve/main/Nxcode-CQ-7B-orpo.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Nxcode-CQ-7B-orpo.Q2_K.gguf"
      },
      {
        "model_id": "mav23/Nxcode-CQ-7B-orpo-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Nxcode-CQ-7B-orpo-GGUF/resolve/main/nxcode-cq-7b-orpo.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "nxcode-cq-7b-orpo.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/NTQAI/Nxcode-CQ-7B-orpo"
  },
  {
    "model_id": "microsoft/NextCoder-32B",
    "label": "Nextcoder 32B",
    "tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1163,
    "likes": 63,
    "last_updated": "2025-06-12T10:50:02+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "nextcoder-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.23293129539951574,
      "code": 0.11646564769975787,
      "math": 0.02186133400200602,
      "story": 0.004287111334002006,
      "roleplay": 0.004287111334002006
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "stelterlab/NextCoder-32B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/NextCoder-32B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 22444584856,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 22444584856
      },
      {
        "model_id": "gabriellarson/NextCoder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gabriellarson/NextCoder-32B-GGUF/resolve/main/NextCoder-32B-F16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 65535970720,
        "notes": null,
        "revision": "main",
        "filename": "NextCoder-32B-F16.gguf"
      },
      {
        "model_id": "Mungert/NextCoder-32B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/NextCoder-32B/resolve/main/NextCoder-32B-imatrix.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15011136,
        "notes": null,
        "revision": "main",
        "filename": "NextCoder-32B-imatrix.gguf"
      }
    ],
    "ram_estimate_gb": 64.8,
    "ram_recommended_gb": 81.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 64.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/microsoft/NextCoder-32B"
  },
  {
    "model_id": "PipableAI/pip-sql-1.3b",
    "label": "Pip Sql 1.3B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1186,
    "likes": 88,
    "last_updated": "2024-03-27T06:02:04+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "pip-sql-1-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.0814468405215647,
      "code": 0.10787227602905569,
      "math": 0.024434052156469408,
      "story": 0.00514468405215647,
      "roleplay": 0.00514468405215647
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "QuantFactory/pip-sql-1.3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/pip-sql-1.3b-GGUF/resolve/main/pip-sql-1.3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 704572800,
        "notes": null,
        "revision": "main",
        "filename": "pip-sql-1.3b.Q2_K.gguf"
      },
      {
        "model_id": "afrideva/pip-sql-1.3b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/afrideva/pip-sql-1.3b-GGUF/resolve/main/pip-sql-1.3b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 704572800,
        "notes": null,
        "revision": "main",
        "filename": "pip-sql-1.3b.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 1.65,
    "ram_recommended_gb": 2.06,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 1.65,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.3,
    "tier": "high",
    "model_url": "https://huggingface.co/PipableAI/pip-sql-1.3b"
  },
  {
    "model_id": "Qwen/Qwen2-Math-72B-Instruct",
    "label": "Qwen2 Math 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1164,
    "likes": 88,
    "last_updated": "2024-09-13T07:13:29+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qwen2-math-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22294491525423726,
      "code": 0.02493355065195587,
      "math": 0.014960130391173521,
      "story": 0.0049867101303911745,
      "roleplay": 0.0049867101303911745
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "second-state/Qwen2-Math-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Qwen2-Math-72B-Instruct-GGUF/resolve/main/Qwen2-Math-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-Math-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "Qwen/Qwen2-Math-72B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Qwen/Qwen2-Math-72B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 145412519312,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 145412519312
      },
      {
        "model_id": "lmstudio-community/Qwen2-Math-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Qwen2-Math-72B-Instruct-GGUF/resolve/main/Qwen2-Math-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-Math-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/Qwen2-Math-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/Qwen2-Math-72B-Instruct-GGUF/resolve/main/Qwen2-Math-72B-Instruct.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-Math-72B-Instruct.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Qwen2-Math-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Qwen2-Math-72B-Instruct-GGUF/resolve/main/Qwen2-Math-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-Math-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Qwen2-Math-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Qwen2-Math-72B-Instruct-GGUF/resolve/main/Qwen2-Math-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Qwen2-Math-72B-Instruct-Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Qwen2-Math-72B-Instruct-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Qwen2-Math-72B-Instruct-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 72314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 87.58,
    "ram_recommended_gb": 109.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 87.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Qwen/Qwen2-Math-72B-Instruct"
  },
  {
    "model_id": "MediaTek-Research/Breeze-7B-Instruct-v1_0",
    "label": "Breeze 7B 0",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1109,
    "likes": 63,
    "last_updated": "2024-06-28T07:26:00+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "breeze-7b-v1",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.21469582324455205,
      "code": 0.02117853560682046,
      "math": 0.012707121364092275,
      "story": 0.004235707121364092,
      "roleplay": 0.004235707121364092
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "YC-Chen/Breeze-7B-Instruct-v1_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/YC-Chen/Breeze-7B-Instruct-v1_0-GGUF/resolve/main/breeze-7b-instruct-v1_0-q6_k.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "breeze-7b-instruct-v1_0-q6_k.gguf"
      },
      {
        "model_id": "tensorblock/Breeze-7B-Instruct-v1_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Breeze-7B-Instruct-v1_0-GGUF/resolve/main/Breeze-7B-Instruct-v1_0-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Breeze-7B-Instruct-v1_0-Q2_K.gguf"
      },
      {
        "model_id": "second-state/Breeze-7B-Instruct-v1_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/Breeze-7B-Instruct-v1_0-GGUF/resolve/main/Breeze-7B-Instruct-v1_0-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14976095456,
        "notes": null,
        "revision": "main",
        "filename": "Breeze-7B-Instruct-v1_0-f16.gguf"
      },
      {
        "model_id": "QuantFactory/Breeze-7B-Instruct-v1_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/Breeze-7B-Instruct-v1_0-GGUF/resolve/main/Breeze-7B-Instruct-v1_0.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Breeze-7B-Instruct-v1_0.Q2_K.gguf"
      },
      {
        "model_id": "gaianet/Breeze-7B-Instruct-v1_0-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/Breeze-7B-Instruct-v1_0-GGUF/resolve/main/Breeze-7B-Instruct-v1_0-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 14976095456,
        "notes": null,
        "revision": "main",
        "filename": "Breeze-7B-Instruct-v1_0-f16.gguf"
      }
    ],
    "ram_estimate_gb": 7.9,
    "ram_recommended_gb": 9.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v1_0"
  },
  {
    "model_id": "HuggingFaceH4/zephyr-7b-gemma-v0.1",
    "label": "Zephyr 7B Gemma",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.1"
    ],
    "dropped_tags": [
      "v0.1"
    ],
    "downloads": 1085,
    "likes": 123,
    "last_updated": "2024-03-03T18:07:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "zephyr-7b-gemma",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.21436894673123486,
      "code": 0.022162738214643932,
      "math": 0.013297642928786359,
      "story": 0.004432547642928787,
      "roleplay": 0.004432547642928787
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/zephyr-7b-gemma-v0.1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/zephyr-7b-gemma-v0.1-GGUF/resolve/main/zephyr-7b-gemma-v0.1.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "zephyr-7b-gemma-v0.1.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-v0.1"
  },
  {
    "model_id": "MediaTek-Research/Breeze-7B-Instruct-v0_1",
    "label": "Breeze 7B 1",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1076,
    "likes": 90,
    "last_updated": "2024-04-24T03:52:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "breeze-7b-v0",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.21424636803874092,
      "code": 0.02473294884653962,
      "math": 0.014839769307923772,
      "story": 0.004946589769307924,
      "roleplay": 0.004946589769307924
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "tensorblock/Breeze-7B-Instruct-v0_1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Breeze-7B-Instruct-v0_1-GGUF/resolve/main/Breeze-7B-Instruct-v0_1-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Breeze-7B-Instruct-v0_1-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v0_1"
  },
  {
    "model_id": "nvidia/OpenCodeReasoning-Nemotron-32B",
    "label": "Opencodereasoning Nemotron 32B",
    "tags": [
      "code",
      "cuda",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "cuda",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1068,
    "likes": 72,
    "last_updated": "2025-05-07T19:38:42+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "opencodereasoning-nemotron-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07655717151454364,
      "code": 0.11581870460048425,
      "math": 0.02296715145436309,
      "story": 0.004655717151454363,
      "roleplay": 0.004655717151454363
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Mungert/OpenCodeReasoning-Nemotron-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/OpenCodeReasoning-Nemotron-32B-GGUF/resolve/main/OpenCodeReasoning-Nemotron-32B-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 17914572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeReasoning-Nemotron-32B-q4_0.gguf"
      },
      {
        "model_id": "lmstudio-community/OpenCodeReasoning-Nemotron-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/OpenCodeReasoning-Nemotron-32B-GGUF/resolve/main/OpenCodeReasoning-Nemotron-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeReasoning-Nemotron-32B-Q6_K.gguf"
      },
      {
        "model_id": "osxest/OpenCodeReasoning-Nemotron-32B-mlx-8Bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/osxest/OpenCodeReasoning-Nemotron-32B-mlx-8Bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 32314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 39.58,
    "ram_recommended_gb": 49.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 39.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/OpenCodeReasoning-Nemotron-32B"
  },
  {
    "model_id": "ibm-granite/granite-34b-code-instruct-8k",
    "label": "Granite 34B Code 8K",
    "tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 1063,
    "likes": 75,
    "last_updated": "2024-09-02T05:53:31+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "grane-34b-code-8k",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2215693099273608,
      "code": 0.1107846549636804,
      "math": 0.021018806419257772,
      "story": 0.004006268806419258,
      "roleplay": 0.004006268806419258
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "tensorblock/granite-34b-code-instruct-8k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/granite-34b-code-instruct-8k-GGUF/resolve/main/granite-34b-code-instruct-8k-Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-34b-code-instruct-8k-Q4_K_M.gguf"
      },
      {
        "model_id": "ibm-granite/granite-34b-code-instruct-8k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ibm-granite/granite-34b-code-instruct-8k-GGUF/resolve/main/granite-34b-code-instruct.Q4_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 19014572800,
        "notes": null,
        "revision": "main",
        "filename": "granite-34b-code-instruct.Q4_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 23.62,
    "ram_recommended_gb": 29.53,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 23.62,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/ibm-granite/granite-34b-code-instruct-8k"
  },
  {
    "model_id": "FlagAlpha/Atom-7B-Chat",
    "label": "Atom 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1052,
    "likes": 81,
    "last_updated": "2024-04-11T11:31:32+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "atom-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.21391949152542372,
      "code": 0.02431293881644935,
      "math": 0.014587763289869608,
      "story": 0.00486258776328987,
      "roleplay": 0.00486258776328987
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "FlagAlpha/Atom-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/FlagAlpha/Atom-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 14017537080,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 14017537080
      }
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/FlagAlpha/Atom-7B-Chat"
  },
  {
    "model_id": "codefuse-ai/CodeFuse-DeepSeek-33B",
    "label": "Codefuse Deepseek 33B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1040,
    "likes": 63,
    "last_updated": "2025-04-02T10:27:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codefuse-deepseek-33b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07760464987482049,
      "code": 0.24433658004566855,
      "math": 0.06390464739357705,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 66.8,
    "ram_recommended_gb": 83.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 66.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B"
  },
  {
    "model_id": "WhiteRabbitNeo/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B",
    "label": "Whiterabbitneo 2.5 Qwen 2.5 Coder 7B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1012,
    "likes": 58,
    "last_updated": "2024-10-09T18:37:10+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "wherabbneo-2-5-qwen-2-5-coder-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07560431293881646,
      "code": 0.11043734866828087,
      "math": 0.02268129388164494,
      "story": 0.004560431293881645,
      "roleplay": 0.004560431293881645
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF/resolve/main/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15237851360,
        "notes": null,
        "revision": "main",
        "filename": "WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-f16.gguf"
      },
      {
        "model_id": "tensorblock/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF/resolve/main/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-Q2_K.gguf"
      },
      {
        "model_id": "mitkox/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mitkox/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 4284346187,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 4284346187
      },
      {
        "model_id": "mav23/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF/resolve/main/whiterabbitneo-2.5-qwen-2.5-coder-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "whiterabbitneo-2.5-qwen-2.5-coder-7b.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF/resolve/main/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B.Q2_K.gguf"
      },
      {
        "model_id": "MaziyarPanahi/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-GGUF/resolve/main/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B"
  },
  {
    "model_id": "internlm/internlm2_5-7b-chat-1m",
    "label": "Internlm2 5 7B 1M",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 1011,
    "likes": 73,
    "last_updated": "2025-03-13T07:04:47+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "internlm2-5-7b-1m",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2308610774818402,
      "code": 0.024726680040120363,
      "math": 0.014836008024072218,
      "story": 0.0049453360080240726,
      "roleplay": 0.0049453360080240726
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "second-state/internlm2_5-7b-chat-1m-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/second-state/internlm2_5-7b-chat-1m-GGUF/resolve/main/internlm2_5-7b-chat-1m-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092896,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-1m-f16.gguf"
      },
      {
        "model_id": "bartowski/internlm2_5-7b-chat-1m-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/internlm2_5-7b-chat-1m-GGUF/resolve/main/internlm2_5-7b-chat-1m-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 30952977248,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-1m-f32.gguf"
      },
      {
        "model_id": "tensorblock/internlm2_5-7b-chat-1m-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/internlm2_5-7b-chat-1m-GGUF/resolve/main/internlm2_5-7b-chat-1m-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-1m-Q2_K.gguf"
      },
      {
        "model_id": "internlm/internlm2_5-7b-chat-1m-gguf",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/internlm/internlm2_5-7b-chat-1m-gguf/resolve/main/internlm2_5-7b-chat-1m-fp16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092608,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-1m-fp16.gguf"
      },
      {
        "model_id": "gaianet/internlm2_5-7b-chat-1m-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/gaianet/internlm2_5-7b-chat-1m-GGUF/resolve/main/internlm2_5-7b-chat-1m-f16.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 15478092896,
        "notes": null,
        "revision": "main",
        "filename": "internlm2_5-7b-chat-1m-f16.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/internlm/internlm2_5-7b-chat-1m"
  },
  {
    "model_id": "Chat2DB/Chat2DB-SQL-7B",
    "label": "Chat2Db Sql 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 995,
    "likes": 55,
    "last_updated": "2024-04-02T09:14:18+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "2db-sql-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2131431598062954,
      "code": 0.02542878635907723,
      "math": 0.015257271815446338,
      "story": 0.005085757271815447,
      "roleplay": 0.005085757271815447
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/Chat2DB-SQL-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Chat2DB-SQL-7B-GGUF/resolve/main/Chat2DB-SQL-7B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Chat2DB-SQL-7B-Q2_K.gguf"
      },
      {
        "model_id": "mav23/Chat2DB-SQL-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/Chat2DB-SQL-7B-GGUF/resolve/main/chat2db-sql-7b.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "chat2db-sql-7b.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Chat2DB/Chat2DB-SQL-7B"
  },
  {
    "model_id": "01-ai/Yi-34B-Chat-4bits",
    "label": "Yi 34B 4Bits",
    "tags": [
      "awq",
      "chat",
      "cuda",
      "large"
    ],
    "raw_tags": [
      "awq",
      "chat",
      "cuda",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 966,
    "likes": 61,
    "last_updated": "2024-11-11T03:31:32+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "awq",
    "quant_bits": 4,
    "canonical_base": "yi-34bs",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.22399818401937047,
      "code": 0.024438314944834505,
      "math": 0.014662988966900702,
      "story": 0.0048876629889669015,
      "roleplay": 0.0048876629889669015
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "01-ai/Yi-34B-Chat-8bits",
        "display_name": null,
        "source": null,
        "download_url": null,
        "quant_method": "gptq",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 20714572800,
        "notes": null,
        "revision": "main"
      }
    ],
    "ram_estimate_gb": 25.66,
    "ram_recommended_gb": 32.08,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 25.66,
    "format": "awq",
    "quant_class": "awq",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/01-ai/Yi-34B-Chat-4bits"
  },
  {
    "model_id": "open-r1/OlympicCoder-32B",
    "label": "Olympiccoder 32B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 939,
    "likes": 155,
    "last_updated": "2025-03-17T18:41:59+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olympiccoder-32b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07836258776328987,
      "code": 0.1149402239709443,
      "math": 0.02350877632898696,
      "story": 0.004836258776328988,
      "roleplay": 0.004836258776328988
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "Mungert/OlympicCoder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/Mungert/OlympicCoder-32B-GGUF/resolve/main/OlympicCoder-32B-q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 17914572800,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-32B-q4_0.gguf"
      },
      {
        "model_id": "lmstudio-community/OlympicCoder-32B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/OlympicCoder-32B-GGUF/resolve/main/OlympicCoder-32B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 25914572800,
        "notes": null,
        "revision": "main",
        "filename": "OlympicCoder-32B-Q6_K.gguf"
      },
      {
        "model_id": "stelterlab/OlympicCoder-32B-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/stelterlab/OlympicCoder-32B-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 19328994120,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 19328994120
      }
    ],
    "ram_estimate_gb": 22.3,
    "ram_recommended_gb": 27.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 22.3,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/open-r1/OlympicCoder-32B"
  },
  {
    "model_id": "google/codegemma-1.1-7b-it",
    "label": "Codegemma 1.1 7B It",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 271,
    "likes": 50,
    "last_updated": "2024-08-07T18:27:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegemma-1-1-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07907723169508526,
      "code": 0.10164119249394674,
      "math": 0.023723169508525578,
      "story": 0.004907723169508526,
      "roleplay": 0.004907723169508526
    },
    "best_for": [
      "local_code_assistant"
    ],
    "variants": [
      {
        "model_id": "bartowski/codegemma-1.1-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/codegemma-1.1-7b-it-GGUF/resolve/main/codegemma-1.1-7b-it-f32.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": 34156769088,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-1.1-7b-it-f32.gguf"
      },
      {
        "model_id": "lmstudio-community/codegemma-1.1-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/codegemma-1.1-7b-it-GGUF/resolve/main/codegemma-1.1-7b-it-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-1.1-7b-it-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-1.1-7b-it-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-1.1-7b-it-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 7314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "google/codegemma-1.1-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/google/codegemma-1.1-7b-it-GGUF/resolve/main/codegemma-1.1-7b-it.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": null,
        "format": "gguf",
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "codegemma-1.1-7b-it.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-1.1-7b-it-6bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-1.1-7b-it-6bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 6,
        "format": "hf",
        "size_bytes": 5564572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "LiteLLMs/codegemma-1.1-7b-it-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LiteLLMs/codegemma-1.1-7b-it-GGUF/resolve/main/Q2_K/Q2_K-00001-of-00001.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "Q2_K/Q2_K-00001-of-00001.gguf"
      },
      {
        "model_id": "mlx-community/codegemma-1.1-7b-it-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/codegemma-1.1-7b-it-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 3814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "ipetrukha/codegemma-1.1-7b-it-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/ipetrukha/codegemma-1.1-7b-it-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "4bit",
        "quant_bits": 4,
        "format": null,
        "size_bytes": 4514572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 9.58,
    "ram_recommended_gb": 11.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.58,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/google/codegemma-1.1-7b-it"
  },
  {
    "model_id": "amd/Instella-3B-Instruct",
    "label": "Instella 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 532,
    "likes": 55,
    "last_updated": "2025-03-28T18:26:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "instella-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.22433716707021792,
      "code": 0.025510280842527582,
      "math": 0.015306168505516549,
      "story": 0.005102056168505517,
      "roleplay": 0.005102056168505517
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "amd/Instella-3B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/amd/Instella-3B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": 6225397920,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 6225397920
      }
    ],
    "ram_estimate_gb": 6.8,
    "ram_recommended_gb": 8.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 6.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/amd/Instella-3B-Instruct"
  },
  {
    "model_id": "dphn/dolphin-vision-72b",
    "label": "Dolphin Vision 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 508,
    "likes": 130,
    "last_updated": "2024-07-16T14:34:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-vision-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2065102905569007,
      "code": 0.022187813440320964,
      "math": 0.013312688064192578,
      "story": 0.004437562688064193,
      "roleplay": 0.004437562688064193
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "mlx-community/dolphin-vision-72b-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/dolphin-vision-72b-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 36314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 44.38,
    "ram_recommended_gb": 55.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 44.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-vision-72b"
  },
  {
    "model_id": "m-a-p/OpenCodeInterpreter-DS-33B",
    "label": "Opencodeinterpreter Ds 33B",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 499,
    "likes": 149,
    "last_updated": "2024-03-03T11:44:54+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "opencodeinterpreter-ds-33b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07985456369107323,
      "code": 0.10319385593220338,
      "math": 0.02395636910732197,
      "story": 0.004985456369107322,
      "roleplay": 0.004985456369107322
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "LoneStriker/OpenCodeInterpreter-DS-33B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/OpenCodeInterpreter-DS-33B-GGUF/resolve/main/OpenCodeInterpreter-DS-33B-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 26714572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeInterpreter-DS-33B-Q6_K.gguf"
      },
      {
        "model_id": "mlx-community/OpenCodeInterpreter-DS-33B-hf-4bit-mlx",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/OpenCodeInterpreter-DS-33B-hf-4bit-mlx/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 16814572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "tensorblock/OpenCodeInterpreter-DS-33B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/OpenCodeInterpreter-DS-33B-GGUF/resolve/main/OpenCodeInterpreter-DS-33B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 10214572800,
        "notes": null,
        "revision": "main",
        "filename": "OpenCodeInterpreter-DS-33B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 20.98,
    "ram_recommended_gb": 26.23,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 20.98,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 33.0,
    "tier": "high",
    "model_url": "https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-33B"
  },
  {
    "model_id": "dphn/dolphin-vision-7b",
    "label": "Dolphin Vision 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 421,
    "likes": 50,
    "last_updated": "2024-07-23T17:04:26+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-vision-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.26438058503769446,
      "code": 0.01266772235851814,
      "math": 0.0036047082393794016,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-vision-7b"
  },
  {
    "model_id": "anthracite-org/magnum-v1-72b",
    "label": "Magnum 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v1"
    ],
    "dropped_tags": [
      "v1"
    ],
    "downloads": 403,
    "likes": 168,
    "last_updated": "2024-09-29T15:54:50+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "magnum-v1-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2756560907171944,
      "code": 0.022831948052974012,
      "math": 0.0189772744357574,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 144.8,
    "ram_recommended_gb": 181.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 144.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/anthracite-org/magnum-v1-72b"
  },
  {
    "model_id": "dphn/dolphin-2.0-mistral-7b",
    "label": "Dolphin 2.0 Mistral 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 343,
    "likes": 132,
    "last_updated": "2024-03-04T16:04:06+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-0-mistral-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.2635314070722258,
      "code": 0.016164281996016393,
      "math": 0.008325439760874548,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.0-mistral-7b"
  },
  {
    "model_id": "dphn/dolphin-2.9-llama3-70b",
    "label": "Dolphin 2.9 Llama3 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 294,
    "likes": 74,
    "last_updated": "2024-05-20T14:40:03+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-9-llama3-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.2035956416464891,
      "code": 0.024519809428284856,
      "math": 0.014711885656970913,
      "story": 0.0049039618856569715,
      "roleplay": 0.0049039618856569715
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/dolphin-2.9-llama3-70b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/dolphin-2.9-llama3-70b-GGUF/resolve/main/dolphin-2.9-llama3-70b-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9-llama3-70b-Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/dolphin-2.9-llama3-70b-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/dolphin-2.9-llama3-70b-GGUF/resolve/main/dolphin-2.9-llama3-70b.Q5_K_M.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 5,
        "format": "gguf",
        "size_bytes": 49314572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.9-llama3-70b.Q5_K_M.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.9-llama3-70b"
  },
  {
    "model_id": "FuseAI/FuseChat-7B-VaRM",
    "label": "Fusechat 7B Varm",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 285,
    "likes": 86,
    "last_updated": "2024-03-16T07:51:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "fuse-7b-varm",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.20347306295399514,
      "code": 0.024488465396188566,
      "math": 0.014693079237713139,
      "story": 0.0048976930792377135,
      "roleplay": 0.0048976930792377135
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "LoneStriker/FuseChat-7B-VaRM-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/LoneStriker/FuseChat-7B-VaRM-GGUF/resolve/main/FuseChat-7B-VaRM-Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "FuseChat-7B-VaRM-Q6_K.gguf"
      },
      {
        "model_id": "tensorblock/FuseChat-7B-VaRM-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/FuseChat-7B-VaRM-GGUF/resolve/main/FuseChat-7B-VaRM-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "FuseChat-7B-VaRM-Q2_K.gguf"
      },
      {
        "model_id": "nold/FuseChat-7B-VaRM-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/nold/FuseChat-7B-VaRM-GGUF/resolve/main/FuseChat-7B-VaRM_Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "FuseChat-7B-VaRM_Q6_K.gguf"
      },
      {
        "model_id": "koesn/FuseChat-7B-VaRM-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/koesn/FuseChat-7B-VaRM-GGUF/resolve/main/fusechat-7b-varm.Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 4164572800,
        "notes": null,
        "revision": "main",
        "filename": "fusechat-7b-varm.Q4_0.gguf"
      }
    ],
    "ram_estimate_gb": 7.9,
    "ram_recommended_gb": 9.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/FuseAI/FuseChat-7B-VaRM"
  },
  {
    "model_id": "nvidia/Hymba-1.5B-Instruct",
    "label": "Hymba 1.5B",
    "tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf"
    ],
    "dropped_tags": [],
    "downloads": 235,
    "likes": 233,
    "last_updated": "2025-01-02T21:25:20+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "hymba-1-5b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.27213547546538713,
      "code": 0.023140736428332098,
      "math": 0.020712782712563493,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 3.8,
    "ram_recommended_gb": 4.75,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 3.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "<2B",
    "params_b": 1.5,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Hymba-1.5B-Instruct"
  },
  {
    "model_id": "Salesforce/codegen-16B-mono",
    "label": "Codegen 16B Mono",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 222,
    "likes": 126,
    "last_updated": "2025-01-31T21:27:22+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegen-16b-mono",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.07278266694677037,
      "code": 0.22036483581821278,
      "math": 0.05952445498575685,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 32.8,
    "ram_recommended_gb": 41.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 32.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "16B",
    "params_b": 16.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Salesforce/codegen-16B-mono"
  },
  {
    "model_id": "taide/TAIDE-LX-7B-Chat",
    "label": "Taide Lx 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 209,
    "likes": 147,
    "last_updated": "2024-05-21T02:59:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "taide-lx-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.20243795399515738,
      "code": 0.023711133400200604,
      "math": 0.014226680040120362,
      "story": 0.004742226680040121,
      "roleplay": 0.004742226680040121
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "taide/TAIDE-LX-7B",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/taide/TAIDE-LX-7B/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": null,
        "quant_bits": null,
        "format": null,
        "size_bytes": null,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "QuantFactory/TAIDE-LX-7B-Chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/TAIDE-LX-7B-Chat-GGUF/resolve/main/TAIDE-LX-7B-Chat.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "TAIDE-LX-7B-Chat.Q2_K.gguf"
      },
      {
        "model_id": "QuantFactory/TAIDE-LX-7B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/QuantFactory/TAIDE-LX-7B-GGUF/resolve/main/TAIDE-LX-7B.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "TAIDE-LX-7B.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/taide/TAIDE-LX-7B-Chat"
  },
  {
    "model_id": "allenai/OLMo-2-1124-13B-Instruct-preview",
    "label": "Olmo 2 1124 13B Preview",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 204,
    "likes": 56,
    "last_updated": "2025-01-06T19:51:02+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "olmo-2-1124-13b-preview",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.2708974756431953,
      "code": 0.01764691843392135,
      "math": 0.009245989506735816,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 26.8,
    "ram_recommended_gb": 33.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 26.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/allenai/OLMo-2-1124-13B-Instruct-preview"
  },
  {
    "model_id": "gradientai/Llama-3-70B-Instruct-Gradient-262k",
    "label": "Llama 3 70B Gradient 262K",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 198,
    "likes": 55,
    "last_updated": "2024-10-28T20:46:41+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-70b-gradient-262k",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.20978813559322035,
      "code": 0.020827482447342026,
      "math": 0.012496489468405215,
      "story": 0.004165496489468405,
      "roleplay": 0.004165496489468405
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "starsy/Llama-3-70B-Instruct-Gradient-262k-AWQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/starsy/Llama-3-70B-Instruct-Gradient-262k-AWQ/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "awq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 39767996256,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json",
        "total_sharded_size_bytes": 39767996256
      },
      {
        "model_id": "mlx-community/Llama-3-70B-Instruct-Gradient-262k-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3-70B-Instruct-Gradient-262k-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 43.18,
    "ram_recommended_gb": 53.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 43.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/gradientai/Llama-3-70B-Instruct-Gradient-262k"
  },
  {
    "model_id": "Tele-AI/telechat-7B",
    "label": "Telechat 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 166,
    "likes": 108,
    "last_updated": "2024-08-02T03:32:30+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "tele-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.26050026975505436,
      "code": 0.008636660278668624,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Tele-AI/telechat-7B"
  },
  {
    "model_id": "yentinglin/Taiwan-LLM-13B-v2.0-chat",
    "label": "Taiwan Llm 13B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v2.0"
    ],
    "dropped_tags": [
      "v2.0"
    ],
    "downloads": 162,
    "likes": 50,
    "last_updated": "2025-04-20T02:16:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "taiwan-llm-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.21929782082324456,
      "code": 0.022513791374122367,
      "math": 0.013508274824473419,
      "story": 0.004502758274824474,
      "roleplay": 0.004502758274824474
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "audreyt/Taiwan-LLM-13B-v2.0-chat-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/audreyt/Taiwan-LLM-13B-v2.0-chat-GGUF/resolve/main/Taiwan-LLM-13B-v2.0-chat-Q4_0.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 4,
        "format": "gguf",
        "size_bytes": 7464572800,
        "notes": null,
        "revision": "main",
        "filename": "Taiwan-LLM-13B-v2.0-chat-Q4_0.gguf"
      }
    ],
    "ram_estimate_gb": 9.76,
    "ram_recommended_gb": 12.2,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 9.76,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/yentinglin/Taiwan-LLM-13B-v2.0-chat"
  },
  {
    "model_id": "abacusai/Dracarys2-72B-Instruct",
    "label": "Dracarys2 72B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 160,
    "likes": 72,
    "last_updated": "2024-10-31T06:18:48+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dracarys2-72b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.20927058111380145,
      "code": 0.02039493480441324,
      "math": 0.012236960882647944,
      "story": 0.004078986960882648,
      "roleplay": 0.004078986960882648
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "bartowski/Dracarys2-72B-Instruct-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Dracarys2-72B-Instruct-GGUF/resolve/main/Dracarys2-72B-Instruct-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21914572800,
        "notes": null,
        "revision": "main",
        "filename": "Dracarys2-72B-Instruct-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 27.1,
    "ram_recommended_gb": 33.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 27.1,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 72.0,
    "tier": "high",
    "model_url": "https://huggingface.co/abacusai/Dracarys2-72B-Instruct"
  },
  {
    "model_id": "aiXcoder/aixcoder-7b-base",
    "label": "Aixcoder 7B Base",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 101,
    "likes": 56,
    "last_updated": "2024-04-15T03:16:20+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "aixcoder-7b-base",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.08502191218763323,
      "code": 0.20876160449502093,
      "math": 0.07374429952892175,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/aiXcoder/aixcoder-7b-base"
  },
  {
    "model_id": "Intel/neural-chat-7b-v3",
    "label": "Neural 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v3"
    ],
    "dropped_tags": [
      "v3"
    ],
    "downloads": 89,
    "likes": 67,
    "last_updated": "2024-11-14T23:11:55+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "neural-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.20830357142857142,
      "code": 0.021266298896690072,
      "math": 0.012759779338014043,
      "story": 0.004253259779338015,
      "roleplay": 0.004253259779338015
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "mav23/neural-chat-7b-v3-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mav23/neural-chat-7b-v3-GGUF/resolve/main/neural-chat-7b-v3.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "neural-chat-7b-v3.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Intel/neural-chat-7b-v3"
  },
  {
    "model_id": "UNIVA-Bllossom/DeepSeek-llama3.3-Bllossom-70B",
    "label": "Deepseek Llama3.3 Bllossom 70B",
    "tags": [
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 87,
    "likes": 60,
    "last_updated": "2025-06-16T04:48:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "deepseek-llama3-3-bllossom-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.0822419048055403,
      "code": 0.2296670982193417,
      "math": 0.07060077391430143,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/UNIVA-Bllossom/DeepSeek-llama3.3-Bllossom-70B"
  },
  {
    "model_id": "dphn/dolphin-2.2-70b",
    "label": "Dolphin 2.2 70B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 82,
    "likes": 51,
    "last_updated": "2024-05-20T14:48:34+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-2-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.25894140106287555,
      "code": 0.010049495491255514,
      "math": 0.003,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 140.8,
    "ram_recommended_gb": 176.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 140.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.2-70b"
  },
  {
    "model_id": "gradientai/Llama-3-70B-Instruct-Gradient-1048k",
    "label": "Llama 3 70B Gradient 1048K",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 80,
    "likes": 122,
    "last_updated": "2024-10-28T20:46:14+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama-3-70b-gradient-1048k",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.20818099273607749,
      "code": 0.0207271815446339,
      "math": 0.01243630892678034,
      "story": 0.004145436308926781,
      "roleplay": 0.004145436308926781
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "vsevolodl/Llama-3-70B-Instruct-Gradient-1048k-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/vsevolodl/Llama-3-70B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-70B-Instruct-Gradient-1048k.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama-3-70B-Instruct-Gradient-1048k.Q2_K.gguf"
      },
      {
        "model_id": "mlx-community/Llama-3-70B-Instruct-Gradient-1048k-8bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3-70B-Instruct-Gradient-1048k-8bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 8,
        "format": "hf",
        "size_bytes": 70314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      },
      {
        "model_id": "mlx-community/Llama-3-70B-Instruct-Gradient-1048k-4bit",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/mlx-community/Llama-3-70B-Instruct-Gradient-1048k-4bit/resolve/main/model.safetensors.index.json?download=true",
        "quant_method": "mlx",
        "quant_bits": 4,
        "format": "hf",
        "size_bytes": 35314572800,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors.index.json"
      }
    ],
    "ram_estimate_gb": 85.18,
    "ram_recommended_gb": 106.48,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 85.18,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/gradientai/Llama-3-70B-Instruct-Gradient-1048k"
  },
  {
    "model_id": "nvidia/Llama3-ChatQA-1.5-70B",
    "label": "Llama3 Chatqa 1.5 70B",
    "tags": [
      "chat",
      "cuda",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "cuda",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 69,
    "likes": 333,
    "last_updated": "2024-05-24T17:32:05+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "llama3qa-1-5-70b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.20053117433414044,
      "code": 0.021874373119358075,
      "math": 0.013124623871614845,
      "story": 0.004374874623871615,
      "roleplay": 0.004374874623871615
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "variants": [
      {
        "model_id": "lmstudio-community/Llama3-ChatQA-1.5-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/lmstudio-community/Llama3-ChatQA-1.5-70B-GGUF/resolve/main/Llama3-ChatQA-1.5-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-70B-Q2_K.gguf"
      },
      {
        "model_id": "bartowski/Llama3-ChatQA-1.5-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/bartowski/Llama3-ChatQA-1.5-70B-GGUF/resolve/main/Llama3-ChatQA-1.5-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-70B-Q2_K.gguf"
      },
      {
        "model_id": "tensorblock/Llama3-ChatQA-1.5-70B-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/tensorblock/Llama3-ChatQA-1.5-70B-GGUF/resolve/main/Llama3-ChatQA-1.5-70B-Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 21314572800,
        "notes": null,
        "revision": "main",
        "filename": "Llama3-ChatQA-1.5-70B-Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 26.38,
    "ram_recommended_gb": 32.98,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 26.38,
    "quant_class": null,
    "format": "hf",
    "size_hint": "70B",
    "params_b": 70.0,
    "tier": "high",
    "model_url": "https://huggingface.co/nvidia/Llama3-ChatQA-1.5-70B"
  },
  {
    "model_id": "Tesslate/UIGEN-T1-7B-q8_0-GGUF",
    "label": "Uigen T1 7B 0",
    "tags": [
      "code",
      "gguf",
      "mps",
      "small"
    ],
    "raw_tags": [
      "code",
      "gguf",
      "mps",
      "q8_0",
      "small"
    ],
    "dropped_tags": [
      "q8_0"
    ],
    "downloads": 66,
    "likes": 204,
    "last_updated": "2025-02-19T19:19:26+00:00",
    "confidence": "recommended",
    "is_quant": true,
    "quant_method": "gguf",
    "canonical_base": "uigen-t1-7b-q8",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.07245698913649445,
      "code": 0.23420365914001462,
      "math": 0.05793319755569812,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 7.8,
    "ram_recommended_gb": 9.75,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 7.8,
    "quant_bits": 8,
    "format": "gguf",
    "quant_class": "gguf-q8",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Tesslate/UIGEN-T1-7B-q8_0-GGUF"
  },
  {
    "model_id": "dphn/dolphin-2.6-mistral-7b-dpo",
    "label": "Dolphin 2.6 Mistral 7B Dpo",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 53,
    "likes": 59,
    "last_updated": "2024-05-20T15:01:33+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-6-mistral-7b-dpo",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.25845621802499574,
      "code": 0.015629598142659875,
      "math": 0.00593143859733212,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.6-mistral-7b-dpo"
  },
  {
    "model_id": "dphn/dolphin-2.6-mistral-7b-dpo-laser",
    "label": "Dolphin 2.6 Mistral 7B Dpo Laser",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 53,
    "likes": 119,
    "last_updated": "2024-03-04T07:09:51+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-6-mistral-7b-dpo-laser",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.20031325665859565,
      "code": 0.02115346038114343,
      "math": 0.012692076228686058,
      "story": 0.004230692076228687,
      "roleplay": 0.004230692076228687
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "MaziyarPanahi/dolphin-2.6-mistral-7b-dpo-laser-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/MaziyarPanahi/dolphin-2.6-mistral-7b-dpo-laser-GGUF/resolve/main/dolphin-2.6-mistral-7b-dpo-laser.Q6_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 6,
        "format": "gguf",
        "size_bytes": 5914572800,
        "notes": null,
        "revision": "main",
        "filename": "dolphin-2.6-mistral-7b-dpo-laser.Q6_K.gguf"
      }
    ],
    "ram_estimate_gb": 7.9,
    "ram_recommended_gb": 9.88,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 7.9,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2.6-mistral-7b-dpo-laser"
  },
  {
    "model_id": "dphn/dolphin-llama-13b",
    "label": "Dolphin Llama 13B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 48,
    "likes": 65,
    "last_updated": "2024-03-04T16:03:07+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-llama-13b",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.20024515738498788,
      "code": 0.025366098294884655,
      "math": 0.015219658976930792,
      "story": 0.0050732196589769315,
      "roleplay": 0.0050732196589769315
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/Dolphin-Llama-13B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/Dolphin-Llama-13B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 7259449616,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 26.8,
    "ram_recommended_gb": 33.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 26.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "13B",
    "params_b": 13.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-llama-13b"
  },
  {
    "model_id": "lucyknada/microsoft_WizardLM-2-7B",
    "label": "Microsoft Wizardlm 2 7B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 35,
    "likes": 53,
    "last_updated": "2024-04-16T11:15:19+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "microsoft-wizardlm-2-7b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.25853468144211966,
      "code": 0.012591066040341084,
      "math": 0.003223979364330359,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant"
    ],
    "ram_estimate_gb": 14.8,
    "ram_recommended_gb": 18.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 14.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/lucyknada/microsoft_WizardLM-2-7B"
  },
  {
    "model_id": "Salesforce/codegen-16B-multi",
    "label": "Codegen 16B Multi",
    "tags": [
      "code",
      "hf",
      "small"
    ],
    "raw_tags": [
      "code",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 34,
    "likes": 119,
    "last_updated": "2025-01-31T21:25:02+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codegen-16b-multi",
    "resource_class": {
      "size_category": "medium"
    },
    "relevance_scores": {
      "assistant": 0.06963713987751571,
      "code": 0.21694983025849549,
      "math": 0.055983084655402,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant"
    ],
    "ram_estimate_gb": 32.8,
    "ram_recommended_gb": 41.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 32.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "16B",
    "params_b": 16.0,
    "tier": "high",
    "model_url": "https://huggingface.co/Salesforce/codegen-16B-multi"
  },
  {
    "model_id": "dphn/dolphin-2_2-yi-34b",
    "label": "Dolphin 2 2 Yi 34B",
    "tags": [
      "chat",
      "hf",
      "large"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 27,
    "likes": 92,
    "last_updated": "2024-07-06T02:20:53+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "dolphin-2-2-yi-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.25409846735649855,
      "code": 0.021900225783365045,
      "math": 0.016635742752544234,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 68.8,
    "ram_recommended_gb": 86.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 68.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/dphn/dolphin-2_2-yi-34b"
  },
  {
    "model_id": "codefuse-ai/CodeFuse-CodeLlama-34B",
    "label": "Codefuse Codellama 34B",
    "tags": [
      "code",
      "hf",
      "large"
    ],
    "raw_tags": [
      "code",
      "hf",
      "large"
    ],
    "dropped_tags": [],
    "downloads": 23,
    "likes": 93,
    "last_updated": "2025-03-23T15:52:57+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "codefuse-codellama-34b",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.07327541858484539,
      "code": 0.22216401114019868,
      "math": 0.05916378412839169,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "local_code_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 68.8,
    "ram_recommended_gb": 86.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 68.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 34.0,
    "tier": "high",
    "model_url": "https://huggingface.co/codefuse-ai/CodeFuse-CodeLlama-34B"
  },
  {
    "model_id": "pansophic/rocket-3B",
    "label": "Rocket 3B",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 20,
    "likes": 86,
    "last_updated": "2024-03-01T11:21:21+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "rocket-3b",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.1925,
      "code": 0.023385155466399198,
      "math": 0.01403109327983952,
      "story": 0.0046770310932798395,
      "roleplay": 0.0046770310932798395
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "TheBloke/rocket-3B-GPTQ",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/TheBloke/rocket-3B-GPTQ/resolve/main/model.safetensors?download=true",
        "quant_method": "gptq",
        "quant_bits": null,
        "format": "hf",
        "size_bytes": 1838811216,
        "notes": null,
        "revision": "main",
        "filename": "model.safetensors"
      }
    ],
    "ram_estimate_gb": 6.8,
    "ram_recommended_gb": 8.5,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 6.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 3.0,
    "tier": "high",
    "model_url": "https://huggingface.co/pansophic/rocket-3B"
  },
  {
    "model_id": "MediaTek-Research/Breexe-8x7B-Instruct-v0_1",
    "label": "Breexe 8X7B 1",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small"
    ],
    "dropped_tags": [],
    "downloads": 14,
    "likes": 54,
    "last_updated": "2024-08-02T01:14:28+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "breexe-8x7b-v0",
    "resource_class": {
      "size_category": "light"
    },
    "relevance_scores": {
      "assistant": 0.188,
      "code": 0.020344784353059177,
      "math": 0.012206870611835506,
      "story": 0.0040689568706118355,
      "roleplay": 0.0040689568706118355
    },
    "best_for": [
      "general_assistant"
    ],
    "variants": [
      {
        "model_id": "PenutChen/Breexe-8x7B-Instruct-v0_1-GGUF",
        "display_name": null,
        "source": null,
        "download_url": "https://huggingface.co/PenutChen/Breexe-8x7B-Instruct-v0_1-GGUF/resolve/main/BreeXe-8x7B-Inst.Q2_K.gguf?download=true",
        "quant_method": "gguf",
        "quant_bits": 2,
        "format": "gguf",
        "size_bytes": 2414572800,
        "notes": null,
        "revision": "main",
        "filename": "BreeXe-8x7B-Inst.Q2_K.gguf"
      }
    ],
    "ram_estimate_gb": 3.7,
    "ram_recommended_gb": 4.63,
    "ram_estimate_method": "variant_size",
    "ram_estimate_confidence": "high",
    "estimated_ram_requirement": 3.7,
    "quant_class": null,
    "format": "hf",
    "size_hint": "2–8B",
    "params_b": 7.0,
    "tier": "high",
    "model_url": "https://huggingface.co/MediaTek-Research/Breexe-8x7B-Instruct-v0_1"
  },
  {
    "model_id": "recursal/QRWKV6-32B-Instruct-Preview-v0.1",
    "label": "Qrwkv6 32B Preview",
    "tags": [
      "chat",
      "hf",
      "small"
    ],
    "raw_tags": [
      "chat",
      "hf",
      "small",
      "v0.1"
    ],
    "dropped_tags": [
      "v0.1"
    ],
    "downloads": 17,
    "likes": 79,
    "last_updated": "2025-06-30T01:02:39+00:00",
    "confidence": "recommended",
    "is_quant": false,
    "canonical_base": "qrwkv6-32b-preview",
    "resource_class": {
      "size_category": "heavy"
    },
    "relevance_scores": {
      "assistant": 0.26880714373019393,
      "code": 0.015919673915146038,
      "math": 0.006666040246958664,
      "story": 0.0,
      "roleplay": 0.0
    },
    "best_for": [
      "general_assistant (powerful hardware)"
    ],
    "ram_estimate_gb": 64.8,
    "ram_recommended_gb": 81.0,
    "ram_estimate_method": "param_heuristic",
    "ram_estimate_confidence": "medium",
    "estimated_ram_requirement": 64.8,
    "quant_class": null,
    "format": "hf",
    "size_hint": "34B/30B",
    "params_b": 32.0,
    "tier": "high",
    "model_url": "https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1"
  }
]